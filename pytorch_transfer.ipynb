{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import functools\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "\n",
    "# general modules\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# tensorflow modules\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "\n",
    "# necessary for visualization and user input\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import asyncio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set True, if code is run as jupyter notebook\n",
    "is_interactive_notebook = True\n",
    "\n",
    "# paths\n",
    "dataset_path = 'datasets\\\\corpus.txt'\n",
    "vocab_path = 'datasets\\\\vocab.txt'\n",
    "\n",
    "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"\"\"Produce N identical layers\"\"\"\n",
    "    return [copy.deepcopy(module) for _ in range(N)]\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"\"\"Mask out subsequent positions.\"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerWrapper(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A wrapper for Keras layers, which allows to visualize data at each layer.\n",
    "\n",
    "    Attributes:\n",
    "        should_visualize (bool): Class attribute controlling whether visualization should occur.\n",
    "        layer (Layer): The Keras layer to be wrapped.\n",
    "        inputs (List[Tensor]): Inputs to the layer during calls.\n",
    "        outputs (List[Tensor]): Outputs of the layer during calls.\n",
    "        counter (int): Counter of layer calls.\n",
    "        visualize_on_calls (List[int]): List of call counts at which to visualize.\n",
    "        visualizations (List[Tuple[str, str]]): List of visualization modes and what to visualize.\n",
    "        visual_setter (bool): If True, this instance can change the should_visualize class variable.\n",
    "    \"\"\"\n",
    "    should_visualize = True  # class variable\n",
    "\n",
    "    def __init__(self, layer, visualize_on_calls=None, visualizations=None, visual_setter=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the LayerCallWrapper\n",
    "        Args:\n",
    "            layer (Layer): The Keras layer to be wrapped.\n",
    "            visualize_on_calls (List[int], optional): List of call counts at which to visualize. Defaults to empty list.\n",
    "            visualizations (List[Tuple[str, str]], optional): List of visualization modes and what to visualize. Defaults to an empty list.\n",
    "            visual_setter (bool, optional): If True, this instance can change the should_visualize class variable. Defaults to False.\n",
    "            **kwargs: Additional keyword arguments.u\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.counter = 0\n",
    "        self.visualize_on_calls = visualize_on_calls if visualize_on_calls else []\n",
    "        self.visualizations = visualizations if visualizations else []\n",
    "        self.visual_setter = visual_setter\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        \"\"\"\n",
    "        Overloads the attributte access in order to access the wrapped layers attribute if not found in the wraper\n",
    "        \"\"\"\n",
    "        if 'layer' in self.__dict__:\n",
    "            return getattr(self.layer, attr)\n",
    "        else:\n",
    "            raise AttributeError(f\"{self.__class__.__name__} object has no attribute {attr}\")\n",
    "\n",
    "        \n",
    "    def call(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Overloads the call to the layer, allowing to capture inputs and outputs, and visualize if needed.\n",
    "\n",
    "        Args:\n",
    "            *args: Variable length argument list.\n",
    "            **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output of the layer call.\n",
    "        \"\"\"\n",
    "        self.inputs.append([arg for arg in args])\n",
    "        output = self.layer(*args, **kwargs)\n",
    "        self.outputs.append(output.numpy())\n",
    "\n",
    "        # check for visualisation param of the instance and visualize or change class settings\n",
    "        if self.counter in self.visualize_on_calls:\n",
    "            if self.should_visualize:\n",
    "                self.visualize(self.visualizations)\n",
    "            if self.visual_setter:\n",
    "                LayerWrapper.should_visualize = True\n",
    "        else:\n",
    "            if self.visual_setter:\n",
    "                LayerWrapper.should_visualize = False\n",
    "\n",
    "        self.counter += 1\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def wait_for_user_input():\n",
    "        # waits for user input, if not jupyter notebook\n",
    "        # causes problems in jupyter\n",
    "        if not is_interactive_notebook:\n",
    "            proceed = input('Continue')\n",
    "\n",
    "    def visualize(self, visualizations):\n",
    "        for mode, what_to_output in visualizations:\n",
    "            if what_to_output == 'x':\n",
    "                data = self.inputs[-1]\n",
    "            elif what_to_output == 'y':\n",
    "                data = self.outputs[-1]\n",
    "            elif what_to_output == 'y-x':\n",
    "                data = [output - input for input, output in zip(self.inputs[-1], self.outputs[-1])]\n",
    "\n",
    "            if mode == 'mode1':\n",
    "                self.visualization_func_1(data)\n",
    "            elif mode == 'mode2':\n",
    "                self.visualization_func2(data)\n",
    "\n",
    "        self.wait_for_user_input()\n",
    "\n",
    "    def visualization_func_1(self, data):\n",
    "        # Assuming data[0] is a numpy array.\n",
    "        # If it's a ListWrapper or another list-like object, convert it to a numpy array.\n",
    "        array_data = np.array(data[0])\n",
    "        # If the array is 1D, reshape it into a 2D array with one column\n",
    "        if array_data.ndim == 1:\n",
    "            array_data = np.reshape(array_data, (-1, 1))\n",
    "        # Set the size of the plot (you can adjust the dimensions as needed)\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        # Use imshow to create a color-coded visualization and display it\n",
    "        plt.imshow(array_data, cmap='jet', aspect='auto')\n",
    "        plt.colorbar(label='Tensor Value')\n",
    "        plt.show()\n",
    "        \n",
    "    def visualization_func2(self, data):\n",
    "        # Your visualization code here\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(layers.Layer):\n",
    "    def __init__(self, encoder, decoder, enc_embed, dec_embed, generator):\n",
    "        super().__init__()\n",
    "        # modules\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.enc_embed = enc_embed\n",
    "        self.dec_embed = dec_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def encode(self, inputs, pad_mask):\n",
    "        return self.encoder(self.enc_embed(inputs), pad_mask)\n",
    "    \n",
    "    def decode(self, enc_input, pad_mask, inputs, subseq_mask):\n",
    "        return self.decoder(self.dec_embed(inputs), enc_input, pad_mask, subseq_mask)\n",
    "\n",
    "    def call(self, enc_input, dec_input, pad_mask, subseq_mask):\n",
    "        return self.decode(self.encode(enc_input, pad_mask), \n",
    "                           pad_mask,\n",
    "                           dec_input, \n",
    "                           subseq_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(layers.Layer):\n",
    "    \"\"\"\n",
    "    Construct a layernorm module\n",
    "    TODO What is done in here? I do not really understand it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6) -> None:\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = self.add_weight(shape=(features,), initializer='ones')\n",
    "        self.b_2 = self.add_weight(shape=(features,), initializer='zeros')\n",
    "        self.eps = eps\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, var = tf.nn.moments(x, axes=-1, keepdims=True)\n",
    "        std = tf.math.sqrt(var + self.eps)\n",
    "        return self.a_2 * (x - mean) / std + self.b_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSublayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout) -> None:\n",
    "        super(ResidualSublayer, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(layers.Layer):\n",
    "    \"\"\"\n",
    "    Core encoder is a stack of N=6 Layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        \"\"\"\n",
    "        Pass the input (and mask) through each layer in turn\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder is made up of a self-attention and a feed forward layer \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(ResidualSublayer(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(layers.Layer):\n",
    "    \"\"\"\n",
    "    Generic N layer decoder with masking\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def call(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    Decoder is made of self-attn, source-attn and feedforward layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(ResidualSublayer(size, dropout), 3)\n",
    "\n",
    "    def call(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sublayers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(layers.Layer):\n",
    "    \"\"\"Implements FFN equation\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1, *args, **kwargs):\n",
    "        super(PositionwiseFeedForward, self).__init__(*args, **kwargs)\n",
    "        self.w_1 = layers.Dense(d_ff)\n",
    "        self.w_2 = layers.Dense(d_model)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.w_2(self.dropout(tf.nn.relu(self.w_1(x))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(layers.Layer):\n",
    "    \"\"\"\n",
    "    Define standard linear + softmax generation step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab):\n",
    "        super(Generator,self).__init__()\n",
    "        self.proj = layers.Dense(vocab)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.nn.log_softmax(self.proj(x), axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "\n",
    "    d_k = query.shape[-1]\n",
    "    scores = tf.matmul(query, tf.transpose(key, perm=[0, 1, 3, 2])) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = tf.cast(mask, dtype=tf.bool)\n",
    "        scores = tf.where(mask, scores, tf.fill(tf.shape(scores), -1e9))\n",
    "    p_attn = tf.nn.softmax(scores, axis=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return tf.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(layers.Layer):\n",
    "    \n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.query, self.key, self.value, self.linear = clones(layers.Dense(d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads\n",
    "            mask = tf.expand_dims(mask, 1)\n",
    "        nbatches = query.shape[0]\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [tf.transpose(tf.reshape(lin(x), [nbatches, -1 , self.h, self.d_k]), perm=[0, 2, 1, 3])  for lin, x in zip([self.query, self.key, self.value], (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = tf.reshape(tf.transpose(x ,perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]   # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth  # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)               # (1, depth)\n",
    "    angle_rads  = positions * angle_rates           # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1\n",
    "        )\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positional_encoding\n",
    "        x *=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        #print(tf.shape(x))\n",
    "        #print(tf.shape(self.pos_encoding[tf.newaxis, :length, :]))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    model = LayerWrapper(\n",
    "                EncoderDecoder(\n",
    "                EncoderStack(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "                DecoderStack(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "                PositionalEmbedding(src_vocab, d_model),\n",
    "                PositionalEmbedding(tgt_vocab, d_model),\n",
    "                LayerWrapper(Generator(tgt_vocab), visualize_on_calls=[1], visualizations=[('mode1', 'x')])\n",
    "            ),\n",
    "            visualize_on_calls=[1], visual_setter=True)\n",
    "\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    # model.build([(None, None), (None, None)])  # Explicit build call to initialize variables\n",
    "    # for w in model.trainable_variables:\n",
    "    #     if len(w.shape) > 1:\n",
    "    #         tf.keras.initializers.GlorotUniform()(w)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_test():\n",
    "    test_model = make_model(11, 11, 2)\n",
    "\n",
    "    test_model.trainable = False\n",
    "    src = tf.constant([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], dtype=tf.int64)\n",
    "    src_mask = tf.ones((1, 1, 10), dtype=tf.float32)\n",
    "\n",
    "    memory = test_model.encode(src, src_mask)\n",
    "    ys = tf.zeros((1, 1), dtype=tf.int64)\n",
    "\n",
    "    for i in range(9):\n",
    "        out = test_model.decode(memory, src_mask, ys, subsequent_mask(ys.shape[1]))\n",
    "        prob = test_model.generator(out[:, -1])\n",
    "        next_word = tf.argmax(prob, axis=-1)[0]\n",
    "        ys = tf.concat([ys, tf.reshape(next_word, (1, 1))], axis=1)\n",
    "\n",
    "    print(\"Example Untrained Model Prediction:\", ys)\n",
    "\n",
    "def run_tests():\n",
    "    for _ in range(10):\n",
    "        inference_test()\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_text_file):\n",
    "    return tf.data.TextLineDataset(filenames=dataset_text_file)\n",
    "\n",
    "def create_vocab(dataset):\n",
    "    bert_vocab_args=dict(\n",
    "        vocab_size = 8000,\n",
    "        reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"],\n",
    "        bert_tokenizer_params = dict(lower_case=True),\n",
    "        learn_params = {},\n",
    "    )\n",
    "\n",
    "    story_vocab = bert_vocab.bert_vocab_from_dataset(\n",
    "        dataset.batch(1000).prefetch(2),\n",
    "        **bert_vocab_args\n",
    "    )\n",
    "    return story_vocab\n",
    "\n",
    "def create_vocab_from_textdata(text_file=dataset_path):\n",
    "    dataset = load_dataset(text_file)\n",
    "    vocab = create_vocab(dataset)\n",
    "    return vocab\n",
    "\n",
    "def write_vocab_file(filepath, vocab):\n",
    "    with open(filepath, 'w') as file:\n",
    "        for token in vocab:\n",
    "            print(token, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
    "\n",
    "    def __init__(self, src, tgt=None, pad=2): # 2 = <blank>\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad)[:, np.newaxis, :]\n",
    "        if tgt is not None:\n",
    "            self.tgt = tgt[:, :-1]\n",
    "            self.tgt_y = tgt[:, 1:]\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            self.ntokens = tf.reduce_sum(tf.cast(self.tgt_y != pad, tf.int64))\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad)[:, np.newaxis, :]\n",
    "        tgt_mask = tf.logical_and(tgt_mask, subsequent_mask(tgt.shape[-1]))\n",
    "        return tgt_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end(ragged):\n",
    "    START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n",
    "    END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n",
    "\n",
    "    count = ragged.bounding_shape()[0]\n",
    "    starts = tf.fill([count, 1], START)\n",
    "    ends = tf.fill([count, 1], END)\n",
    "    return tf.concat([starts, ragged, ends], axis=1)\n",
    "\n",
    "def cleanup_text(reserved_tokens, token_txt):\n",
    "    bad_tokens = list(filter(lambda token: token != \"[UNK]\", reserved_tokens))\n",
    "    bad_tokens_re = \"|\".join(bad_tokens)\n",
    "\n",
    "    bad_cells = tf.strings.regex_full_match(token_txt, bad_tokens_re)\n",
    "    ragged_result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n",
    "\n",
    "    result = tf.strings.reduce_join(ragged_result, separator=' ', axis=-1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryTokenizer(tf.Module):\n",
    "    def __init__(self, reserved_tokens, vocab_path):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tf_text.BertTokenizer(vocab_path, lower_case=True)\n",
    "        self._reserved_tokens = reserved_tokens\n",
    "        self._vocab_path = tf.saved_model.Asset(vocab_path)\n",
    "\n",
    "        vocab = pathlib.Path(vocab_path).read_text().splitlines()\n",
    "        self.vocab = tf.Variable(vocab)\n",
    "\n",
    "        ## Create the signatures for export:\n",
    "\n",
    "        # tokenize signature for a batch of strings\n",
    "        self.tokenize.get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string))\n",
    "        \n",
    "        # detokenize and lookup signature for:\n",
    "        # * Tensor with shape [tokens] and [batch, tokens]\n",
    "        # * RaggedTensor with shape [batch, tokens]\n",
    "        self.detokenize.get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n",
    "        self.detokenize.get_concrete_function(\n",
    "            tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n",
    "        \n",
    "        self.lookup.get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n",
    "        self.lookup.get_concrete_function(\n",
    "            tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n",
    "        \n",
    "\n",
    "        # get_* methods take no argument\n",
    "        self.get_vocab_size.get_concrete_function()\n",
    "        self.get_vocab_path.get_concrete_function()\n",
    "        self.get_reserved_tokens.get_concrete_function()\n",
    "\n",
    "    @tf.function\n",
    "    def tokenize(self, strings):\n",
    "        encoded = self.tokenizer.tokenize(strings)\n",
    "        merged_enc = encoded.merge_dims(-2, -1)\n",
    "        merg_enc_start_end = add_start_end(merged_enc)\n",
    "        return merg_enc_start_end\n",
    "    \n",
    "    @tf.function\n",
    "    def detokenize(self, tokenized):\n",
    "        words = self.tokenizer.detokenize(tokenized)\n",
    "        return cleanup_text(self._reserved_tokens, words)\n",
    "    \n",
    "    @tf.function\n",
    "    def lookup(self, token_ids):\n",
    "        return tf.gather(self.vocab, token_ids)\n",
    "    \n",
    "    @tf.function\n",
    "    def get_vocab_size(self):\n",
    "        return tf.shape(self.vocab)[0]\n",
    "    \n",
    "    @tf.function\n",
    "    def get_vocab_path(self):\n",
    "        return self._vocab_path\n",
    "    \n",
    "    @tf.function\n",
    "    def get_reserved_tokens(self):\n",
    "        return tf.constant(self._reserved_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
    "\n",
    "    step: int = 0 # Steps in the current epoch\n",
    "    accum_step: int = 0 # Number of gradient accumulation steps\n",
    "    samples: int = 0 # total number of examples used\n",
    "    tokens: int = 0 # total number of tokens processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_simu_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
