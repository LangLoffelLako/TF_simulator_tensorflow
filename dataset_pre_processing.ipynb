{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pre-Processing Notebook\n",
    "The purpose of this notebook is to preprocess each file of the datasets we collected.\n",
    "We want all the dataset as a single csv-file with stories as entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "import logging as log\n",
    "import functools\n",
    "import itertools\n",
    "import pathlib\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=log.DEBUG,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "log_enabled = True\n",
    "show_notebook_results = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decorators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `log_dec(func)`:\n",
    "\n",
    "    This is a decorator function that logs the start and end time of the function it decorates if logging is enabled. \n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    `func`: The function to be logged.\n",
    "\n",
    "    How it works: \n",
    "\n",
    "    - The `wrapper` function is defined to wrap around the `func`.\n",
    "    - If `log_enabled` is `True`, the start time of the function is logged.\n",
    "    - The `func` is then executed with its arguments (`*args` and `**kwargs`).\n",
    "    - If there's any exception, it's raised; otherwise, the function returns the output of `func`.\n",
    "    - Finally, if `log_enabled` is `True`, the duration of the function execution is calculated and logged.\n",
    "\n",
    "2. `run_notebook(func)`:\n",
    "\n",
    "    This is a decorator function that controls the display of the function it decorates based on the `show_notebook_results` flag.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    `func`: The function whose results are to be controlled.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - The `wrapper` function is defined to wrap around `func`.\n",
    "    - If `show_notebook_results` is `True`, the function is executed and its result is returned.\n",
    "    - If `show_notebook_results` is `False`, the function does not execute and no result is returned.\n",
    "\n",
    "3. `save_and_load_to_path(path)`:\n",
    "\n",
    "    This is a decorator factory that generates a decorator for saving the output of a function to a JSON file and loading it back the next time the function is called. \n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    `path`: The path where the JSON file is saved.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - A decorator `decorator(func)` is defined that takes a function `func` to be decorated.\n",
    "    - Inside this decorator, a `wrapper` function is defined to wrap around `func`.\n",
    "    - Initially, `save_data` is set to `True`.\n",
    "    - It then tries to open and load the JSON file at the given `path`. If it succeeds, it sets `save_data` to `False` and returns the loaded data.\n",
    "    - If it fails to load the data, it runs `func` and returns its output.\n",
    "    - If there's any exception, it's raised.\n",
    "    - Finally, if `save_data` is still `True` (meaning the function was run and its output wasn't already saved), it saves the output of `func` to the JSON file at `path`.\n",
    "    \n",
    "    Note: These decorators are higher-order function that use `functools.wraps()` to preserve the metadata of `func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dec(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            if log_enabled:\n",
    "                start_time = time()\n",
    "                log.info('{} started'.format(func.__name__))\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "        finally:\n",
    "            if log_enabled:\n",
    "                duration = time() - start_time\n",
    "                log.info('{} finished'.format(func.__name__))\n",
    "    return wrapper\n",
    "\n",
    "def run_notebook(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if show_notebook_results:\n",
    "            return func(*args, **kwargs)\n",
    "        else:\n",
    "            return\n",
    "    return wrapper\n",
    "\n",
    "def save_and_load_to_path(path):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            save_data = True\n",
    "            try:\n",
    "                try:\n",
    "                    with open(path, 'r') as file:\n",
    "                        save_data = False\n",
    "                        return json.load(file)\n",
    "                except:\n",
    "                    return func(*args, **kwargs)\n",
    "            except Exception as ex:\n",
    "                raise ex\n",
    "            finally:\n",
    "                if save_data:\n",
    "                    with open(path, 'w') as file:\n",
    "                        json.dump(func(*args, **kwargs), file)\n",
    "            return wrapper\n",
    "        return decorator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `read_in_text(file_path)`:\n",
    "\n",
    "    This function reads in a text file and returns its contents as a string. \n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    `file_path`: A string specifying the path to the text file.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - The function opens the file at `file_path` in read mode.\n",
    "    - It then reads the entire content of the file into a string.\n",
    "    - Finally, it returns this string.\n",
    "\n",
    "    Note: This function is decorated with `@log_dec`, which will log the start and end time of its execution if logging is enabled.\n",
    "\n",
    "2. `read_in_csv(file_path, data_range=None)`:\n",
    "\n",
    "    This function reads in a CSV file and returns its content as a string.\n",
    "    \n",
    "    Parameters:\n",
    "\n",
    "    `file_path`: A string specifying the path to the CSV file.\n",
    "    \n",
    "    `data_range` (optional): A range of column indices. If provided, only these columns will be included in the output string. Default is `None`, in which case all columns are included.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - The function opens the file at `file_path` in read mode.\n",
    "    - It then reads the content of the file into a CSV reader object, with a comma as the delimiter.\n",
    "    - The header row of the CSV file is skipped.\n",
    "    - If `data_range` is not `None`, it creates a string `merged_data` that contains only the columns specified by `data_range` from each row of the CSV file, with each column separated by a comma and each row separated by a newline.\n",
    "    - If `data_range` is `None`, it creates a string `merged_data` that contains all columns from each row of the CSV file, with each column separated by a comma and each row separated by a newline.\n",
    "    - Finally, it returns `merged_data`.\n",
    "\n",
    "    Note: This function is decorated with `@log_dec`, which will log the start and end time of its execution if logging is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@log_dec\n",
    "def read_in_text(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "    return data\n",
    "\n",
    "@log_dec\n",
    "def read_in_csv(file_path, data_range=None):\n",
    "    _line_delim = '\\n'\n",
    "    _clm_delim = ', '\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = csv.reader(file, delimiter=',')\n",
    "        next(data) # deletes the header row of the csv-file\n",
    "        if not data_range is None:\n",
    "            merged_data = _line_delim.join(_clm_delim.join(row[i] for i in data_range) for row in data)\n",
    "        else:\n",
    "            merged_data = _line_delim.join(_clm_delim.join(row) for row in data)\n",
    "    return merged_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset tokenization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `tokenize_children_stories()`:\n",
    "\n",
    "    This function reads in a text file containing children's stories, splits the text into paragraphs, and then tokenizes each paragraph into sentences. It returns a list of lists, where each inner list contains the sentences of a paragraph.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - The function reads in a text file using the `read_in_text()` function. The file path is 'datasets_raw_data\\\\children_stories_text_corpus\\\\cleaned_merged_fairy_tales_without_eos.txt'.\n",
    "    - It then splits the read text into paragraphs at double newline ('\\n\\n') characters.\n",
    "    - Next, it tokenizes each paragraph into sentences using the `sent_tokenize()` function from the NLTK library. This results in a list of lists, where each inner list contains the sentences of a paragraph.\n",
    "    - Finally, it returns this list of lists.\n",
    "\n",
    "2. `tokenize_poe_short_stories()`:\n",
    "\n",
    "    This function reads in a CSV file containing short stories by Edgar Allan Poe, splits the text into paragraphs, and then tokenizes each paragraph into sentences. It returns a list of lists, where each inner list contains the sentences of a paragraph.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - The function reads in a CSV file using the `read_in_csv()` function. The file path is 'datasets_raw_data\\\\poe_short_stories\\\\preprocessed_data.csv', and the `data_range` parameter is set to `[1]`, meaning that only the second column of the CSV file will be read in.\n",
    "    - It then splits the read text into paragraphs at newline ('\\n') characters.\n",
    "    - Next, it tokenizes each paragraph into sentences using the `sent_tokenize()` function from the NLTK library. This results in a list of lists, where each inner list contains the sentences of a paragraph.\n",
    "    - Finally, it returns this list of lists.\n",
    "\n",
    "    Here's the documentation for these functions:\n",
    "\n",
    "3. `tokenize_reddit_short_stories()`:\n",
    "\n",
    "    This function reads a text file containing popular Reddit short stories, cleans the data by removing specific tags (`<sos>`, `<eos>`, `<nl>`), and then tokenizes the data into sentences.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - It reads the text file using `read_in_text()` function from the specified path.\n",
    "    - It removes the specific tags from the data using `re.sub()`.\n",
    "    - It splits the cleaned data into paragraphs at double newline (`\\n\\n`) characters.\n",
    "    - It tokenizes each paragraph into sentences using `sent_tokenize()` function, resulting in a list of lists, where each inner list contains the sentences of a paragraph.\n",
    "    - Finally, it returns this list of lists.\n",
    "\n",
    "    Note: This function is decorated with `@run_notebook` and `@log_dec`, implying that its execution can be toggled and its execution time will be logged if logging is enabled.\n",
    "\n",
    "4. `tokenize_single_file_sherlock_holmes(file)`:\n",
    "\n",
    "    This function reads a single text file of Sherlock Holmes stories, cleans the data by removing newline characters and extra white spaces, then tokenizes the data into sentences.\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    `file`: The path of the text file to be read and tokenized.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - It reads the text file using `read_in_text()` function from the specified path.\n",
    "    - It removes newline characters and extra white spaces from the data using `re.sub()`.\n",
    "    - It splits the cleaned data at `---` characters and takes the first part.\n",
    "    - It tokenizes the cleaned data into sentences using `sent_tokenize()` function.\n",
    "    - Finally, it returns the list of tokenized sentences.\n",
    "\n",
    "    Note: This function is decorated with `@log_dec`, meaning that its execution time will be logged if logging is enabled.\n",
    "\n",
    "5. `tokenize_sherlock_holmes()`:\n",
    "\n",
    "    This function reads and tokenizes all the text files in the Sherlock Holmes dataset directory.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - It iterates over all the files in the 'datasets_raw_data\\\\sherlock_holmes' directory.\n",
    "    - For each file, it applies the `tokenize_single_file_sherlock_holmes()` function, which returns a list of tokenized sentences.\n",
    "    - Finally, it returns a list of these lists.\n",
    "\n",
    "    Note: This function is decorated with `@run_notebook` and `@log_dec`, meaning that its execution can be toggled and its execution time will be logged if logging is enabled.\n",
    "\n",
    "6. `tokenize_all()`:\n",
    "\n",
    "    This function tokenizes all the stories from different sources (children stories, Poe short stories, Reddit short stories, Sherlock Holmes stories), and writes the tokenized stories into a text file.\n",
    "\n",
    "    How it works:\n",
    "\n",
    "    - It calls the functions `tokenize_children_stories()`, `tokenize_poe_short_stories()`, `tokenize_reddit_short_stories()`, and `tokenize_sherlock_holmes()`.\n",
    "    - It concatenates all the tokenized stories into one list.\n",
    "    - It writes the concatenated list into a text file at 'datasets\\\\corpus.txt'.\n",
    "    - Finally, it returns the text data that was written into the file.\n",
    "\n",
    "    Note: This function is decorated with `@log_dec`, meaning that its execution time will be logged if logging is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@run_notebook\n",
    "@log_dec\n",
    "def tokenize_children_stories():\n",
    "    data = read_in_text('datasets_raw_data\\\\children_stories_text_corpus\\\\cleaned_merged_fairy_tales_without_eos.txt')\n",
    "    data_split = list(map(lambda text: sent_tokenize(text), data.split(sep='\\n\\n')))\n",
    "    return data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@run_notebook\n",
    "@log_dec\n",
    "def tokenize_poe_short_stories():\n",
    "    data = read_in_csv('datasets_raw_data\\\\poe_short_stories\\\\preprocessed_data.csv', data_range=[1])\n",
    "    data_split = list(map(lambda text: sent_tokenize(text), data.split(sep='\\n')))\n",
    "    return data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@run_notebook\n",
    "@log_dec\n",
    "def tokenize_reddit_short_stories():\n",
    "    data = read_in_text('datasets_raw_data\\\\popular_reddit_short_stories\\\\reddit_short_stories.txt')\n",
    "    data_strip = re.sub(r'\\<sos\\>|\\<eos\\>|\\<nl\\>', '', data)\n",
    "    data_split = list(map(lambda text: sent_tokenize(text), data_strip.split(sep='\\n\\n')))\n",
    "    return data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_dec\n",
    "def tokenize_single_file_sherlock_holmes(file):\n",
    "    data =              read_in_text(file)\n",
    "    data_strip =        re.sub(r'\\n|\\s{2,}', ' ', data)\n",
    "    data_strip_end =    re.split(r'---', data_strip)[0]\n",
    "    data_split =        sent_tokenize(data_strip_end)\n",
    "    return data_split\n",
    "\n",
    "@run_notebook\n",
    "@log_dec\n",
    "def tokenize_sherlock_holmes():\n",
    "    data = [tokenize_single_file_sherlock_holmes('datasets_raw_data\\\\sherlock_holmes' + '\\\\' + file)\n",
    "            for file in os.listdir('datasets_raw_data\\\\sherlock_holmes')]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_dec\n",
    "def tokenize_all():\n",
    "    story_delim = '\\n\\n'\n",
    "    sentence_delim = '\\n'\n",
    "    func_list = [\n",
    "        tokenize_children_stories(),\n",
    "        tokenize_poe_short_stories(),\n",
    "        tokenize_reddit_short_stories(),\n",
    "        tokenize_sherlock_holmes(),\n",
    "    ]\n",
    "    corpus = [story for collection in func_list for story in collection]\n",
    "    with open('datasets\\\\corpus.txt', 'w') as file:\n",
    "        #json.dump(corpus, file)\n",
    "        text_data = story_delim.join(list(map(lambda text_list: sentence_delim.join(text_list),corpus)))\n",
    "        file.write(text_data)\n",
    "    return text_data\n",
    "\n",
    "tokenize_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scifi Stories Text Corpus\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really big corpus, don't use for now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Works of Charles Dickens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This dataset is really messy.\n",
    "* Leave for later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bookcorpusopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bco_dataset_generator():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bco_file_path = \"datasets_raw_data\\\\books1\\\\epubtxt\"\n",
    "\n",
    "    def txt_files_to_lines_gen(self):\n",
    "        for file in os.listdir(self.bco_file_path):\n",
    "            with open(os.path.join(self.bco_file_path, file), 'r') as f:\n",
    "                for line in f:\n",
    "                    yield line.strip()\n",
    "\n",
    "    def lines_to_fit_sentences(self, sentences, length):\n",
    "        length = length / 1.5 # estimate of token/word ratio (in real the value is about 1.4)\n",
    "\n",
    "        current_combined_sentence = \"\"\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()  # Remove leading/trailing whitespace\n",
    "            sentence_words = sentence.split()\n",
    "\n",
    "            # Check if combining the current sentence with the previous one exceeds the word limit\n",
    "            if len(current_combined_sentence.split()) + len(sentence_words) > length:\n",
    "                yield current_combined_sentence\n",
    "                current_combined_sentence = sentence  # Start a new combined sentence\n",
    "            else:\n",
    "                current_combined_sentence += \" \" + sentence  # Concatenate the sentences\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        lines_gen = self.txt_files_to_lines_gen()\n",
    "        fit_sentence_gen = self.lines_to_fit_sentences(lines_gen, 512)\n",
    "        dataset = tf.data.Dataset.from_generator(lambda: fit_sentence_gen, \n",
    "                                                 output_signature=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "        return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUT_OFF_LINE = 10000\n",
    "\n",
    "def txt_files_to_lines_gen(file_path):\n",
    "    \"\"\"\n",
    "    Generator function that yields lines from text files in a directory.\n",
    "\n",
    "    Args:\n",
    "        file_path (str):    Path to the directory containing the text files.\n",
    "\n",
    "    Yields:\n",
    "        str:                A line from a text file.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    path = pathlib.Path(file_path)\n",
    "\n",
    "    for file in path.iterdir():\n",
    "        if file.is_file():\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    yield line.strip()\n",
    "\n",
    "def lines_to_fit_sentences(sentences, length):\n",
    "        \"\"\"\n",
    "        Generator function that combines sentences so that the combined sentence is close to a certain length.\n",
    "        \n",
    "        Args:\n",
    "            sentences (iterator):   An iterator that yields sentences.\n",
    "            length (int):           The maximum length for combined sentences.\n",
    "            \n",
    "        Yields:\n",
    "            str:                    A combined sentence.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        length = length / 1.5 # estimate of token/word ratio (in real the value is about 1.4)\n",
    "\n",
    "        current_combined_sentence = \"\"\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()  # Remove leading/trailing whitespace\n",
    "            sentence_words = sentence.split()\n",
    "\n",
    "            # Check if combining the current sentence with the previous one exceeds the word limit\n",
    "            if len(current_combined_sentence.split()) + len(sentence_words) > length:\n",
    "                yield current_combined_sentence\n",
    "                current_combined_sentence = sentence  # Start a new combined sentence\n",
    "            else:\n",
    "                current_combined_sentence += \" \" + sentence  # Concatenate the sentences\n",
    "\n",
    "def process_and_save_txt_files(input_path, output_path, sentence_length, cutoff_line):\n",
    "    \"\"\"\n",
    "    Loads all text files from a directory, processes them into fitting sentences,\n",
    "    and saves them into multiple text files.\n",
    "\n",
    "    Args:\n",
    "        input_path (str):      The path to the directory with the text files to process.\n",
    "        output_path (str):     The path where the processed text files will be saved.\n",
    "        sentence_length (int): The maximum length for the processed sentences.\n",
    "        cutoff_line (int):     The number of sentences per output file.\n",
    "    \"\"\"\n",
    "    log.debug(f'Start processing text files from {input_path} into sentences of length {sentence_length}.')\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = pathlib.Path(output_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate lines from all text files in the directory\n",
    "    lines = txt_files_to_lines_gen(input_path)\n",
    "\n",
    "    # Combine lines into sentences of fitting length\n",
    "    sentences = lines_to_fit_sentences(lines, sentence_length)\n",
    "\n",
    "    # Prepare to count sentences\n",
    "    count = 0\n",
    "\n",
    "    # Prepare to count files\n",
    "    file_count = 0\n",
    "\n",
    "    # Prepare to write to an output file\n",
    "    f = open(os.path.join(output_path, f'output_{file_count}.txt'), 'w')\n",
    "\n",
    "    try:\n",
    "        # Iterate over the sentences generator\n",
    "        for sentence in sentences:\n",
    "            # Write the sentence to the file\n",
    "            f.write(sentence + '\\n')\n",
    "\n",
    "            # Increase the count of sentences\n",
    "            count += 1\n",
    "\n",
    "            # If we have reached the cutoff line, start a new output file\n",
    "            if count >= cutoff_line:\n",
    "                log.debug(f'Saved {cutoff_line} sentences into file {file_count}.txt.')\n",
    "\n",
    "                # Close the current file\n",
    "                f.close()\n",
    "\n",
    "                # Reset the sentence count\n",
    "                count = 0\n",
    "\n",
    "                # Increase the file count\n",
    "                file_count += 1\n",
    "\n",
    "                # Open a new file for writing\n",
    "                f = open(os.path.join(output_path, f'output_{file_count}.txt'), 'w')\n",
    "    finally:\n",
    "        # Make sure the last file gets closed\n",
    "        f.close()\n",
    "\n",
    "    log.info(f'Finished processing text files. Generated {file_count} output files.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 00:27:13 DEBUG    Start processing text files from datasets\\bookscorpusopen\\epubtxt into sentences of length 512.\n",
      "2023-06-06 00:27:13 DEBUG    execute\n",
      "2023-06-06 00:27:13 DEBUG    execute\n",
      "2023-06-06 00:27:16 DEBUG    Saved 10000 sentences into file 0.txt.\n",
      "2023-06-06 00:27:21 DEBUG    Saved 10000 sentences into file 1.txt.\n",
      "2023-06-06 00:27:24 DEBUG    Saved 10000 sentences into file 2.txt.\n",
      "2023-06-06 00:27:27 DEBUG    Saved 10000 sentences into file 3.txt.\n",
      "2023-06-06 00:27:29 DEBUG    Saved 10000 sentences into file 4.txt.\n",
      "2023-06-06 00:27:32 DEBUG    Saved 10000 sentences into file 5.txt.\n",
      "2023-06-06 00:27:34 DEBUG    Saved 10000 sentences into file 6.txt.\n",
      "2023-06-06 00:27:37 DEBUG    Saved 10000 sentences into file 7.txt.\n",
      "2023-06-06 00:27:40 DEBUG    Saved 10000 sentences into file 8.txt.\n",
      "2023-06-06 00:27:43 DEBUG    Saved 10000 sentences into file 9.txt.\n",
      "2023-06-06 00:27:45 DEBUG    Saved 10000 sentences into file 10.txt.\n",
      "2023-06-06 00:27:48 DEBUG    Saved 10000 sentences into file 11.txt.\n",
      "2023-06-06 00:27:50 DEBUG    Saved 10000 sentences into file 12.txt.\n",
      "2023-06-06 00:27:52 DEBUG    Saved 10000 sentences into file 13.txt.\n",
      "2023-06-06 00:27:55 DEBUG    Saved 10000 sentences into file 14.txt.\n",
      "2023-06-06 00:27:57 DEBUG    Saved 10000 sentences into file 15.txt.\n",
      "2023-06-06 00:28:00 DEBUG    Saved 10000 sentences into file 16.txt.\n",
      "2023-06-06 00:28:02 DEBUG    Saved 10000 sentences into file 17.txt.\n",
      "2023-06-06 00:28:03 DEBUG    Saved 10000 sentences into file 18.txt.\n",
      "2023-06-06 00:28:05 DEBUG    Saved 10000 sentences into file 19.txt.\n",
      "2023-06-06 00:28:07 DEBUG    Saved 10000 sentences into file 20.txt.\n",
      "2023-06-06 00:28:09 DEBUG    Saved 10000 sentences into file 21.txt.\n",
      "2023-06-06 00:28:12 DEBUG    Saved 10000 sentences into file 22.txt.\n",
      "2023-06-06 00:28:16 DEBUG    Saved 10000 sentences into file 23.txt.\n",
      "2023-06-06 00:28:19 DEBUG    Saved 10000 sentences into file 24.txt.\n",
      "2023-06-06 00:28:21 DEBUG    Saved 10000 sentences into file 25.txt.\n",
      "2023-06-06 00:28:24 DEBUG    Saved 10000 sentences into file 26.txt.\n",
      "2023-06-06 00:28:26 DEBUG    Saved 10000 sentences into file 27.txt.\n",
      "2023-06-06 00:28:29 DEBUG    Saved 10000 sentences into file 28.txt.\n",
      "2023-06-06 00:28:31 DEBUG    Saved 10000 sentences into file 29.txt.\n",
      "2023-06-06 00:28:33 DEBUG    Saved 10000 sentences into file 30.txt.\n",
      "2023-06-06 00:28:36 DEBUG    Saved 10000 sentences into file 31.txt.\n",
      "2023-06-06 00:28:39 DEBUG    Saved 10000 sentences into file 32.txt.\n",
      "2023-06-06 00:28:41 DEBUG    Saved 10000 sentences into file 33.txt.\n",
      "2023-06-06 00:28:44 DEBUG    Saved 10000 sentences into file 34.txt.\n",
      "2023-06-06 00:28:47 DEBUG    Saved 10000 sentences into file 35.txt.\n",
      "2023-06-06 00:28:49 DEBUG    Saved 10000 sentences into file 36.txt.\n",
      "2023-06-06 00:28:52 DEBUG    Saved 10000 sentences into file 37.txt.\n",
      "2023-06-06 00:28:54 DEBUG    Saved 10000 sentences into file 38.txt.\n",
      "2023-06-06 00:28:57 DEBUG    Saved 10000 sentences into file 39.txt.\n",
      "2023-06-06 00:28:59 DEBUG    Saved 10000 sentences into file 40.txt.\n",
      "2023-06-06 00:29:02 DEBUG    Saved 10000 sentences into file 41.txt.\n",
      "2023-06-06 00:29:04 DEBUG    Saved 10000 sentences into file 42.txt.\n",
      "2023-06-06 00:29:06 DEBUG    Saved 10000 sentences into file 43.txt.\n",
      "2023-06-06 00:29:09 DEBUG    Saved 10000 sentences into file 44.txt.\n",
      "2023-06-06 00:29:12 DEBUG    Saved 10000 sentences into file 45.txt.\n",
      "2023-06-06 00:29:16 DEBUG    Saved 10000 sentences into file 46.txt.\n",
      "2023-06-06 00:29:18 DEBUG    Saved 10000 sentences into file 47.txt.\n",
      "2023-06-06 00:29:21 DEBUG    Saved 10000 sentences into file 48.txt.\n",
      "2023-06-06 00:29:24 DEBUG    Saved 10000 sentences into file 49.txt.\n",
      "2023-06-06 00:29:26 DEBUG    Saved 10000 sentences into file 50.txt.\n",
      "2023-06-06 00:29:29 DEBUG    Saved 10000 sentences into file 51.txt.\n",
      "2023-06-06 00:29:31 DEBUG    Saved 10000 sentences into file 52.txt.\n",
      "2023-06-06 00:29:34 DEBUG    Saved 10000 sentences into file 53.txt.\n",
      "2023-06-06 00:29:37 DEBUG    Saved 10000 sentences into file 54.txt.\n",
      "2023-06-06 00:29:40 DEBUG    Saved 10000 sentences into file 55.txt.\n",
      "2023-06-06 00:29:42 DEBUG    Saved 10000 sentences into file 56.txt.\n",
      "2023-06-06 00:29:45 DEBUG    Saved 10000 sentences into file 57.txt.\n",
      "2023-06-06 00:29:48 DEBUG    Saved 10000 sentences into file 58.txt.\n",
      "2023-06-06 00:29:51 DEBUG    Saved 10000 sentences into file 59.txt.\n",
      "2023-06-06 00:29:54 DEBUG    Saved 10000 sentences into file 60.txt.\n",
      "2023-06-06 00:29:57 DEBUG    Saved 10000 sentences into file 61.txt.\n",
      "2023-06-06 00:30:00 DEBUG    Saved 10000 sentences into file 62.txt.\n",
      "2023-06-06 00:30:03 DEBUG    Saved 10000 sentences into file 63.txt.\n",
      "2023-06-06 00:30:06 DEBUG    Saved 10000 sentences into file 64.txt.\n",
      "2023-06-06 00:30:09 DEBUG    Saved 10000 sentences into file 65.txt.\n",
      "2023-06-06 00:30:12 DEBUG    Saved 10000 sentences into file 66.txt.\n",
      "2023-06-06 00:30:16 DEBUG    Saved 10000 sentences into file 67.txt.\n",
      "2023-06-06 00:30:19 DEBUG    Saved 10000 sentences into file 68.txt.\n",
      "2023-06-06 00:30:22 DEBUG    Saved 10000 sentences into file 69.txt.\n",
      "2023-06-06 00:30:24 DEBUG    Saved 10000 sentences into file 70.txt.\n",
      "2023-06-06 00:30:28 DEBUG    Saved 10000 sentences into file 71.txt.\n",
      "2023-06-06 00:30:32 DEBUG    Saved 10000 sentences into file 72.txt.\n",
      "2023-06-06 00:30:35 DEBUG    Saved 10000 sentences into file 73.txt.\n",
      "2023-06-06 00:30:38 DEBUG    Saved 10000 sentences into file 74.txt.\n",
      "2023-06-06 00:30:41 DEBUG    Saved 10000 sentences into file 75.txt.\n",
      "2023-06-06 00:30:44 DEBUG    Saved 10000 sentences into file 76.txt.\n",
      "2023-06-06 00:30:47 DEBUG    Saved 10000 sentences into file 77.txt.\n",
      "2023-06-06 00:30:50 DEBUG    Saved 10000 sentences into file 78.txt.\n",
      "2023-06-06 00:30:53 DEBUG    Saved 10000 sentences into file 79.txt.\n",
      "2023-06-06 00:30:57 DEBUG    Saved 10000 sentences into file 80.txt.\n",
      "2023-06-06 00:31:00 DEBUG    Saved 10000 sentences into file 81.txt.\n",
      "2023-06-06 00:31:05 DEBUG    Saved 10000 sentences into file 82.txt.\n",
      "2023-06-06 00:31:09 DEBUG    Saved 10000 sentences into file 83.txt.\n",
      "2023-06-06 00:31:12 DEBUG    Saved 10000 sentences into file 84.txt.\n",
      "2023-06-06 00:31:15 DEBUG    Saved 10000 sentences into file 85.txt.\n",
      "2023-06-06 00:31:18 DEBUG    Saved 10000 sentences into file 86.txt.\n",
      "2023-06-06 00:31:22 DEBUG    Saved 10000 sentences into file 87.txt.\n",
      "2023-06-06 00:31:25 DEBUG    Saved 10000 sentences into file 88.txt.\n",
      "2023-06-06 00:31:28 DEBUG    Saved 10000 sentences into file 89.txt.\n",
      "2023-06-06 00:31:31 DEBUG    Saved 10000 sentences into file 90.txt.\n",
      "2023-06-06 00:31:34 DEBUG    Saved 10000 sentences into file 91.txt.\n",
      "2023-06-06 00:31:37 DEBUG    Saved 10000 sentences into file 92.txt.\n",
      "2023-06-06 00:31:40 DEBUG    Saved 10000 sentences into file 93.txt.\n",
      "2023-06-06 00:31:44 DEBUG    Saved 10000 sentences into file 94.txt.\n",
      "2023-06-06 00:31:47 DEBUG    Saved 10000 sentences into file 95.txt.\n",
      "2023-06-06 00:31:50 DEBUG    Saved 10000 sentences into file 96.txt.\n",
      "2023-06-06 00:31:53 DEBUG    Saved 10000 sentences into file 97.txt.\n",
      "2023-06-06 00:31:56 DEBUG    Saved 10000 sentences into file 98.txt.\n",
      "2023-06-06 00:32:00 DEBUG    Saved 10000 sentences into file 99.txt.\n",
      "2023-06-06 00:32:03 DEBUG    Saved 10000 sentences into file 100.txt.\n",
      "2023-06-06 00:32:06 DEBUG    Saved 10000 sentences into file 101.txt.\n",
      "2023-06-06 00:32:09 DEBUG    Saved 10000 sentences into file 102.txt.\n",
      "2023-06-06 00:32:12 DEBUG    Saved 10000 sentences into file 103.txt.\n",
      "2023-06-06 00:32:14 DEBUG    Saved 10000 sentences into file 104.txt.\n",
      "2023-06-06 00:32:17 DEBUG    Saved 10000 sentences into file 105.txt.\n",
      "2023-06-06 00:32:20 DEBUG    Saved 10000 sentences into file 106.txt.\n",
      "2023-06-06 00:32:24 DEBUG    Saved 10000 sentences into file 107.txt.\n",
      "2023-06-06 00:32:27 DEBUG    Saved 10000 sentences into file 108.txt.\n",
      "2023-06-06 00:32:30 DEBUG    Saved 10000 sentences into file 109.txt.\n",
      "2023-06-06 00:32:33 DEBUG    Saved 10000 sentences into file 110.txt.\n",
      "2023-06-06 00:32:36 DEBUG    Saved 10000 sentences into file 111.txt.\n",
      "2023-06-06 00:32:39 DEBUG    Saved 10000 sentences into file 112.txt.\n",
      "2023-06-06 00:32:47 DEBUG    Saved 10000 sentences into file 113.txt.\n",
      "2023-06-06 00:32:54 DEBUG    Saved 10000 sentences into file 114.txt.\n",
      "2023-06-06 00:32:57 DEBUG    Saved 10000 sentences into file 115.txt.\n",
      "2023-06-06 00:33:00 DEBUG    Saved 10000 sentences into file 116.txt.\n",
      "2023-06-06 00:33:03 DEBUG    Saved 10000 sentences into file 117.txt.\n",
      "2023-06-06 00:33:07 DEBUG    Saved 10000 sentences into file 118.txt.\n",
      "2023-06-06 00:33:09 DEBUG    Saved 10000 sentences into file 119.txt.\n",
      "2023-06-06 00:33:12 DEBUG    Saved 10000 sentences into file 120.txt.\n",
      "2023-06-06 00:33:16 DEBUG    Saved 10000 sentences into file 121.txt.\n",
      "2023-06-06 00:33:19 DEBUG    Saved 10000 sentences into file 122.txt.\n",
      "2023-06-06 00:33:22 DEBUG    Saved 10000 sentences into file 123.txt.\n",
      "2023-06-06 00:33:25 DEBUG    Saved 10000 sentences into file 124.txt.\n",
      "2023-06-06 00:33:28 DEBUG    Saved 10000 sentences into file 125.txt.\n",
      "2023-06-06 00:33:31 DEBUG    Saved 10000 sentences into file 126.txt.\n",
      "2023-06-06 00:33:34 DEBUG    Saved 10000 sentences into file 127.txt.\n",
      "2023-06-06 00:33:38 DEBUG    Saved 10000 sentences into file 128.txt.\n",
      "2023-06-06 00:33:41 DEBUG    Saved 10000 sentences into file 129.txt.\n",
      "2023-06-06 00:33:44 DEBUG    Saved 10000 sentences into file 130.txt.\n",
      "2023-06-06 00:33:48 DEBUG    Saved 10000 sentences into file 131.txt.\n",
      "2023-06-06 00:33:51 DEBUG    Saved 10000 sentences into file 132.txt.\n",
      "2023-06-06 00:33:54 DEBUG    Saved 10000 sentences into file 133.txt.\n",
      "2023-06-06 00:33:56 DEBUG    Saved 10000 sentences into file 134.txt.\n",
      "2023-06-06 00:33:59 DEBUG    Saved 10000 sentences into file 135.txt.\n",
      "2023-06-06 00:34:02 DEBUG    Saved 10000 sentences into file 136.txt.\n",
      "2023-06-06 00:34:06 DEBUG    Saved 10000 sentences into file 137.txt.\n",
      "2023-06-06 00:34:09 DEBUG    Saved 10000 sentences into file 138.txt.\n",
      "2023-06-06 00:34:12 DEBUG    Saved 10000 sentences into file 139.txt.\n",
      "2023-06-06 00:34:15 DEBUG    Saved 10000 sentences into file 140.txt.\n",
      "2023-06-06 00:34:17 DEBUG    Saved 10000 sentences into file 141.txt.\n",
      "2023-06-06 00:34:21 DEBUG    Saved 10000 sentences into file 142.txt.\n",
      "2023-06-06 00:34:23 DEBUG    Saved 10000 sentences into file 143.txt.\n",
      "2023-06-06 00:34:27 DEBUG    Saved 10000 sentences into file 144.txt.\n",
      "2023-06-06 00:34:30 DEBUG    Saved 10000 sentences into file 145.txt.\n",
      "2023-06-06 00:34:34 DEBUG    Saved 10000 sentences into file 146.txt.\n",
      "2023-06-06 00:34:37 DEBUG    Saved 10000 sentences into file 147.txt.\n",
      "2023-06-06 00:34:40 DEBUG    Saved 10000 sentences into file 148.txt.\n",
      "2023-06-06 00:34:44 DEBUG    Saved 10000 sentences into file 149.txt.\n",
      "2023-06-06 00:34:47 DEBUG    Saved 10000 sentences into file 150.txt.\n",
      "2023-06-06 00:34:50 DEBUG    Saved 10000 sentences into file 151.txt.\n",
      "2023-06-06 00:34:53 DEBUG    Saved 10000 sentences into file 152.txt.\n",
      "2023-06-06 00:34:57 DEBUG    Saved 10000 sentences into file 153.txt.\n",
      "2023-06-06 00:35:00 DEBUG    Saved 10000 sentences into file 154.txt.\n",
      "2023-06-06 00:35:03 DEBUG    Saved 10000 sentences into file 155.txt.\n",
      "2023-06-06 00:35:06 DEBUG    Saved 10000 sentences into file 156.txt.\n",
      "2023-06-06 00:35:09 DEBUG    Saved 10000 sentences into file 157.txt.\n",
      "2023-06-06 00:35:12 DEBUG    Saved 10000 sentences into file 158.txt.\n",
      "2023-06-06 00:35:15 DEBUG    Saved 10000 sentences into file 159.txt.\n",
      "2023-06-06 00:35:19 DEBUG    Saved 10000 sentences into file 160.txt.\n",
      "2023-06-06 00:35:22 DEBUG    Saved 10000 sentences into file 161.txt.\n",
      "2023-06-06 00:35:25 DEBUG    Saved 10000 sentences into file 162.txt.\n",
      "2023-06-06 00:35:28 DEBUG    Saved 10000 sentences into file 163.txt.\n",
      "2023-06-06 00:35:32 DEBUG    Saved 10000 sentences into file 164.txt.\n",
      "2023-06-06 00:35:35 DEBUG    Saved 10000 sentences into file 165.txt.\n",
      "2023-06-06 00:35:38 DEBUG    Saved 10000 sentences into file 166.txt.\n",
      "2023-06-06 00:35:41 DEBUG    Saved 10000 sentences into file 167.txt.\n",
      "2023-06-06 00:35:45 DEBUG    Saved 10000 sentences into file 168.txt.\n",
      "2023-06-06 00:35:48 DEBUG    Saved 10000 sentences into file 169.txt.\n",
      "2023-06-06 00:35:51 DEBUG    Saved 10000 sentences into file 170.txt.\n",
      "2023-06-06 00:35:54 DEBUG    Saved 10000 sentences into file 171.txt.\n",
      "2023-06-06 00:35:57 DEBUG    Saved 10000 sentences into file 172.txt.\n",
      "2023-06-06 00:36:00 DEBUG    Saved 10000 sentences into file 173.txt.\n",
      "2023-06-06 00:36:03 DEBUG    Saved 10000 sentences into file 174.txt.\n",
      "2023-06-06 00:36:07 DEBUG    Saved 10000 sentences into file 175.txt.\n",
      "2023-06-06 00:36:10 DEBUG    Saved 10000 sentences into file 176.txt.\n",
      "2023-06-06 00:36:14 DEBUG    Saved 10000 sentences into file 177.txt.\n",
      "2023-06-06 00:36:17 DEBUG    Saved 10000 sentences into file 178.txt.\n",
      "2023-06-06 00:36:21 DEBUG    Saved 10000 sentences into file 179.txt.\n",
      "2023-06-06 00:36:24 DEBUG    Saved 10000 sentences into file 180.txt.\n",
      "2023-06-06 00:36:27 DEBUG    Saved 10000 sentences into file 181.txt.\n",
      "2023-06-06 00:36:31 DEBUG    Saved 10000 sentences into file 182.txt.\n",
      "2023-06-06 00:36:34 DEBUG    Saved 10000 sentences into file 183.txt.\n",
      "2023-06-06 00:36:37 DEBUG    Saved 10000 sentences into file 184.txt.\n",
      "2023-06-06 00:36:40 DEBUG    Saved 10000 sentences into file 185.txt.\n",
      "2023-06-06 00:36:43 DEBUG    Saved 10000 sentences into file 186.txt.\n",
      "2023-06-06 00:36:47 DEBUG    Saved 10000 sentences into file 187.txt.\n",
      "2023-06-06 00:36:50 DEBUG    Saved 10000 sentences into file 188.txt.\n",
      "2023-06-06 00:36:53 DEBUG    Saved 10000 sentences into file 189.txt.\n",
      "2023-06-06 00:36:56 DEBUG    Saved 10000 sentences into file 190.txt.\n",
      "2023-06-06 00:37:00 DEBUG    Saved 10000 sentences into file 191.txt.\n",
      "2023-06-06 00:37:03 DEBUG    Saved 10000 sentences into file 192.txt.\n",
      "2023-06-06 00:37:06 DEBUG    Saved 10000 sentences into file 193.txt.\n",
      "2023-06-06 00:37:10 DEBUG    Saved 10000 sentences into file 194.txt.\n",
      "2023-06-06 00:37:14 DEBUG    Saved 10000 sentences into file 195.txt.\n",
      "2023-06-06 00:37:17 DEBUG    Saved 10000 sentences into file 196.txt.\n",
      "2023-06-06 00:37:20 DEBUG    Saved 10000 sentences into file 197.txt.\n",
      "2023-06-06 00:37:24 DEBUG    Saved 10000 sentences into file 198.txt.\n",
      "2023-06-06 00:37:26 DEBUG    Saved 10000 sentences into file 199.txt.\n",
      "2023-06-06 00:37:30 DEBUG    Saved 10000 sentences into file 200.txt.\n",
      "2023-06-06 00:37:33 DEBUG    Saved 10000 sentences into file 201.txt.\n",
      "2023-06-06 00:37:36 DEBUG    Saved 10000 sentences into file 202.txt.\n",
      "2023-06-06 00:37:39 DEBUG    Saved 10000 sentences into file 203.txt.\n",
      "2023-06-06 00:37:42 DEBUG    Saved 10000 sentences into file 204.txt.\n",
      "2023-06-06 00:37:45 DEBUG    Saved 10000 sentences into file 205.txt.\n",
      "2023-06-06 00:37:49 DEBUG    Saved 10000 sentences into file 206.txt.\n",
      "2023-06-06 00:37:53 DEBUG    Saved 10000 sentences into file 207.txt.\n",
      "2023-06-06 00:37:56 DEBUG    Saved 10000 sentences into file 208.txt.\n",
      "2023-06-06 00:37:59 DEBUG    Saved 10000 sentences into file 209.txt.\n",
      "2023-06-06 00:38:02 DEBUG    Saved 10000 sentences into file 210.txt.\n",
      "2023-06-06 00:38:05 DEBUG    Saved 10000 sentences into file 211.txt.\n",
      "2023-06-06 00:38:09 DEBUG    Saved 10000 sentences into file 212.txt.\n",
      "2023-06-06 00:38:12 DEBUG    Saved 10000 sentences into file 213.txt.\n",
      "2023-06-06 00:38:16 DEBUG    Saved 10000 sentences into file 214.txt.\n",
      "2023-06-06 00:38:18 DEBUG    Saved 10000 sentences into file 215.txt.\n",
      "2023-06-06 00:38:21 DEBUG    Saved 10000 sentences into file 216.txt.\n",
      "2023-06-06 00:38:25 DEBUG    Saved 10000 sentences into file 217.txt.\n",
      "2023-06-06 00:38:28 DEBUG    Saved 10000 sentences into file 218.txt.\n",
      "2023-06-06 00:38:32 DEBUG    Saved 10000 sentences into file 219.txt.\n",
      "2023-06-06 00:38:35 DEBUG    Saved 10000 sentences into file 220.txt.\n",
      "2023-06-06 00:38:38 DEBUG    Saved 10000 sentences into file 221.txt.\n",
      "2023-06-06 00:38:42 DEBUG    Saved 10000 sentences into file 222.txt.\n",
      "2023-06-06 00:38:46 DEBUG    Saved 10000 sentences into file 223.txt.\n",
      "2023-06-06 00:38:49 DEBUG    Saved 10000 sentences into file 224.txt.\n",
      "2023-06-06 00:38:52 DEBUG    Saved 10000 sentences into file 225.txt.\n",
      "2023-06-06 00:38:55 DEBUG    Saved 10000 sentences into file 226.txt.\n",
      "2023-06-06 00:38:58 DEBUG    Saved 10000 sentences into file 227.txt.\n",
      "2023-06-06 00:39:01 DEBUG    Saved 10000 sentences into file 228.txt.\n",
      "2023-06-06 00:39:04 DEBUG    Saved 10000 sentences into file 229.txt.\n",
      "2023-06-06 00:39:08 DEBUG    Saved 10000 sentences into file 230.txt.\n",
      "2023-06-06 00:39:10 DEBUG    Saved 10000 sentences into file 231.txt.\n",
      "2023-06-06 00:39:14 DEBUG    Saved 10000 sentences into file 232.txt.\n",
      "2023-06-06 00:39:18 DEBUG    Saved 10000 sentences into file 233.txt.\n",
      "2023-06-06 00:39:21 DEBUG    Saved 10000 sentences into file 234.txt.\n",
      "2023-06-06 00:39:24 DEBUG    Saved 10000 sentences into file 235.txt.\n",
      "2023-06-06 00:39:28 DEBUG    Saved 10000 sentences into file 236.txt.\n",
      "2023-06-06 00:39:31 DEBUG    Saved 10000 sentences into file 237.txt.\n",
      "2023-06-06 00:39:34 DEBUG    Saved 10000 sentences into file 238.txt.\n",
      "2023-06-06 00:39:37 DEBUG    Saved 10000 sentences into file 239.txt.\n",
      "2023-06-06 00:39:41 DEBUG    Saved 10000 sentences into file 240.txt.\n",
      "2023-06-06 00:39:44 DEBUG    Saved 10000 sentences into file 241.txt.\n",
      "2023-06-06 00:39:47 DEBUG    Saved 10000 sentences into file 242.txt.\n",
      "2023-06-06 00:39:52 DEBUG    Saved 10000 sentences into file 243.txt.\n",
      "2023-06-06 00:39:55 DEBUG    Saved 10000 sentences into file 244.txt.\n",
      "2023-06-06 00:39:58 DEBUG    Saved 10000 sentences into file 245.txt.\n",
      "2023-06-06 00:40:02 DEBUG    Saved 10000 sentences into file 246.txt.\n",
      "2023-06-06 00:40:05 DEBUG    Saved 10000 sentences into file 247.txt.\n",
      "2023-06-06 00:40:09 DEBUG    Saved 10000 sentences into file 248.txt.\n",
      "2023-06-06 00:40:12 DEBUG    Saved 10000 sentences into file 249.txt.\n",
      "2023-06-06 00:40:16 DEBUG    Saved 10000 sentences into file 250.txt.\n",
      "2023-06-06 00:40:20 DEBUG    Saved 10000 sentences into file 251.txt.\n",
      "2023-06-06 00:40:23 DEBUG    Saved 10000 sentences into file 252.txt.\n",
      "2023-06-06 00:40:26 DEBUG    Saved 10000 sentences into file 253.txt.\n",
      "2023-06-06 00:40:30 DEBUG    Saved 10000 sentences into file 254.txt.\n",
      "2023-06-06 00:40:33 DEBUG    Saved 10000 sentences into file 255.txt.\n",
      "2023-06-06 00:40:36 DEBUG    Saved 10000 sentences into file 256.txt.\n",
      "2023-06-06 00:40:39 DEBUG    Saved 10000 sentences into file 257.txt.\n",
      "2023-06-06 00:40:43 DEBUG    Saved 10000 sentences into file 258.txt.\n",
      "2023-06-06 00:40:47 DEBUG    Saved 10000 sentences into file 259.txt.\n",
      "2023-06-06 00:40:50 DEBUG    Saved 10000 sentences into file 260.txt.\n",
      "2023-06-06 00:40:53 DEBUG    Saved 10000 sentences into file 261.txt.\n",
      "2023-06-06 00:40:57 DEBUG    Saved 10000 sentences into file 262.txt.\n",
      "2023-06-06 00:40:59 DEBUG    Saved 10000 sentences into file 263.txt.\n",
      "2023-06-06 00:41:03 DEBUG    Saved 10000 sentences into file 264.txt.\n",
      "2023-06-06 00:41:06 DEBUG    Saved 10000 sentences into file 265.txt.\n",
      "2023-06-06 00:41:09 DEBUG    Saved 10000 sentences into file 266.txt.\n",
      "2023-06-06 00:41:14 DEBUG    Saved 10000 sentences into file 267.txt.\n",
      "2023-06-06 00:41:18 DEBUG    Saved 10000 sentences into file 268.txt.\n",
      "2023-06-06 00:41:21 DEBUG    Saved 10000 sentences into file 269.txt.\n",
      "2023-06-06 00:41:25 DEBUG    Saved 10000 sentences into file 270.txt.\n",
      "2023-06-06 00:41:29 DEBUG    Saved 10000 sentences into file 271.txt.\n",
      "2023-06-06 00:41:33 DEBUG    Saved 10000 sentences into file 272.txt.\n",
      "2023-06-06 00:41:36 DEBUG    Saved 10000 sentences into file 273.txt.\n",
      "2023-06-06 00:41:40 DEBUG    Saved 10000 sentences into file 274.txt.\n",
      "2023-06-06 00:41:43 DEBUG    Saved 10000 sentences into file 275.txt.\n",
      "2023-06-06 00:41:46 DEBUG    Saved 10000 sentences into file 276.txt.\n",
      "2023-06-06 00:41:50 DEBUG    Saved 10000 sentences into file 277.txt.\n",
      "2023-06-06 00:41:53 DEBUG    Saved 10000 sentences into file 278.txt.\n",
      "2023-06-06 00:41:56 DEBUG    Saved 10000 sentences into file 279.txt.\n",
      "2023-06-06 00:41:59 DEBUG    Saved 10000 sentences into file 280.txt.\n",
      "2023-06-06 00:42:02 DEBUG    Saved 10000 sentences into file 281.txt.\n",
      "2023-06-06 00:42:06 DEBUG    Saved 10000 sentences into file 282.txt.\n",
      "2023-06-06 00:42:09 DEBUG    Saved 10000 sentences into file 283.txt.\n",
      "2023-06-06 00:42:12 DEBUG    Saved 10000 sentences into file 284.txt.\n",
      "2023-06-06 00:42:15 DEBUG    Saved 10000 sentences into file 285.txt.\n",
      "2023-06-06 00:42:18 DEBUG    Saved 10000 sentences into file 286.txt.\n",
      "2023-06-06 00:42:22 DEBUG    Saved 10000 sentences into file 287.txt.\n",
      "2023-06-06 00:42:26 DEBUG    Saved 10000 sentences into file 288.txt.\n",
      "2023-06-06 00:42:29 DEBUG    Saved 10000 sentences into file 289.txt.\n",
      "2023-06-06 00:42:32 DEBUG    Saved 10000 sentences into file 290.txt.\n",
      "2023-06-06 00:42:36 DEBUG    Saved 10000 sentences into file 291.txt.\n",
      "2023-06-06 00:42:39 DEBUG    Saved 10000 sentences into file 292.txt.\n",
      "2023-06-06 00:42:42 DEBUG    Saved 10000 sentences into file 293.txt.\n",
      "2023-06-06 00:42:45 DEBUG    Saved 10000 sentences into file 294.txt.\n",
      "2023-06-06 00:42:48 DEBUG    Saved 10000 sentences into file 295.txt.\n",
      "2023-06-06 00:42:51 DEBUG    Saved 10000 sentences into file 296.txt.\n",
      "2023-06-06 00:42:54 DEBUG    Saved 10000 sentences into file 297.txt.\n",
      "2023-06-06 00:42:57 DEBUG    Saved 10000 sentences into file 298.txt.\n",
      "2023-06-06 00:43:01 DEBUG    Saved 10000 sentences into file 299.txt.\n",
      "2023-06-06 00:43:04 DEBUG    Saved 10000 sentences into file 300.txt.\n",
      "2023-06-06 00:43:07 DEBUG    Saved 10000 sentences into file 301.txt.\n",
      "2023-06-06 00:43:11 DEBUG    Saved 10000 sentences into file 302.txt.\n",
      "2023-06-06 00:43:14 DEBUG    Saved 10000 sentences into file 303.txt.\n",
      "2023-06-06 00:43:17 DEBUG    Saved 10000 sentences into file 304.txt.\n",
      "2023-06-06 00:43:20 DEBUG    Saved 10000 sentences into file 305.txt.\n",
      "2023-06-06 00:43:23 DEBUG    Saved 10000 sentences into file 306.txt.\n",
      "2023-06-06 00:43:26 DEBUG    Saved 10000 sentences into file 307.txt.\n",
      "2023-06-06 00:43:30 DEBUG    Saved 10000 sentences into file 308.txt.\n",
      "2023-06-06 00:43:33 DEBUG    Saved 10000 sentences into file 309.txt.\n",
      "2023-06-06 00:43:36 DEBUG    Saved 10000 sentences into file 310.txt.\n",
      "2023-06-06 00:43:39 DEBUG    Saved 10000 sentences into file 311.txt.\n",
      "2023-06-06 00:43:42 DEBUG    Saved 10000 sentences into file 312.txt.\n",
      "2023-06-06 00:43:46 DEBUG    Saved 10000 sentences into file 313.txt.\n",
      "2023-06-06 00:43:49 DEBUG    Saved 10000 sentences into file 314.txt.\n",
      "2023-06-06 00:43:52 DEBUG    Saved 10000 sentences into file 315.txt.\n",
      "2023-06-06 00:43:56 DEBUG    Saved 10000 sentences into file 316.txt.\n",
      "2023-06-06 00:43:59 DEBUG    Saved 10000 sentences into file 317.txt.\n",
      "2023-06-06 00:44:02 DEBUG    Saved 10000 sentences into file 318.txt.\n",
      "2023-06-06 00:44:05 DEBUG    Saved 10000 sentences into file 319.txt.\n",
      "2023-06-06 00:44:09 DEBUG    Saved 10000 sentences into file 320.txt.\n",
      "2023-06-06 00:44:12 DEBUG    Saved 10000 sentences into file 321.txt.\n",
      "2023-06-06 00:44:15 DEBUG    Saved 10000 sentences into file 322.txt.\n",
      "2023-06-06 00:44:18 DEBUG    Saved 10000 sentences into file 323.txt.\n",
      "2023-06-06 00:44:22 DEBUG    Saved 10000 sentences into file 324.txt.\n",
      "2023-06-06 00:44:25 DEBUG    Saved 10000 sentences into file 325.txt.\n",
      "2023-06-06 00:44:28 DEBUG    Saved 10000 sentences into file 326.txt.\n",
      "2023-06-06 00:44:31 DEBUG    Saved 10000 sentences into file 327.txt.\n",
      "2023-06-06 00:44:34 DEBUG    Saved 10000 sentences into file 328.txt.\n",
      "2023-06-06 00:44:37 DEBUG    Saved 10000 sentences into file 329.txt.\n",
      "2023-06-06 00:44:40 DEBUG    Saved 10000 sentences into file 330.txt.\n",
      "2023-06-06 00:44:45 DEBUG    Saved 10000 sentences into file 331.txt.\n",
      "2023-06-06 00:44:48 DEBUG    Saved 10000 sentences into file 332.txt.\n",
      "2023-06-06 00:44:50 DEBUG    Saved 10000 sentences into file 333.txt.\n",
      "2023-06-06 00:44:54 DEBUG    Saved 10000 sentences into file 334.txt.\n",
      "2023-06-06 00:44:57 DEBUG    Saved 10000 sentences into file 335.txt.\n",
      "2023-06-06 00:45:00 DEBUG    Saved 10000 sentences into file 336.txt.\n",
      "2023-06-06 00:45:03 DEBUG    Saved 10000 sentences into file 337.txt.\n",
      "2023-06-06 00:45:07 DEBUG    Saved 10000 sentences into file 338.txt.\n",
      "2023-06-06 00:45:10 DEBUG    Saved 10000 sentences into file 339.txt.\n",
      "2023-06-06 00:45:13 DEBUG    Saved 10000 sentences into file 340.txt.\n",
      "2023-06-06 00:45:16 DEBUG    Saved 10000 sentences into file 341.txt.\n",
      "2023-06-06 00:45:20 DEBUG    Saved 10000 sentences into file 342.txt.\n",
      "2023-06-06 00:45:23 DEBUG    Saved 10000 sentences into file 343.txt.\n",
      "2023-06-06 00:45:26 DEBUG    Saved 10000 sentences into file 344.txt.\n",
      "2023-06-06 00:45:29 DEBUG    Saved 10000 sentences into file 345.txt.\n",
      "2023-06-06 00:45:32 DEBUG    Saved 10000 sentences into file 346.txt.\n",
      "2023-06-06 00:45:35 DEBUG    Saved 10000 sentences into file 347.txt.\n",
      "2023-06-06 00:45:39 DEBUG    Saved 10000 sentences into file 348.txt.\n",
      "2023-06-06 00:45:42 DEBUG    Saved 10000 sentences into file 349.txt.\n",
      "2023-06-06 00:45:46 DEBUG    Saved 10000 sentences into file 350.txt.\n",
      "2023-06-06 00:45:49 DEBUG    Saved 10000 sentences into file 351.txt.\n",
      "2023-06-06 00:45:54 DEBUG    Saved 10000 sentences into file 352.txt.\n",
      "2023-06-06 00:45:57 DEBUG    Saved 10000 sentences into file 353.txt.\n",
      "2023-06-06 00:46:00 DEBUG    Saved 10000 sentences into file 354.txt.\n",
      "2023-06-06 00:46:03 DEBUG    Saved 10000 sentences into file 355.txt.\n",
      "2023-06-06 00:46:06 DEBUG    Saved 10000 sentences into file 356.txt.\n",
      "2023-06-06 00:46:10 DEBUG    Saved 10000 sentences into file 357.txt.\n",
      "2023-06-06 00:46:13 DEBUG    Saved 10000 sentences into file 358.txt.\n",
      "2023-06-06 00:46:16 DEBUG    Saved 10000 sentences into file 359.txt.\n",
      "2023-06-06 00:46:21 DEBUG    Saved 10000 sentences into file 360.txt.\n",
      "2023-06-06 00:46:24 DEBUG    Saved 10000 sentences into file 361.txt.\n",
      "2023-06-06 00:46:27 DEBUG    Saved 10000 sentences into file 362.txt.\n",
      "2023-06-06 00:46:30 DEBUG    Saved 10000 sentences into file 363.txt.\n",
      "2023-06-06 00:46:33 DEBUG    Saved 10000 sentences into file 364.txt.\n",
      "2023-06-06 00:46:36 DEBUG    Saved 10000 sentences into file 365.txt.\n",
      "2023-06-06 00:46:40 DEBUG    Saved 10000 sentences into file 366.txt.\n",
      "2023-06-06 00:46:43 DEBUG    Saved 10000 sentences into file 367.txt.\n",
      "2023-06-06 00:46:45 DEBUG    Saved 10000 sentences into file 368.txt.\n",
      "2023-06-06 00:46:49 DEBUG    Saved 10000 sentences into file 369.txt.\n",
      "2023-06-06 00:46:52 DEBUG    Saved 10000 sentences into file 370.txt.\n",
      "2023-06-06 00:46:56 DEBUG    Saved 10000 sentences into file 371.txt.\n",
      "2023-06-06 00:46:59 DEBUG    Saved 10000 sentences into file 372.txt.\n",
      "2023-06-06 00:47:02 DEBUG    Saved 10000 sentences into file 373.txt.\n",
      "2023-06-06 00:47:05 DEBUG    Saved 10000 sentences into file 374.txt.\n",
      "2023-06-06 00:47:09 DEBUG    Saved 10000 sentences into file 375.txt.\n",
      "2023-06-06 00:47:11 DEBUG    Saved 10000 sentences into file 376.txt.\n",
      "2023-06-06 00:47:15 DEBUG    Saved 10000 sentences into file 377.txt.\n",
      "2023-06-06 00:47:18 DEBUG    Saved 10000 sentences into file 378.txt.\n",
      "2023-06-06 00:47:21 DEBUG    Saved 10000 sentences into file 379.txt.\n",
      "2023-06-06 00:47:24 DEBUG    Saved 10000 sentences into file 380.txt.\n",
      "2023-06-06 00:47:29 DEBUG    Saved 10000 sentences into file 381.txt.\n",
      "2023-06-06 00:47:32 DEBUG    Saved 10000 sentences into file 382.txt.\n",
      "2023-06-06 00:47:36 DEBUG    Saved 10000 sentences into file 383.txt.\n",
      "2023-06-06 00:47:39 DEBUG    Saved 10000 sentences into file 384.txt.\n",
      "2023-06-06 00:47:42 DEBUG    Saved 10000 sentences into file 385.txt.\n",
      "2023-06-06 00:47:45 DEBUG    Saved 10000 sentences into file 386.txt.\n",
      "2023-06-06 00:47:49 INFO     Finished processing text files. Generated 387 output files.\n"
     ]
    }
   ],
   "source": [
    "process_and_save_txt_files(input_path='datasets\\\\bookscorpusopen\\\\epubtxt', \n",
    "                           output_path='datasets\\\\bookscorpusopen\\\\processed_512', \n",
    "                           sentence_length=512, \n",
    "                           cutoff_line=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_simu_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
