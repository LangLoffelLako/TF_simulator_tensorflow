{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I finally understood, that during traingin each next token is calculated simultaneously for the whole sentence, such that no sequential processing is needed. That is of course redundant for inference. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging and decorators\n",
    "import logging as log\n",
    "import functools\n",
    "import time\n",
    "\n",
    "# system tools\n",
    "# import pathlib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# general modules\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# tensorflow modules\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "\n",
    "# necessary for visualization and user input\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging settings\n",
    "log.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "        # log.INFO for normal run\n",
    "    # level=log.INFO,\n",
    "        # log.DEBUG for diagnostics\n",
    "    level=log.DEBUG,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "log_enabled = True\n",
    "\n",
    "# Set True, if code is run as jupyter notebook\n",
    "is_interactive_notebook = True\n",
    "\n",
    "# paths\n",
    "dataset_path = 'datasets\\\\corpus.txt'\n",
    "vocab_path = 'datasets\\\\vocab.txt'\n",
    "\n",
    "# tokenization\n",
    "tokenizer_name = 'story_corpus_tokenizer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dec(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            if log_enabled and not kwargs.get('training') is None:\n",
    "                start_time = time.time()\n",
    "                class_name = func.__qualname__.split('.')[0]\n",
    "                log.info(f'{class_name}.{func.__name__} called')\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "        finally:\n",
    "            if log_enabled and not kwargs.get('training') is None:\n",
    "                duration = time.time() - start_time\n",
    "                log.info(f'{class_name}.{func.__name__} executed')\n",
    "    return wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "def clones(module, N):\n",
    "    \"\"\"Produce N identical layers\"\"\"\n",
    "    return [copy.deepcopy(module) for _ in range(N)]\n",
    "\n",
    "def clones_alt(layer_class, N, **kwargs):\n",
    "    \"\"\"Produce N identical layers\"\"\"\n",
    "    return [layer_class(**kwargs) for layer_number in range(N)]\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"\"\"Mask out subsequent positions.\"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerWrapperNew(layers.Layer):\n",
    "    visualize = True\n",
    "\n",
    "    def __init__(self, vis_on_count=None, enabler=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.counter = 0\n",
    "        self.vis_on_count = vis_on_count if vis_on_count else []\n",
    "        self.enabler = enabler\n",
    "\n",
    "    def visualize_data(self, data, mode, training=None):\n",
    "        if training is False:\n",
    "            # check for visualisation param of the instance and visualize or change class settings\n",
    "            if self.counter in self.vis_on_count:\n",
    "                if self.visualize:\n",
    "                    self.choose_func(mode)(data)\n",
    "                if self.enabler:\n",
    "                    LayerWrapperNew.visualize = True\n",
    "            else:\n",
    "                if self.enabler:\n",
    "                    LayerWrapperNew.visualize = False\n",
    "            self.counter += 1\n",
    "\n",
    "    # @log_dec\n",
    "    def choose_func(self, mode):\n",
    "        if mode == 'color_bar':\n",
    "            return lambda x: self.color_bar(x)\n",
    "        elif mode == 'mode2':\n",
    "            return lambda x: self.visualization_func2(x)\n",
    "        else:\n",
    "            return do_nothing\n",
    "\n",
    "    def color_bar(self, data):\n",
    "        # Assuming data[0] is a numpy array.\n",
    "        # If it's a ListWrapper or another list-like object, convert it to a numpy array.\n",
    "        array_data = np.array(data[0])\n",
    "        # If the array is 1D, reshape it into a 2D array with one column\n",
    "        if array_data.ndim == 1:\n",
    "            array_data = np.reshape(array_data, (-1, 1))\n",
    "        # Set the size of the plot (you can adjust the dimensions as needed)\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        # Use imshow to create a color-coded visualization and display it\n",
    "        plt.imshow(array_data, cmap='jet', aspect='auto')\n",
    "        plt.colorbar(label='Tensor Value')\n",
    "        plt.show()\n",
    "        \n",
    "    def visualization_func2(self, data):\n",
    "        # Your visualization code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerWrapper(layers.Layer):\n",
    "    \"\"\"\n",
    "    A wrapper for Keras layers, which allows to visualize data at each layer.\n",
    "\n",
    "    Attributes:\n",
    "        should_visualize (bool): Class attribute controlling whether visualization should occur.\n",
    "        layer (Layer): The Keras layer to be wrapped.\n",
    "        inputs (List[Tensor]): Inputs to the layer during calls.\n",
    "        outputs (List[Tensor]): Outputs of the layer during calls.\n",
    "        counter (int): Counter of layer calls.\n",
    "        visualize_on_calls (List[int]): List of call counts at which to visualize.\n",
    "        visualizations (List[Tuple[str, str]]): List of visualization modes and what to visualize.\n",
    "        visual_setter (bool): If True, this instance can change the should_visualize class variable.\n",
    "    \"\"\"\n",
    "    should_visualize = True  # class variable\n",
    "\n",
    "    def __init__(self, layer, visualize_on_calls=None, visualizations=None, visual_setter=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the LayerCallWrapper\n",
    "        Args:\n",
    "            layer (Layer): The Keras layer to be wrapped.\n",
    "            visualize_on_calls (List[int], optional): List of call counts at which to visualize. Defaults to empty list.\n",
    "            visualizations (List[Tuple[str, str]], optional): List of visualization modes and what to visualize. Defaults to an empty list.\n",
    "            visual_setter (bool, optional): If True, this instance can change the should_visualize class variable. Defaults to False.\n",
    "            **kwargs: Additional keyword arguments.u\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.counter = 0\n",
    "        self.visualize_on_calls = visualize_on_calls if visualize_on_calls else []\n",
    "        self.visualizations = visualizations if visualizations else []\n",
    "        self.visual_setter = visual_setter\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        \"\"\"\n",
    "        Overloads the attributte access in order to access the wrapped layers attribute if not found in the wraper\n",
    "        \"\"\"\n",
    "        if 'layer' in self.__dict__:\n",
    "            return getattr(self.layer, attr)\n",
    "        else:\n",
    "            raise AttributeError(f\"{self.__class__.__name__} object has no attribute {attr}\")\n",
    " \n",
    "    def call(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Overloads the call to the layer, allowing to capture inputs and outputs, and visualize if needed.\n",
    "\n",
    "        Args:\n",
    "            *args: Variable length argument list.\n",
    "            **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output of the layer call.\n",
    "        \"\"\"\n",
    "\n",
    "        self.inputs.append([arg for arg in args])\n",
    "        output = self.layer(*args, **kwargs)\n",
    "\n",
    "        tf.print(f'shape of {self.__class__.__name__}.{self.layer.__class__.__name__} out', tf.shape(output))\n",
    "        tf.print(f'dtype of {self.__class__.__name__}.{self.layer.__class__.__name__} out', output.dtype)\n",
    "        \n",
    "        if kwargs.get('training') is False:\n",
    "            self.outputs.append(output)\n",
    "\n",
    "            # check for visualisation param of the instance and visualize or change class settings\n",
    "            if self.counter in self.visualize_on_calls:\n",
    "                if self.should_visualize:\n",
    "                    self.visualize(self.visualizations)\n",
    "                if self.visual_setter:\n",
    "                    LayerWrapper.should_visualize = True\n",
    "            else:\n",
    "                if self.visual_setter:\n",
    "                    LayerWrapper.should_visualize = False\n",
    "\n",
    "            self.counter += 1\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def wait_for_user_input():\n",
    "        # waits for user input, if not jupyter notebook\n",
    "        # causes problems in jupyter\n",
    "        if not is_interactive_notebook:\n",
    "            proceed = input('Continue')\n",
    "\n",
    "    # @log_dec\n",
    "    def visualize(self, visualizations):\n",
    "        for mode, what_to_output in visualizations:\n",
    "            if what_to_output == 'x':\n",
    "                data = self.inputs[-1]\n",
    "            elif what_to_output == 'y':\n",
    "                data = self.outputs[-1]\n",
    "            elif what_to_output == 'y-x':\n",
    "                data = [output - input for input, output in zip(self.inputs[-1], self.outputs[-1])]\n",
    "\n",
    "            continue\n",
    "\n",
    "            if mode == 'mode1':\n",
    "                self.visualization_func_1(data)\n",
    "            elif mode == 'mode2':\n",
    "                self.visualization_func2(data)\n",
    "\n",
    "        self.wait_for_user_input()\n",
    "\n",
    "    def visualization_func_1(self, data):\n",
    "        # Assuming data[0] is a numpy array.\n",
    "        # If it's a ListWrapper or another list-like object, convert it to a numpy array.\n",
    "        array_data = np.array(data[0])\n",
    "        # If the array is 1D, reshape it into a 2D array with one column\n",
    "        if array_data.ndim == 1:\n",
    "            array_data = np.reshape(array_data, (-1, 1))\n",
    "        # Set the size of the plot (you can adjust the dimensions as needed)\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        # Use imshow to create a color-coded visualization and display it\n",
    "        plt.imshow(array_data, cmap='jet', aspect='auto')\n",
    "        plt.colorbar(label='Tensor Value')\n",
    "        plt.show()\n",
    "        \n",
    "    def visualization_func2(self, data):\n",
    "        # Your visualization code here\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classes are built using the Keras Functional API, which provides more flexibility than the Sequential API for defining complex models. Each class is a subclass of tf.keras.layers.Layer, so they can be composed to build more complex layers or models. The call method of each class defines the computation that the layer performs.\n",
    "\n",
    "These classes are designed to be components of a larger transformer model. The model itself is typically composed of an encoder and a decoder, each of which is made up of a stack of identical layers. The layers themselves contain sublayers that perform operations such as self-attention, source attention (in the case of the decoder), and position-wise feed-forward networks. These operations are encapsulated within classes like `EncoderStack`, `DecoderStack`, `EncoderLayer`, `DecoderLayer`, and `PositionwiseFeedForward`. The layer norm and dropout are applied in `ResidualSublayer` for regularizing and speeding up the training process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `EncoderDecoder`:\n",
    "    - `__init__(self, encoder, decoder, enc_embed, dec_embed, generator)`: This initializes the EncoderDecoder instance. It takes in five arguments:\n",
    "        - `encoder`: The encoder layer to be used.\n",
    "        - `decoder`: The decoder layer to be used.\n",
    "        - `enc_embed`: The embedding layer for the encoder.\n",
    "        - `dec_embed`: The embedding layer for the decoder.\n",
    "        - `generator`: The final layer that generates the output tokens.\n",
    "    - `encode(self, inputs, pad_mask)`: This method is used to encode the inputs using the encoder layer. It takes in two arguments:\n",
    "        - `inputs`: The input tokens to be encoded.\n",
    "        - `pad_mask`: The mask indicating which tokens are padding.\n",
    "    - `decode(self, enc_input, pad_mask, inputs, subseq_mask)`: This method is used to decode the encoded inputs using the decoder layer. It takes in four arguments:\n",
    "        - `enc_input`: The encoded input from the encoder.\n",
    "        - `pad_mask`: The mask indicating which tokens are padding in the encoded input.\n",
    "        - `inputs`: The target tokens to be decoded.\n",
    "        - `subseq_mask`: The mask indicating which tokens in the target sequence should not be attended to.\n",
    "    - `call(self, enc_input, dec_input, pad_mask, subseq_mask)`: This method is used to perform the complete transformation from input tokens to output tokens. It takes in four arguments that are the same as those described in the `encode` and `decode` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @LayerWrapperDecorator(visualize_on_calls=[1], visual_setter=True)\n",
    "class EncoderDecoder(tf.keras.Model):\n",
    "    def __init__(self, encoder_stack, decoder_stack, enc_embed, dec_embed, generator):\n",
    "        super().__init__()\n",
    "        # modules\n",
    "        self.encoder_stack = encoder_stack\n",
    "        self.decoder_stack = decoder_stack\n",
    "        self.enc_embed = enc_embed\n",
    "        self.dec_embed = dec_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    # @log_dec\n",
    "    def encode(self, inputs, pad_mask, training=None):\n",
    "        return self.encoder_stack(self.enc_embed(inputs), pad_mask, training=training)\n",
    "    \n",
    "    # @log_dec\n",
    "    def decode(self, enc_input, pad_mask, inputs, subseq_mask, training=None):\n",
    "        return self.decoder_stack(self.dec_embed(inputs), enc_input, pad_mask, subseq_mask, training=training)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        enc_input, dec_input, pad_mask, subseq_mask = inputs\n",
    "\n",
    "        return self.decode(self.encode(enc_input, pad_mask, training), \n",
    "                           pad_mask,\n",
    "                           dec_input, \n",
    "                           subseq_mask, training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. `LayerNorm`:\n",
    "    - `__init__(self, features, eps=1e-6)`: This initializes the LayerNorm instance. It takes in two arguments:\n",
    "        - `features`: The number of features in the input to be normalized.\n",
    "        - `eps`: A small number to add to the denominator for numerical stability.\n",
    "    - `call(self, x)`: This method is used to apply layer normalization to the input. It takes in one argument:\n",
    "        - `x`: The input to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(layers.Layer):\n",
    "\n",
    "    def __init__(self, features, eps=1e-6) -> None:\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = self.add_weight(shape=(features,), initializer='ones', name=self.name + \"a_2\")\n",
    "        self.b_2 = self.add_weight(shape=(features,), initializer='zeros', name=self.name + \"b_2\")\n",
    "        self.eps = eps\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x):\n",
    "        mean, var = tf.nn.moments(x, axes=-1, keepdims=True)\n",
    "        std = tf.math.sqrt(var + self.eps)\n",
    "        return self.a_2 * (x - mean) / std + self.b_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. `ResidualSublayer`:\n",
    "    - `__init__(self, size, dropout)`: This initializes the ResidualSublayer instance. It takes in two arguments:\n",
    "        - `size`: The number of features in the input.\n",
    "        - `dropout`: The dropout rate to be applied after the sublayer.\n",
    "    - `call(self, x, sublayer)`: This method is used to apply a sublayer and a residual connection to the input. It takes in two arguments:\n",
    "        - `x`: The input to be transformed.\n",
    "        - `sublayer`: The sublayer to be applied to the input. This is expected to be a function or callable object that takes in the input and returns a tensor of the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSublayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout) -> None:\n",
    "        super(ResidualSublayer, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, sublayer, training=None):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        sublayer_out = sublayer(self.norm(x))\n",
    "        return x + self.dropout(sublayer_out, training=training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Stack Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `EncoderStack`:\n",
    "    - `__init__(self, layer, N)`: This initializes the EncoderStack instance. It takes in two arguments and initializes two instance variables:\n",
    "        - `layer`: The type of layer to be used in the encoder stack. This should be a callable object that takes in the input and a mask and returns a tensor.\n",
    "        - `N`: The number of layers in the encoder stack.\n",
    "        - `self.layers` is a list of `N` layer clones of the type `layer`.\n",
    "        - `self.norm` is the norm layer, that is applied to the output of the `EncoderStack`.\n",
    "    - `call(self, x, mask)`: This method is used to pass the input through each layer in the encoder stack in turn. It takes in two arguments:\n",
    "        - `x`: The input to be processed by the encoder stack.\n",
    "        - `mask`: The mask indicating which tokens should not be attended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(layers.Layer):\n",
    "    \"\"\"\n",
    "    Core encoder is a stack of N=6 Layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, N, size, **kwargs):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        self.layers = clones_alt(layer, N, size=size, **kwargs)\n",
    "        self.norm = LayerNorm(size)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, mask, training=None):\n",
    "        \"\"\"\n",
    "        Pass the input (and mask) through each layer in turn\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask, training=training)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. `EncoderLayer`:\n",
    "    - `__init__(self, size, self_attn, feed_forward, dropout)`: This initializes the EncoderLayer instance. It takes in four arguments:\n",
    "        - `size`: The number of features in the input.\n",
    "        - `self_attn`: The self-attention mechanism to be used in the encoder layer. This should be a callable object that takes in the input and a mask and returns a tensor.\n",
    "        - `feed_forward`: The feed-forward network to be used in the encoder layer. This should be a callable object that takes in the input and returns a tensor.\n",
    "        - `dropout`: The dropout rate to be applied after each sublayer.\n",
    "    - `call(self, x, mask)`: This method is used to pass the input through the self-attention mechanism and the feed-forward network. It takes in two arguments:\n",
    "        - `x`: The input to be processed by the encoder layer.\n",
    "        - `mask`: The mask indicating which tokens should not be attended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder is made up of a self-attention and a feed forward layer \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones_alt(ResidualSublayer, N=2, size=size, dropout=dropout)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, mask, training=None):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask, training=training), training=training)\n",
    "        return self.sublayer[1](x, lambda x: self.feed_forward(x, training=training), training=training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Stack Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. `DecoderStack`:\n",
    "    - `__init__(self, layer, N)`: This initializes the DecoderStack instance. It takes in two arguments and initializes two instance variables:\n",
    "        - `layer`: The type of layer to be used in the decoder stack. This should be a callable object that takes in the input, the memory from the encoder, a source mask, and a target mask, and returns a tensor.\n",
    "        - `N`: The number of layers in the decoder stack.\n",
    "        - `self.layers` is a list of `N` layer clones of the type `layer`.\n",
    "        - `self.norm` is the norm layer, that is applied to the output of the `EncoderStack`.\n",
    "    - `call(self, x, memory, src_mask, tgt_mask)`: This method is used to pass the input through each layer in the decoder stack in turn. It takes in four arguments:\n",
    "        - `x`: The input to be processed by the decoder stack.\n",
    "        - `memory`: The output of the encoder, which serves as the memory for the decoder.\n",
    "        - `src_mask`: The mask indicating which tokens in the source sequence should not be attended to.\n",
    "        - `tgt_mask`: The mask indicating which tokens in the target sequence should not be attended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(layers.Layer):\n",
    "    \"\"\"\n",
    "    Generic N layer decoder with masking\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, N, size, **kwargs):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.layers = clones_alt(layer, N, size=size, **kwargs)\n",
    "        self.norm = LayerNorm(size)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, memory, src_mask, tgt_mask, training=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask, training=training)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. `DecoderLayer`:\n",
    "    - `__init__(self, size, self_attn, src_attn, feed_forward, dropout)`: This initializes the DecoderLayer instance. It takes in five arguments:\n",
    "        - `size`: The number of features in the input.\n",
    "        - `self_attn`: The self-attention mechanism to be used in the decoder layer. This should be a callable object that takes in the input and a mask and returns a tensor.\n",
    "        - `src_attn`: The source attention mechanism to be used in the decoder layer. This should be a callable object that takes in the input, the memory from the encoder, and a mask, and returns a tensor.\n",
    "        - `feed_forward`: The feed-forward network to be used in the decoder layer. This should be a callable object that takes in the input and returns a tensor.\n",
    "        - `dropout`: The dropout rate to be applied after each sublayer.\n",
    "    - `call(self, x, memory, src_mask, tgt_mask)`: This method is used to pass the input through the self-attention mechanism, the source attention mechanism, and the feed-forward network. It takes in four arguments:\n",
    "        - `x`: The input to be processed by the decoder layer.\n",
    "        - `memory`: The output of the encoder, which serves as the memory for the decoder.\n",
    "        - `src_mask`: The mask indicating which tokens in the source sequence should not be attended to.\n",
    "        - `tgt_mask`: The mask indicating which tokens in the target sequence should not be attended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    Decoder is made of self-attn, source-attn and feedforward layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones_alt(ResidualSublayer, N=3, size=size, dropout=dropout)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, memory, src_mask, tgt_mask, training=None):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sublayers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. `PositionwiseFeedForward`:\n",
    "    - `__init__(self, d_model, d_ff, dropout=0.1, *args, **kwargs)`: This initializes the PositionwiseFeedForward instance. It takes in three arguments and an optional set of arguments:\n",
    "        - `d_model`: The number of features in the input.\n",
    "        - `d_ff`: The number of features in the hidden layer of the feed-forward network.\n",
    "        - `dropout`: The dropout rate to be applied after the first layer of the feed-forward network.\n",
    "        - `*args, **kwargs`: Additional arguments that might be necessary for the parent class initialization.\n",
    "    - `call(self, x)`: This method is used to pass the input through the feed-forward network. It takes in one argument:\n",
    "        - `x`: The input to be processed by the feed-forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(layers.Layer):\n",
    "    \"\"\"Implements FFN equation\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1, *args, **kwargs):\n",
    "        super(PositionwiseFeedForward, self).__init__(*args, **kwargs)\n",
    "        self.w_1 = layers.Dense(d_ff)\n",
    "        self.w_2 = layers.Dense(d_model)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, training=None):\n",
    "        return self.w_2(self.dropout(tf.nn.relu(self.w_1(x)), training=training))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. `Generator`:\n",
    "    - `__init__(self, vocab)`: This method initializes the Generator instance. It accepts one argument:\n",
    "        - `vocab`: The size of the vocabulary which will be the number of output units in the dense layer.\n",
    "    - `call(self, x)`: This method is used to pass the input through the generator. It takes in one argument:\n",
    "        - `x`: The input tensor to be processed by the generator. The method returns the log softmax of the output of the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @LayerWrapperDecorator(visualize_on_calls=[1], visualizations=[('mode1', 'x')])\n",
    "class Generator(LayerWrapperNew):\n",
    "    \"\"\"\n",
    "    Define standard linear + softmax generation step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab):\n",
    "        super(Generator,self).__init__(vis_on_count=[1])\n",
    "        self.proj = layers.Dense(vocab)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, training=None):\n",
    "        result = tf.nn.log_softmax(self.proj(x), axis=-1)\n",
    "        self.visualize_data(result, 'color_bar', training=training)\n",
    "        return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "10. `attention(query, key, value, mask=None, dropout=None)`:\n",
    "    - This is a function that computes the 'Scaled Dot Product Attention'. The arguments are as follows:\n",
    "        - `query`, `key`, `value`: These are the main inputs to the attention function.\n",
    "        - `mask`: Optional mask for the attention scores.\n",
    "        - `dropout`: Optional dropout rate to be applied to the attention scores.\n",
    "    - The function first scales the dot product of the query and key, applies the mask if provided, applies softmax to compute attention scores, applies dropout if provided, and then uses the attention scores to compute a weighted sum of the value inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @log_dec\n",
    "def attention(query, key, value, mask=None, dropout=None, training=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "\n",
    "    d_k = query.shape[-1]\n",
    "    scores = tf.matmul(query, tf.transpose(key, perm=[0, 1, 3, 2])) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = tf.cast(mask, dtype=tf.bool)\n",
    "        scores = tf.where(mask, scores, tf.fill(tf.shape(scores), -1e9))\n",
    "    p_attn = tf.nn.softmax(scores, axis=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn, training=training)\n",
    "    return tf.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. `MultiHeadedAttention`:\n",
    "    - `__init__(self, h, d_model, dropout=0.1)`: This initializes the MultiHeadedAttention instance. It takes in three arguments:\n",
    "        - `h`: The number of attention heads.\n",
    "        - `d_model`: The number of features in the input.\n",
    "        - `dropout`: The dropout rate to be applied after the softmax in the attention computation.\n",
    "    - `call(self, query, key, value, mask=None)`: This method is used to compute the multi-headed attention over the inputs. It takes in four arguments:\n",
    "        - `query`, `key`, `value`: These are the main inputs to the attention computation.\n",
    "        - `mask`: Optional mask for the attention scores.\n",
    "    - The method first computes the linear projections of the inputs, applies the attention function to the projected inputs, concatenates the outputs of the attention function across the attention heads, and then applies a final linear transformation to the concatenated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(layers.Layer):\n",
    "    \n",
    "    def __init__(self, h, d_model, dropout=0.1, **kwargs):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.query, self.key, self.value, self.linear = clones_alt(layers.Dense, N=4, units=d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, query, key, value, mask=None, training=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads\n",
    "            mask = tf.expand_dims(mask, 1)\n",
    "\n",
    "        nbatches = tf.shape(query)[0]\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            tf.transpose(tf.reshape(lin(x), [nbatches, -1 , self.h, self.d_k]), perm=[0, 2, 1, 3]) \n",
    "            for lin, x in zip(\n",
    "                [self.query, self.key, self.value], \n",
    "                (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout, training=training)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = tf.reshape(tf.transpose(x ,perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embedding Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. `positional_encoding(length, depth)`:\n",
    "    - This is a function that computes the positional encoding for a sequence of a given length and depth. The arguments are as follows:\n",
    "        - `length`: The length of the sequence for which positional encoding is to be computed.\n",
    "        - `depth`: The number of features in the input sequence.\n",
    "    - The function first computes the rates at which the angles should change across the positions and depths, then computes the angles at each position and depth, and finally applies sine to the angles at the even indices and cosine to the angles at the odd indices. The positional encoding for a position is thus a vector of these sine and cosine values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @log_dec\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]   # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth  # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)               # (1, depth)\n",
    "    angle_rads  = positions * angle_rates           # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1\n",
    "        )\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. `PositionalEmbedding`:\n",
    "    - `__init__(self, vocab_size, d_model)`: This method initializes the PositionalEmbedding instance. It takes in two arguments:\n",
    "        - `vocab_size`: The size of the vocabulary, which will be the input dimension of the embedding layer.\n",
    "        - `d_model`: The number of features to be output by the embedding layer and the depth for the positional encoding.\n",
    "    - `call(self, x)`: This method is used to compute the positionally encoded embeddings of the inputs. It takes in one argument:\n",
    "        - `x`: The input tensor for which the embeddings are to be computed.\n",
    "    - The method first computes the embeddings of the inputs, scales the embeddings by the square root of `d_model`, and then adds the positional encoding to these scaled embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    # @log_dec\n",
    "    # @tf.function\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positional_encoding\n",
    "        x *=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        # TODO: Dropout is missing\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. `make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1)`:\n",
    "    - The `make_model` function constructs a Transformer model from given hyperparameters. It takes seven arguments:\n",
    "        - `src_vocab`: The size of the source vocabulary.\n",
    "        - `tgt_vocab`: The size of the target vocabulary.\n",
    "        - `N`(default=6): The number of layers in the Transformer's Encoder and Decoder stacks.\n",
    "        - `d_model`(default=512): The dimension of the model. It's the number of features in input and output.\n",
    "        - `d_ff`(default=2048): The number of features in the hidden layer of the feed-forward network.\n",
    "        - `h`(default=8): The number of attention heads in the MultiHeadedAttention mechanism.\n",
    "        - `dropout`(default=0.1): The dropout rate to be applied in several parts of the model.\n",
    "    - Inside this function, instances of `MultiHeadedAttention` and `PositionwiseFeedForward` are created. These instances are then deep-copied and used to construct the Encoder and Decoder stacks, additionally the PositionalEmbeddings, and the Generator are instantiated. All these parts are then assembled into a `EncoderDecoder` instance, which includes the complete Transformer model. If a module is wrapped with a `LayerWrapper` this is in order to visualize the output of this layer on sucessive calls. Look for the specific meaning of the `LayerWrapper` parameters in the definition of the class.\n",
    "    - Finally, the function returns the constructed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_dec\n",
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "\n",
    "    '''model = LayerWrapper(\n",
    "                EncoderDecoder(\n",
    "                    EncoderStack(\n",
    "                        EncoderLayer,\n",
    "                        N=N, \n",
    "                        size=d_model, \n",
    "                        dropout=dropout, \n",
    "                        self_attn=MultiHeadedAttention(h, d_model), \n",
    "                        feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout)),\n",
    "                    DecoderStack(\n",
    "                        DecoderLayer, \n",
    "                        N=N, \n",
    "                        size=d_model, \n",
    "                        dropout=dropout,\n",
    "                        self_attn=MultiHeadedAttention(h, d_model), \n",
    "                        src_attn=MultiHeadedAttention(h, d_model), \n",
    "                        feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout)),\n",
    "                    PositionalEmbedding(\n",
    "                        src_vocab, \n",
    "                        d_model),\n",
    "                    PositionalEmbedding(\n",
    "                        tgt_vocab, \n",
    "                        d_model),\n",
    "                    LayerWrapper(\n",
    "                        Generator(tgt_vocab),\n",
    "                        visualize_on_calls=[1],\n",
    "                        visualizations=[('mode1', 'x')]\n",
    "                    ),\n",
    "\n",
    "                ),\n",
    "                visualize_on_calls=[1],\n",
    "                visual_setter=True\n",
    "            )\n",
    "    '''\n",
    "    model = EncoderDecoder(\n",
    "                EncoderStack(\n",
    "                    EncoderLayer,\n",
    "                    N=N, \n",
    "                    size=d_model, \n",
    "                    dropout=dropout, \n",
    "                    self_attn=MultiHeadedAttention(h, d_model), \n",
    "                    feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout)),\n",
    "                DecoderStack(\n",
    "                    DecoderLayer, \n",
    "                    N=N, \n",
    "                    size=d_model, \n",
    "                    dropout=dropout,\n",
    "                    self_attn=MultiHeadedAttention(h, d_model), \n",
    "                    src_attn=MultiHeadedAttention(h, d_model), \n",
    "                    feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout)),\n",
    "                PositionalEmbedding(\n",
    "                    src_vocab, \n",
    "                    d_model),\n",
    "                PositionalEmbedding(\n",
    "                    tgt_vocab, \n",
    "                    d_model),\n",
    "                Generator(tgt_vocab)\n",
    "            )\n",
    "\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    # model.build([(None, None), (None, None)])  # Explicit build call to initialize variables\n",
    "    # for w in model.trainable_variables:\n",
    "    #     if len(w.shape) > 1:\n",
    "    #         tf.keras.initializers.GlorotUniform()(w)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_text_file):\n",
    "    return tf.data.TextLineDataset(filenames=dataset_text_file)\n",
    "\n",
    "def create_vocab(dataset):\n",
    "    bert_vocab_args=dict(\n",
    "        vocab_size = 8000,\n",
    "        reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"],\n",
    "        bert_tokenizer_params = dict(lower_case=True),\n",
    "        learn_params = {},\n",
    "    )\n",
    "\n",
    "    story_vocab = bert_vocab.bert_vocab_from_dataset(\n",
    "        dataset.batch(1000).prefetch(2),\n",
    "        **bert_vocab_args\n",
    "    )\n",
    "    return story_vocab\n",
    "\n",
    "def create_vocab_from_textdata(text_file=dataset_path):\n",
    "    dataset = load_dataset(text_file)\n",
    "    vocab = create_vocab(dataset)\n",
    "    return vocab\n",
    "\n",
    "def write_vocab_file(filepath, vocab):\n",
    "    with open(filepath, 'w') as file:\n",
    "        for token in vocab:\n",
    "            print(token, file=file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_dec\n",
    "def load_tokenizer(tokenizer_name):\n",
    "    return tf.saved_model.load(tokenizer_name)\n",
    "\n",
    "@log_dec\n",
    "def create_datasets(file_path, tokenizer, buffer_size=20000, batch_size=64, max_padding=128, pad_id=0):\n",
    "    # Create a Dataset from the text file\n",
    "    lines_dataset = tf.data.TextLineDataset(file_path)\n",
    "\n",
    "    # Tokenize the whole dataset with the pre-trained tokenizer\n",
    "    tokenized_dataset = (lines_dataset\n",
    "                         .shuffle(buffer_size)\n",
    "                         .batch(batch_size)\n",
    "                         .map(lambda x: prepare_datapoint(x,tokenizer, max_padding=128, pad_id=0))\n",
    "                         .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "    # Determine the number of lines for training (80% for this example)\n",
    "    num_lines = sum(1 for _ in tokenized_dataset)\n",
    "    num_train = int(0.8 * num_lines)\n",
    "\n",
    "    # Split the data into train and validation datasets\n",
    "    train_dataset = tokenized_dataset.take(num_train)\n",
    "    valid_dataset = tokenized_dataset.skip(num_train)\n",
    "\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "@log_dec\n",
    "def prepare_datapoint(data_point, tokenizer, max_padding, pad_id=0):\n",
    "    \n",
    "    src_tokens = tokenizer.tokenize(data_point)\n",
    "    tgt_tokens = src_tokens[:, :-1]\n",
    "    label_tokens = src_tokens[:, 1:]\n",
    "\n",
    "    src = src_tokens.to_tensor(shape=[1, max_padding], default_value=pad_id)\n",
    "    tgt = tgt_tokens.to_tensor(shape=[1, max_padding], default_value=pad_id)\n",
    "    label = label_tokens.to_tensor(shape=[1, max_padding], default_value=pad_id)\n",
    "    \n",
    "    src_mask = (src != pad_id)[:, np.newaxis, :]\n",
    "    tgt_mask = make_std_mask(tgt, pad_id)\n",
    "\n",
    "    return (src, tgt, src_mask, tgt_mask), label\n",
    "\n",
    "@log_dec\n",
    "def make_std_mask(tgt, pad_id):\n",
    "    \"Create a mask to hide padding and future words.\"\n",
    "    tgt_mask = (tgt != pad_id)[:, np.newaxis, :]\n",
    "    tgt_mask = tf.logical_and(tgt_mask, subsequent_mask(tgt.shape[-1]))\n",
    "    return tgt_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(layers.Layer):\n",
    "    \"\"\"\n",
    "    This class represents a loss function layer that applies label smoothing to prevent overconfidence \n",
    "    in the model's predictions. This is done by replacing the 0s and 1s in the labels with smoothed values, \n",
    "    such that the model learns to be less confident and thus, more robust.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): The size of the vocabulary, which also represents the number of classes.\n",
    "        padding_idx (int): The index representing padding elements.\n",
    "        smoothing (float): The smoothing factor to be applied. The values should be between 0 and 1. \n",
    "                           Default value is 0.\n",
    "        reduction (tf.keras.losses.Reduction): The type of reduction to apply to the output loss. \n",
    "                                               Default is tf.keras.losses.Reduction.SUM.\n",
    "\n",
    "    Methods:\n",
    "        call(x, target): Calculates and returns the loss given the model's output `x` and the target labels.\n",
    "\n",
    "    Example:\n",
    "        >>> loss_func = LabelSmoothingLoss(vocab_size=5000, padding_idx=0, smoothing=0.1)\n",
    "        >>> x = tf.random.uniform((10, 5000))  # model's output\n",
    "        >>> target = tf.random.uniform((10, 1), maxval=5000, dtype=tf.int32)  # target labels\n",
    "        >>> loss = loss_func(x, target)  # calculate loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, padding_idx, smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        # self.loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        self.loss_func = tf.keras.losses.KLDivergence(reduction='none')\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, x, target):\n",
    "        # create padding mask\n",
    "        mask = self.padding_mask(target, self.padding_idx)\n",
    "\n",
    "        # Apply label confidence\n",
    "        true_dist = target * self.confidence\n",
    "\n",
    "        # Apply label smoothing\n",
    "        smoothing_value = self.smoothing / tf.cast(self.vocab_size - 2, tf.float32)\n",
    "        true_dist = tf.where(tf.equal(true_dist, 0), smoothing_value, true_dist)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = self.kl_div_loss(x, true_dist)\n",
    "\n",
    "        loss = tf.cast(self.apply_mask(loss, mask), x.dtype)\n",
    "\n",
    "        loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def padding_mask(t, padding_idx):\n",
    "        return tf.cast(tf.equal(t[:, :, padding_idx], 0), tf.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mask(t, mask):\n",
    "        return t * (tf.reshape(mask, [-1, 1]) * tf.ones_like(t))\n",
    "    \n",
    "    @staticmethod\n",
    "    def kl_div_loss(input, target):\n",
    "        return target * (tf.math.log(target)-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCompute(tf.keras.losses.Loss):\n",
    "    def __init__(self, generator, loss_function, vocab_size, name='loss_compute'):\n",
    "        super().__init__(name=name)\n",
    "        self.generator = generator\n",
    "        self.loss_function = loss_function\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    # @log_dec\n",
    "    def call(self, y_true, y_pred): \n",
    "        # tf.print('initial y_pred', y_pred)\n",
    "        # tf.print('initial y_true', y_true)\n",
    "        y_pred = self.generator(y_pred)\n",
    "        y_true_one_hot = tf.cast(tf.one_hot(y_true, depth=self.vocab_size), tf.float32)\n",
    "        # Compute loss\n",
    "        # tf.print(tf.argmax(y_true_one_hot, axis=-1))\n",
    "        loss = self.loss_function(y_pred, y_true_one_hot)\n",
    "        # Calculate mean loss per batch\n",
    "        norm = tf.cast(tf.shape(y_true)[0], dtype=tf.float32)\n",
    "        \n",
    "        sloss = loss / norm\n",
    "\n",
    "        # Return scaled loss (mean loss per batch) and total loss (for the whole batch)\n",
    "        return loss\n",
    "        # return sloss * norm, sloss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model=512, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    # @log_dec\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg_1 = tf.math.rsqrt(step)\n",
    "        arg_2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg_1, arg_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @log_dec\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "\n",
    "  match = label == pred\n",
    "  mask = label != 0\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(tokenizer, config):\n",
    "\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    n_epochs = config[\"n_epochs\"]\n",
    "    base_lr = config[\"base_lr\"]\n",
    "    max_padding = config[\"max_padding\"]\n",
    "    padding_idx = config[\"padding_idx\"]\n",
    "    warmup_steps = config[\"warmup_steps\"]\n",
    "    d_model = config[\"d_model\"]\n",
    "    N = config[\"N\"]\n",
    "    h = config[\"h\"]\n",
    "    fit_verbose = config[\"fit_verbose\"]\n",
    "    load_latest = config[\"load_latest\"]\n",
    "    save_model = config[\"save_model\"]\n",
    "\n",
    "\n",
    "    tokenizer = load_tokenizer(tokenizer_name)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "    model = make_model(vocab_size, vocab_size, d_model=d_model, N=N, h=h)\n",
    "\n",
    "    # out = model.decode(model.encode(first_batch.src, first_batch.src_mask), \n",
    "    #                       first_batch.src_mask,\n",
    "    #                       first_batch.tgt, \n",
    "    #                       first_batch.tgt_mask)\n",
    "\n",
    "    # out = model(first_batch.src, first_batch.tgt, first_batch.src_mask, first_batch.tgt_mask)\n",
    "\n",
    "    model.compile(\n",
    "        loss = LossCompute(\n",
    "            model.generator, \n",
    "            LabelSmoothingLoss(vocab_size, padding_idx=padding_idx, smoothing=0.1), \n",
    "            vocab_size=vocab_size), \n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            TransformerSchedule(d_model=d_model, warmup_steps=warmup_steps),\n",
    "            beta_1=0.9, \n",
    "            beta_2=0.98, \n",
    "            epsilon=1e-9), \n",
    "        metrics = [masked_accuracy]\n",
    "    )\n",
    "\n",
    "    model = load_latest_weights(model, d_model, load_latest=load_latest)\n",
    "\n",
    "    if save_model:\n",
    "\n",
    "        current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        directory = f\"model_N{N}_h{h}_d{d_model}_t{current_time}\"\n",
    "        ckp_name = \"model_{epoch:03d}.h5\"\n",
    "        final_name = \"final_model.h5\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        checkpoint_path = os.path.join(directory, ckp_name)\n",
    "        final_path = os.path.join(directory, final_name)\n",
    "        \n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_path, \n",
    "            save_freq='epoch', \n",
    "            save_weights_only=True, \n",
    "            verbose=1)\n",
    "    else:\n",
    "        checkpoint = []\n",
    "\n",
    "    # TODO: Return to fullsized dataset\n",
    "    model.fit(train_data.take(10),\n",
    "        epochs = n_epochs,\n",
    "        batch_size = batch_size,\n",
    "        validation_data = val_data.take(10),\n",
    "        callbacks = [checkpoint],\n",
    "        verbose = fit_verbose)\n",
    "    \n",
    "    if save_model:\n",
    "        model.save_weights(final_path, overwrite=True)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_latest_weights(model, d_model, load_latest=False, model_folder=None):\n",
    "    if model_folder is not None:\n",
    "        # Load weights from the specified model folder\n",
    "        directories = [model_folder]\n",
    "    elif load_latest:\n",
    "        # Get all the directories and sort them in descending order\n",
    "        directories = sorted(glob.glob('model_*'), key=os.path.getmtime, reverse=True)\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "    # Load weights from the latest trained model\n",
    "    latest_weights = None\n",
    "    if directories:\n",
    "        latest_dir = directories[0]\n",
    "        # Get all the h5 files inside the directory and sort them\n",
    "        h5_files = sorted(glob.glob(os.path.join(latest_dir, '*.h5')))\n",
    "\n",
    "        if h5_files:\n",
    "            # Pick the last epoch file (or final_model file if it exists)\n",
    "            latest_epoch_file = h5_files[-1] if 'final_model.h5' not in h5_files[-1] else h5_files[-2]\n",
    "            latest_weights = os.path.join(latest_epoch_file)\n",
    "\n",
    "    # Load weights if we found a previously trained model\n",
    "    if latest_weights is not None:\n",
    "        print(f'Loading weights from {latest_weights}')\n",
    "        \n",
    "        # Create a dummy input matching the input shape of the model\n",
    "        dummy_input = tf.random.uniform(shape=[1,d_model]), tf.random.uniform(shape=[1,d_model]), None, None\n",
    "        # Call the model on the dummy input\n",
    "        _ = model.generator(model(dummy_input))\n",
    "\n",
    "        model.load_weights(latest_weights)\n",
    "        return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"n_epochs\": 1,\n",
    "        \"base_lr\": 1.0,\n",
    "        \"max_padding\": 128,\n",
    "        \"padding_idx\": 0,\n",
    "        \"warmup_steps\": 1000,\n",
    "        \"N\": 6,\n",
    "        \"d_model\": 128,\n",
    "        \"h\": 8,\n",
    "        \"fit_verbose\": 2,\n",
    "        \"load_latest\": False,\n",
    "        \"save_model\": False,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = create_datasets(\n",
    "    dataset_path, \n",
    "    load_tokenizer(tokenizer_name),\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    max_padding=config[\"max_padding\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79 908 108 ... 0 0 0]]\n",
      "[[82 284 7235 ... 0 0 0]]\n",
      "[[144 50 269 ... 0 0 0]]\n",
      "[[91 149 114 ... 0 0 0]]\n",
      "[[87 89 143 ... 0 0 0]]\n",
      "[[107 159 106 ... 0 0 0]]\n",
      "[[90 201 7242 ... 0 0 0]]\n",
      "[[129 119 571 ... 0 0 0]]\n",
      "[[1627 95 1824 ... 0 0 0]]\n",
      "[[99 143 15 ... 0 0 0]]\n",
      "[[5 161 266 ... 0 0 0]]\n",
      "[[83 90 10 ... 0 0 0]]\n",
      "[[50 10 54 ... 0 0 0]]\n",
      "[[124 50 203 ... 0 0 0]]\n",
      "[[13 5 16 ... 0 0 0]]\n",
      "[[482 15 50 ... 0 0 0]]\n",
      "[[82 887 2663 ... 0 0 0]]\n",
      "[[5 281 90 ... 0 0 0]]\n",
      "[[50 325 123 ... 0 0 0]]\n",
      "[[88 230 123 ... 0 0 0]]\n",
      "10/10 - 34s - loss: 7.8068 - masked_accuracy: 0.0029 - val_loss: 7.7591 - val_masked_accuracy: 0.0000e+00 - 34s/epoch - 3s/step\n",
      "Model: \"encoder_decoder_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_stack_5 (EncoderSta  multiple                 595840    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " decoder_stack_5 (DecoderSta  multiple                 663424    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " positional_embedding_10 (Po  multiple                 1021568   \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " positional_embedding_11 (Po  multiple                 1021568   \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " generator_5 (Generator)     multiple                  1029549   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,331,949\n",
      "Trainable params: 4,331,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = run_model(tokenizer_name, config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordComplete(tf.Module):\n",
    "  def __init__(self, tokenizer, transformer, max_length=512, dtype=tf.Tensor, decode_result=True):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.transformer = transformer\n",
    "    self.max_length = max_length\n",
    "    self.dtype = dtype\n",
    "    self.decode_result = decode_result\n",
    "\n",
    "  def __call__(self, input, decode=True, encoding='utf-8'):\n",
    "    \n",
    "    # TODO: Bug with empty strings as input\n",
    "    tensor_input = tf.convert_to_tensor(input)\n",
    "\n",
    "    if len(tensor_input.shape) == 0:\n",
    "      tensor_input = tensor_input[tf.newaxis]\n",
    "\n",
    "\n",
    "    tokenized_input = self.tokenizer.tokenize(tensor_input).to_tensor()\n",
    "\n",
    "    enc_input = tokenized_input\n",
    "    context = self.transformer.encode(enc_input, None, training=False)\n",
    "\n",
    "    end = enc_input[-1][-1]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "\n",
    "    for i, value in enumerate(tokenized_input[0][:-1]):\n",
    "      output_array = output_array.write(i, value)\n",
    "    \n",
    "    out_init_len = output_array.size()\n",
    "\n",
    "    for i in tf.range(out_init_len, self.max_length):\n",
    "      dec_input = output_array.concat()[tf.newaxis]\n",
    "\n",
    "      decode = self.transformer.decode(context, None, dec_input, None, training=False)\n",
    "\n",
    "      predictions = self.transformer.generator(decode, training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "\n",
    "      output_array = output_array.write(i, predicted_id[0][0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = output_array.concat()[tf.newaxis]\n",
    "\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    text = self.tokenizer.detokenize(output)  # Shape: `()`.\n",
    "\n",
    "    tokens = self.tokenizer.lookup(output)\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    # self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    # attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    if self.decode_result:\n",
    "      text = text.numpy()[0].decode(encoding)\n",
    "\n",
    "    return text, tokens # , attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] hallo shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting shooting mighty mighty tf.Tensor(\n",
      "[[b'[START]' b'hall' b'##o' b'shooting' b'shooting' b'shooting'\n",
      "  b'shooting' b'shooting' b'shooting' b'shooting' b'shooting' b'shooting'\n",
      "  b'shooting' b'shooting' b'shooting' b'shooting' b'shooting' b'shooting'\n",
      "  b'shooting' b'shooting' b'shooting' b'shooting' b'shooting' b'shooting'\n",
      "  b'shooting' b'shooting' b'shooting' b'shooting' b'shooting' b'shooting'\n",
      "  b'mighty' b'mighty']], shape=(1, 32), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "inference_model = WordComplete(load_tokenizer(tokenizer_name), model, max_length=32)\n",
    "\n",
    "string = \"Hallo\"\n",
    "\n",
    "text, tokens = inference_model(string)\n",
    "\n",
    "print(text, tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_simu_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
