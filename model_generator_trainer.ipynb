{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- I finally understood, that during traingin each next token is calculated simultaneously for the whole sentence, such that no sequential processing is needed. That is of course redundant for inference. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging and decorators\n",
    "import logging as log\n",
    "import time\n",
    "\n",
    "# system tools\n",
    "import pathlib\n",
    "\n",
    "# general modules\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow modules\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "#from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
    "\n",
    "# necessary for visualization and user input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging settings\n",
    "log.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(processName)s %(threadName)s %(funcName)-20s %(message)s',\n",
    "        # log.INFO for normal run\n",
    "    level=log.INFO,\n",
    "        # log.DEBUG for diagnostics\n",
    "    # level=log.DEBUG,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# paths\n",
    "corpus_file_path = 'datasets\\\\corpus'\n",
    "bco_file_path = \"datasets\\\\bookscorpusopen\\\\epubtxt\"\n",
    "bco_compact_file_path = \"datasets\\\\bookscorpusopen\\\\processed_512\"\n",
    "tight_fit_512_dataset_path = 'datasets\\\\tight_fit'\n",
    "vocab_path = 'datasets\\\\vocab.txt'\n",
    "\n",
    "# tokenizer\n",
    "tokenizer_name = 'story_corpus_tokenizer'\n",
    "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(*args, **kwargs):\n",
    "    \"\"\"Placeholder for VisualWrapper\"\"\"\n",
    "    pass\n",
    "\n",
    "def clones(layer_class, N, **kwargs):\n",
    "    \"\"\"Produce N identical layers\"\"\"\n",
    "    log.debug(f'execute with class {layer_class.__class__.__name__} and N={N}')\n",
    "    return [layer_class(**kwargs) for layer_number in range(N)]\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"\"\"Mask out subsequent positions.\"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualWrapper():\n",
    "    \"\"\"This is a mixin-Class for the tensorflow layers that enable visualization during non-training sessions.\"\"\"\n",
    "    should_visualize = False # globally de-/enable visualization\n",
    "    instances = []          # save instances of VisualWrapper for reset_counter classmethod (see below)\n",
    "\n",
    "    def __init__(self, vis_on_count=None, enabler=False):\n",
    "        \"\"\"\n",
    "        Initialize a VisualWrapper instance.\n",
    "\n",
    "        Args:\n",
    "            vis_on_count (list, optional):  A list of counts on which to perform a visualizations. \n",
    "                                            If not provided, no operations will be performed on any count.\n",
    "            enabler (bool, optional):       A flag used to control whether visualization is enabled. \n",
    "                                            If False, it ensures no child class does perform any visualization.\n",
    "                                            Defaults to False.\n",
    "\n",
    "        The initialized instance is appended to the `VisualWrapper.instances` list, \n",
    "        the reset_counter classmethod resets the counters of all instances in the list.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        self.counter = 0\n",
    "        self.vis_on_count = vis_on_count if vis_on_count else []\n",
    "        self.enabler = enabler\n",
    "        VisualWrapper.instances.append(self)\n",
    "\n",
    "    def visualize_data(self, data_x, mode, training, text=None, data_y=None, vis_diff=False):\n",
    "        \"\"\"\n",
    "        Visualizes data_x (data_y) if tensorflow is not in training mode and global self.shoule_visualize is True.\n",
    "        This only happens while self.counter is in self.vis_on_count (counter is increased by 1 with every execution)\n",
    "\n",
    "        Args:\n",
    "            data_x (unspecific often tensors):              The data that is visualized. TODO: Implement type check, to catch errors in advance\n",
    "            mode (string):                                  One of the modes available in choose_func (see methods) to select the visualisation format.\n",
    "            training (bool):                                Boolean parameter used by tensorflow to differentiate training and inference.\n",
    "                                                            Only visualize when not in training mode.\n",
    "            text (string):                                  Explanatory text giving information about the visualisation data.\n",
    "                                                            Printed before visualisation is displayed.\n",
    "            data_y (unspecific often tensors, optional):    TODO: Implement for multiple data visualization\n",
    "            vis_diff (bool, optional):                      TODO: Implement for multiple data visualisation\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        if training is None:\n",
    "            if self.counter in self.vis_on_count:  \n",
    "                if self.should_visualize:\n",
    "                    log.debug(f'visualize as training={training}, vis_counter={self.counter}, vis_conters={self.vis_on_count}, global_visualize={self.should_visualize}')\n",
    "                    # if all checks for visualization are passed execute visualisation\n",
    "\n",
    "                    # print explanatory text\n",
    "                    tf.print(text)\n",
    "\n",
    "                    # choose the correct visualization function\n",
    "                    func = self.choose_func(mode)\n",
    "\n",
    "                    # apply visualization function to data_x\n",
    "                    func(data_x)\n",
    "\n",
    "                if self.enabler:\n",
    "                    # set class variable should_visualize if instance is an enabler\n",
    "                    VisualWrapper.should_visualize = True\n",
    "            else:\n",
    "                if self.enabler:\n",
    "                    # set class variable should_visualize if instance is an enabler\n",
    "                    VisualWrapper.should_visualize = False\n",
    "            self.counter += 1\n",
    "\n",
    "    def choose_func(self, mode):\n",
    "        \"\"\"\n",
    "        This function returns an executable function for the chosen 'mode'.\n",
    "\n",
    "        Args:\n",
    "            mode (string): The string indicating the visualization mode to apply.\n",
    "\n",
    "        Returns:\n",
    "            function: An executable function taking one input argument. This argument should be the data to be visualized.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        if mode == 'color_bar':\n",
    "            return lambda x: self.color_bar(x)\n",
    "        elif mode == 'print':\n",
    "            return lambda x: self.print_data(x)\n",
    "        elif mode == 'reduce_dim':\n",
    "            return lambda x: self.reduce_dim(x)\n",
    "        else:\n",
    "            # return a placeholder function, if no valid 'mode' is given.\n",
    "            return do_nothing\n",
    "\n",
    "    def color_bar(self, tensor):\n",
    "        \"\"\"\n",
    "        Use matplotlib to plot a colorbar that visualizes the values of a 1-D-tensor.\n",
    "\n",
    "        Args:\n",
    "            tensor (tf.tensor): The tensor to be visualized\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        # labels for the plot TODO: Generalize such that the labels are valid for all data types.\n",
    "        x_label = 'Positions'\n",
    "        y_label = 'Embbeddings'\n",
    "\n",
    "        # Assuming data[0] is a numpy array.\n",
    "        # If it's a ListWrapper or another list-like object, convert it to a numpy array.\n",
    "        # TODO: Doesn't work. Check for error.\n",
    "        tensor = np.array(tensor[0])\n",
    "\n",
    "        # If the array is 1D, reshape it into a 2D array with one column\n",
    "        if tensor.ndim == 1:\n",
    "            tensor = np.reshape(tensor, (-1, 1))\n",
    "\n",
    "        # Set the size of the plot (you can adjust the dimensions as needed)\n",
    "        plt.figure(figsize=(10, 2))\n",
    "\n",
    "        # Use imshow to create a color-coded visualization\n",
    "        plt.imshow(tensor, cmap='jet', aspect='auto')\n",
    "        plt.colorbar(label='Tensor Value')\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.show()\n",
    "        \n",
    "    def print_data(self,data):\n",
    "        log.debug(f'execute')\n",
    "        tf.print(data)\n",
    "\n",
    "    def reduce_dim(self, tensor):\n",
    "        \"\"\"\n",
    "        Reduces the dimensionality of the input tensor using PCA and plots the result.\n",
    "\n",
    "        This function first scales the input tensor by its minimum absolute value, then applies PCA to reduce its \n",
    "        dimensionality to 3. It then creates a 3D quiver plot of the reduced data.\n",
    "\n",
    "        Args:\n",
    "            tensor (np.ndarray): The input tensor to be reduced and visualized. \n",
    "\n",
    "        Shows:\n",
    "            A 3D matplotlib plot of the tensor after dimensionality reduction using PCA.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        # Reduce the first dimension, to create a 1-D numpy array.\n",
    "        array = np.squeeze(tensor, axis=0)\n",
    "\n",
    "        # Scale the array by its minimum absolute value to normalize the data\n",
    "        scaled_array = array / np.min(np.abs(array))\n",
    "\n",
    "        # Apply PCA for dimensionality reduction.\n",
    "        # This reduces the dimensions of the data to 3.\n",
    "        # TODO: PCA must be trained. Alternative algorithms could be tsne or umap.\n",
    "        pca = PCA(n_components=3)\n",
    "        reduced_array = pca.fit_transform(scaled_array)\n",
    "\n",
    "        # Create a new figure and a set of subplots. \n",
    "        # The figure size is set to (3,3) to maintain a square aspect ratio. \n",
    "        # TODO: Find best size for plot\n",
    "        fig, ax = plt.subplots(figsize=(3, 3))\n",
    "        # Add another subplot to create a 3D plot.\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Create a quiver plot to visualize each point as a vector from the origin\n",
    "        ax.quiver(0, 0, 0, reduced_array[:, 0], reduced_array[:, 1], reduced_array[:, 2], arrow_length_ratio=0.1)\n",
    "\n",
    "        # Label each component (PCA dimension) on the axes.\n",
    "        ax.set_xlabel('Component 1')\n",
    "        ax.set_ylabel('Component 2')\n",
    "        ax.set_zlabel('Component 3')\n",
    "        # Set a title for the plot\n",
    "        # TODO: Generalize the title\n",
    "        ax.set_title('Embeddings')\n",
    "\n",
    "        # Set the plot boundaries to be the maximum value in the reduced array.\n",
    "        boundaries = np.max(reduced_array)\n",
    "        ax.set_xlim([-boundaries, boundaries])\n",
    "        ax.set_ylim([-boundaries, boundaries])\n",
    "        ax.set_zlim([-boundaries, boundaries])\n",
    "\n",
    "        # Disply the plot\n",
    "        plt.show()\n",
    "\n",
    "    @classmethod\n",
    "    def reset_counter(cls):\n",
    "        \"\"\"Reset the counter for all instances of the class.\"\"\"\n",
    "        log.debug(f'execute')\n",
    "        for instance in cls.instances:\n",
    "            instance.counter = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classes are built using the Keras Functional API, which provides more flexibility than the Sequential API for defining complex models. Each class is a subclass of tf.keras.layers.Layer, so they can be composed to build more complex layers or models. The call method of each class defines the computation that the layer performs.\n",
    "\n",
    "These classes are designed to be components of a larger transformer model. The model itself is typically composed of an encoder and a decoder, each of which is made up of a stack of identical layers. The layers themselves contain sublayers that perform operations such as self-attention, source attention (in the case of the decoder), and position-wise feed-forward networks. These operations are encapsulated within classes like `EncoderStack`, `DecoderStack`, `EncoderLayer`, `DecoderLayer`, and `PositionwiseFeedForward`. The layer norm and dropout are applied in `ResidualSublayer` for regularizing and speeding up the training process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(tf.keras.Model, VisualWrapper):\n",
    "    \"\"\"\n",
    "    Defines a Transformer model for sequence-to-sequence tasks.\n",
    "\n",
    "    This class implements the Transformer architecture, which consists of an Encoder and Decoder, each built from multiple stacked self-attention and feedforward layers.\n",
    "    Inherits from both the TensorFlow Keras Model class for building ML models and a custom VisualWrapper class for data visualization.\n",
    "\n",
    "    Attributes:\n",
    "        encoder_stack (Encoder):                The encoder component of the Transformer.\n",
    "        decoder_stack (Decoder):                The decoder component of the Transformer.\n",
    "        enc_embed (tf.keras.layers.Embedding):  The input embedding layer for the encoder.\n",
    "        dec_embed (tf.keras.layers.Embedding):  The input embedding layer for the decoder.\n",
    "        generator (tf.keras.layers.Dense):      The output linear layer.\n",
    "\n",
    "    Note: We use two seperate embeddings, because the encoder get's the data with start token, while the decoder get's the data without start token.\n",
    "    Note: To receive actual output from the model it is necessary to run call on the input and then the generator on the output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_stack, decoder_stack, enc_embed, dec_embed, generator):\n",
    "        \"\"\"\n",
    "        Initialize the EncoderDecoder model together with the parent VisualWrapper.\n",
    "        The EncoderDecoder model is an visualization enabler, that means, that it enables visualization for all its sublayer, if self.counter in self.vis_on_count.\n",
    "\n",
    "        Args:\n",
    "            encoder_stack (layers.Layer):   A Encoder object, consisting of a stack of self-attention and feedforward layers.\n",
    "                                            The stack size is determined within the object.\n",
    "            decoder_stack (layers.Layer):   A Decoder object, consisting of a stack of self-attention, source-attention and feedforward layers.\n",
    "                                            The stack size is determined within the object.\n",
    "            enc_embed (layers.Layer):       An embedding layer for the encoder input.\n",
    "            dec_embed (layers.Layer):       An embedding layer for the decoder input.\n",
    "            generator (layers.Layer):       The final linear layer that generates predictions.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0], enabler=True)\n",
    "\n",
    "        self.encoder_stack = encoder_stack\n",
    "        self.decoder_stack = decoder_stack\n",
    "        self.enc_embed = enc_embed\n",
    "        self.dec_embed = dec_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def encode(self, inputs, pad_mask, training=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (Tensor):            Input data tensor to encode.\n",
    "            pad_mask (Tensor):          Mask tensor to ignore padding tokens in the input.\n",
    "            training (bool, optional):  Boolean flag indicating whether the model is in training mode. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Tensor:                     The output of the encoder stack.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        return self.encoder_stack(self.enc_embed(inputs), \n",
    "                                  pad_mask, \n",
    "                                  training=training)\n",
    "\n",
    "    def decode(self, enc_input, pad_mask, inputs, subseq_mask, training=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enc_input (Tensor):         Encoded input data tensor to decode.\n",
    "            pad_mask (Tensor):          Mask tensor to ignore padding tokens in the input.\n",
    "            inputs (Tensor):            Input data tensor for the decoder.\n",
    "            subseq_mask (Tensor):       Mask tensor to ignore subsequent tokens in the input.\n",
    "            training (bool, optional):  Boolean flag indicating whether the model is in training mode. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Tensor:                     The output of the decoder stack.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        return self.decoder_stack(self.dec_embed(inputs), \n",
    "                                  enc_input, \n",
    "                                  pad_mask, \n",
    "                                  subseq_mask, \n",
    "                                  training=training)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (tuple):             Tuple of Tensors (enc_input (Tensor, dtype=tf.float32), \n",
    "                                                          dec_input, (Tensor, dtype=tf.float32)\n",
    "                                                          pad_mask, (Tensor, dtype=tf.bool)\n",
    "                                                          subseq_mask(Tensor, dtype=tf.bool)\n",
    "                                                         ).\n",
    "            training (bool, optional):  Boolean flag indicating whether the model is in training mode. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output of the model.\n",
    "        \"\"\"\n",
    "        # We need to unpack the input, as tensorflows model.fit method requires the input to be passed as a single parameter,\n",
    "        # but it actually contains (enc_input, dec_input, pad_mask, subseq_mask) as a tuple.\n",
    "        enc_input, dec_input, pad_mask, subseq_mask = inputs\n",
    "\n",
    "        # the following is only used to visualize model input and output data\n",
    "        if not training: # Additional training = False check, such that calculations for execution are not conducted unless not training\n",
    "            input_emb_enc = self.enc_embed(enc_input)\n",
    "            input_emb_dec = self.dec_embed(dec_input)\n",
    "            self.visualize_data(input_emb_enc- input_emb_dec, mode='color_bar', training=training, text='The difference between the enc_emb and the dec_emb')\n",
    "\n",
    "        return self.decode(self.encode(enc_input, pad_mask, training), \n",
    "                           pad_mask,\n",
    "                           dec_input, \n",
    "                           subseq_mask, training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    Implements the Layer Normalization technique, a type of normalization performed on inputs across features.\n",
    "\n",
    "    Inherits from both the TensorFlow Keras Layer class for building custom layers, and a custom VisualWrapper class for data visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        features (int):             The size of the input data.\n",
    "            eps (float, optional):  A small constant added to the variance to avoid dividing by zero. Defaults to 1e-6.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "\n",
    "        # Initialize the scale and offset parameters\n",
    "        self.a_2 = self.add_weight(shape=(input_size,), initializer='ones', name=self.name + \"a_2\")\n",
    "        self.b_2 = self.add_weight(shape=(input_size,), initializer='zeros', name=self.name + \"b_2\")\n",
    "        self.eps = eps\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Performs the layer normalization on the input data.\n",
    "\n",
    "        Args:\n",
    "            input_tensor (Tensor):  The input data.\n",
    "\n",
    "        Returns:\n",
    "            norm_out (Tensor):      The normalized data.\n",
    "        \"\"\"\n",
    "        # Compute the mean and variance of the input data\n",
    "        mean, var = tf.nn.moments(input_tensor, axes=-1, keepdims=True)\n",
    "\n",
    "        # Compute the standard deviation\n",
    "        std = tf.math.sqrt(var + self.eps)\n",
    "\n",
    "        # Perform the layer normalization\n",
    "        norm_out = self.a_2 * (input_tensor - mean) / std + self.b_2\n",
    "\n",
    "        return norm_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSublayer(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    A layer that applies a sublayer to the input, followed by dropout, and then adds the input to the result.\n",
    "    This follows the 'pre-norm' variation of the Transformer architecture, where Layer Normalization is applied before the sublayer.\n",
    "\n",
    "    !!! This layer is used to wrap the attention sublayer and the feedforward layer in the encoder stack and decoder stack. !!!\n",
    "    \n",
    "    Inherits from both the TensorFlow Keras Layer class for building custom layers, and a custom VisualWrapper class for data visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size (int):         The number of features in the input data.\n",
    "            dropout (float):    The rate of dropout to apply after the sublayer.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, input_tensor, sublayer, training=None):\n",
    "        \"\"\"\n",
    "        Applies the sublayer to the input after normalization, applies dropout, and then adds the input to the result.\n",
    "\n",
    "        Args:\n",
    "            input_tensor (Tensor):      The input data.\n",
    "            sublayer (layers.Layer):    The sublayer to apply to the input data.\n",
    "            training (bool):            Indicates whether the layer should behave in training mode (apply dropout) or in inference mode (do not apply dropout).\n",
    "\n",
    "        Returns:\n",
    "            residual_out (Tensor): The output data.\n",
    "        \"\"\"\n",
    "        # Apply normalisation and sublayer\n",
    "        norm_input = self.norm(input_tensor)\n",
    "        sublayer_out = sublayer(norm_input)\n",
    "\n",
    "        # If visualization is enabled for the current step, compute the sublayer output with and without dropout and visualize the difference\n",
    "        # We need to check this additionally here, as we need to separately compute the dropout (dropout is only used during training not during inference),\n",
    "        # but we don't want to compute dropout twice, if not necessary.\n",
    "        if not training and self.counter in self.vis_on_count:\n",
    "            # compute dropout even when training=False\n",
    "            sublayer_dropout = self.dropout(sublayer_out, training=True)\n",
    "\n",
    "            self.visualize_data(sublayer_dropout-sublayer_out, \n",
    "                                mode=\"color_bar\", \n",
    "                                training=training, \n",
    "                                text=\"Visualize difference before/after dropout.\")\n",
    "            \n",
    "        # compute residual output by applying dropout to the sublayer output and adding to the input\n",
    "        residual_out = input_tensor + self.dropout(sublayer_out, training=training)\n",
    "\n",
    "        return residual_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    This class represents the Encoder part of the Transformer model, which is composed of a stack of identical layers.\n",
    "    Each layer in the Encoder Stack consists of two sub-layers: a Multi-head Self-Attention mechanism, and a Position-wise\n",
    "    Fully Connected Feed-Forward network.\n",
    "    A residual connection is employed around each of the two sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, N, size, **kwargs):\n",
    "        \"\"\"\n",
    "        Inititalize the EncoderStack instance\n",
    "        Args:\n",
    "            layer (layers.layer):   An instance of a layer, which will be cloned N times to form the encoder stack.\n",
    "            N (int):                The number of layers in the encoder stack.\n",
    "            size (int):             The dimensionality of the input/ouput space of the encoder.\n",
    "            **kwargs (various):     Additional keyword arguments. They contain the parameters of the layers in self.layers, such that they can\n",
    "                                    be passed to the clone function that initializes the layers.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.layers = clones(layer, N, size=size, **kwargs) # Creating N identical layer stacks to form the encoder\n",
    "        self.norm = LayerNorm(size)\n",
    "\n",
    "    def call(self, input_tensor, mask, training=None):\n",
    "        \"\"\"\n",
    "        This function propagates the input through the encoder stack, by applying succesively each layer in the self.layers attribute.\n",
    "        This is aquivalent to running the attention layer and the fully connected feed-forward layer N times, \n",
    "        before finally normalising and returning an output.\n",
    "\n",
    "        Args:\n",
    "            input_tensor (Tensor): The input to the encoder.\n",
    "            mask (Tensor of dtype tf.Boolean): A boolean mask tensor for padding positions within the input.\n",
    "            training (bool, None): A boolean indicating whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            (Tensor):              The output of the encoder stack.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            input_tensor = layer(input_tensor, mask, training=training)\n",
    "\n",
    "        encoder_out = self.norm(input_tensor, training=training)\n",
    "\n",
    "        return encoder_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    This class represents a single layer within the Encoder stack of the Transformer model.\n",
    "    Each EncoderLayer consists of two sub-layers: \n",
    "        - a Multi-head Self-Attention mechanism, \n",
    "        - a Position-wise Fully Connected Feed-Forward network.\n",
    "    A residual connection is employed around each of the two sub-layers.\n",
    "    \n",
    "    Note:   The residual sublayers do themselves not contain sublayers, because of two reasons:\n",
    "                - Like that we can clone the ResidualSublayer, instead of having to write out each single sublayer\n",
    "                - During forward pass, we need to pass different information to the sublayers e.g. mask, training, x, context.\n",
    "                  This process is simplified if the ResidualSublayer can be skipped.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        \"\"\"\n",
    "        Initializes the EncoderLayer\n",
    "        Args:\n",
    "            size (int):                    The dimensionality of the input/output space of the encoder.\n",
    "            self_attn (layers.Layer):      The Multi-head Self-Attention mechanism.\n",
    "            feed_forward (layers.Layer):   The Position-wise Fully Connected Feed-Forward network.\n",
    "            dropout (float):               The dropout rate to be applied to the output during training.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(ResidualSublayer, \n",
    "                               N=2, \n",
    "                               size=size, \n",
    "                               dropout=dropout)\n",
    "\n",
    "    def call(self, input_tensor, mask, training=None):\n",
    "        \"\"\"\n",
    "        This function propagates the input through the attention layer and the feed-forward layer.\n",
    "\n",
    "        The Self-Attention mechanism (sublayer[0]) takes three times the input_tensor as input for query, key, value\n",
    "        it hiddes the padding through a padding mask, passed through the mask argument, and returns the rearranged output.\n",
    "\n",
    "        The Feed-Forward network takes the output of the Self-Attention mechanism and creates meaningful information for the next Encoder-Layer.\n",
    "        \n",
    "        Args:\n",
    "            input_tensor (Tensor):              The input to the encoder layer.\n",
    "            mask (Tensor of dtype tf.Boolean):  A boolean mask tensor for padding positions within the input.\n",
    "            training (bool, optional):          A boolean indicating whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            ff_output (Tensor):                 The output of the encoder layer.\n",
    "        \"\"\"\n",
    "        attn_output = self.sublayer[0](input_tensor, \n",
    "                                        lambda x: self.self_attn(x, x, x, \n",
    "                                                                 mask, \n",
    "                                                                 training=training), \n",
    "                                        training=training)\n",
    "        ff_output = self.sublayer[1](attn_output, \n",
    "                                     lambda x: self.feed_forward(x, \n",
    "                                                                 training=training), \n",
    "                                     training=training)\n",
    "        return ff_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    This class represents the Decoder part of the Transformer model, which is composed of a stack of identical layers.\n",
    "    Each layer in the Decoder Stack consists of three sub-layers: \n",
    "        - a Masked Multi-head Self-Attention mechanism, \n",
    "        - a Multi-head Self-Attention mechanism over the Encoder's output,\n",
    "        - a Position-wise Fully Connected Feed-Forward network.\n",
    "    A residual connection is employed around each of the three sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, N, size, **kwargs):\n",
    "        \"\"\"\n",
    "        Inititalize the DecoderStack instance\n",
    "        Args:\n",
    "            layer (layers.layer):   An instance of a layer, which will be cloned N times to form the decoder stack.\n",
    "            N (int):                The number of layers in the decoder stack.\n",
    "            size (int):             The dimensionality of the input/output space of the decoder.\n",
    "            **kwargs (various):     Additional keyword arguments. They contain the parameters of the layers in self.layers, such that they can\n",
    "                                    be passed to the clone function that initializes the layers.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.layers = clones(layer, N, size=size, **kwargs)\n",
    "        self.norm = LayerNorm(size)\n",
    "\n",
    "    def call(self, input_tensor, enc_memory_tensor, src_mask, tgt_mask, training=None):\n",
    "        \"\"\"\n",
    "        This function propagates the input through the decoder stack, by applying succesively each layer in the self.layers attribute.\n",
    "        This is equivalent to running the masked attention layer, the attention layer over the encoder's output, \n",
    "        and the fully connected feed-forward layer N times, before finally normalising and returning an output.\n",
    "\n",
    "        Args:\n",
    "            input_tensor (Tensor):                  The input to the decoder.\n",
    "            enc_memory_tensor (Tensor):             The output of the encoder, serves as the \"memory\" in the Transformer model.\n",
    "            src_mask (Tensor of dtype tf.Boolean):  A boolean mask tensor for padding positions within the source input.\n",
    "            tgt_mask (Tensor of dtype tf.Boolean):  A boolean mask tensor for padding and preventing \"future\" information \n",
    "                                                    in attenting to the source input.\n",
    "            training (bool, None):                  A boolean indicating whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            decoder_out (Tensor):                   The output of the decoder stack.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            input_tensor = layer(input_tensor, \n",
    "                                 enc_memory_tensor, \n",
    "                                 src_mask, tgt_mask, \n",
    "                                 training=training)\n",
    "            \n",
    "        decoder_out = self.norm(input_tensor, training=training)\n",
    "        \n",
    "        return decoder_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    This class represents a single layer within the Decoder stack of the Transformer model.\n",
    "    Each DecoderLayer consists of three sub-layers:\n",
    "        - a Masked Multi-head Self-Attention mechanism,\n",
    "        - a Multi-head Self-Attention mechanism that interacts with the output of the encoder,\n",
    "        - a Position-wise Fully Connected Feed-Forward network.\n",
    "    A residual connection is employed around each of the three sub-layers.\n",
    "    \n",
    "    Note: The residual sublayers do not themselves contain sublayers, because of two reasons:\n",
    "      - This way, we can clone the ResidualSublayer, instead of having to write out each single sublayer.\n",
    "      - During the forward pass, we need to pass different information to the sublayers e.g. masks, training, context. \n",
    "        This process is simplified if the ResidualSublayer can be skipped.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        \"\"\"\n",
    "        Initializes the DecoderLayer\n",
    "        Args:\n",
    "            size (int):                    The dimensionality of the input/output space of the decoder.\n",
    "            self_attn (layers.Layer):      The Masked Multi-head Self-Attention mechanism.\n",
    "            src_attn (layers.Layer):       The Masked Multi-head Source-Attention mechanism that interacts with the encoder output.\n",
    "            feed_forward (layers.Layer):   The Position-wise Fully Connected Feed-Forward network.\n",
    "            dropout (float):               The dropout rate to be applied to the output during training.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(ResidualSublayer, N=3, size=size, dropout=dropout)\n",
    "\n",
    "    def call(self, input_tensor, enc_memory, src_mask, tgt_mask, training=None):\n",
    "        \"\"\"\n",
    "        This function propagates the input through the decoder layer.\n",
    "\n",
    "        The Masked Self-Attention mechanism (sublayer[0]) takes three times the input_tensor as input for query, key, value.\n",
    "        It hides the padding and future positions from affecting the current token's attention calculation through a combined padding and lookahead mask, \n",
    "        passed through the tgt_mask argument, and returns the rearranged output.\n",
    "\n",
    "        The Encoder-Decoder Attention mechanism (sublayer[1]) takes the output from the previous Masked Self-Attention mechanism as the query and the encoder \n",
    "        output (memory) as both the key and the value. It also employs a padding mask (src_mask) on the encoder output and returns the attention-combined output.\n",
    "\n",
    "        The Feed-Forward network (sublayer[2]) takes the output of the Encoder-Decoder Attention mechanism and creates meaningful information for the next Decoder-Layer.\n",
    "        \n",
    "        Args:\n",
    "            input_tensor (Tensor):                             The input to the decoder layer.\n",
    "            enc_memory (Tensor):                        The output of the encoder, serves as the \"memory\" in the Transformer model.\n",
    "            src_mask (Tensor of dtype tf.Boolean):  A boolean mask tensor for padding positions within the source input.\n",
    "            tgt_mask (Tensor of dtype tf.Boolean):  A boolean mask tensor for padding and preventing \"future\" information in self-attention mechanism within the target input.\n",
    "            training (bool, optional):              A boolean indicating whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            ff_out (Tensor):                The output of the decoder layer.\n",
    "        \"\"\"\n",
    "        self_attn_out = self.sublayer[0](input_tensor, \n",
    "                                         lambda x: self.self_attn(x, x, x, \n",
    "                                                                  tgt_mask, \n",
    "                                                                  training=training),\n",
    "                                         training=training)\n",
    "        src_attn_out = self.sublayer[1](self_attn_out, \n",
    "                                        lambda x: self.src_attn(x, enc_memory, enc_memory, \n",
    "                                                                src_mask,\n",
    "                                                                training=training),\n",
    "                                        training=training)\n",
    "        ff_out = self.sublayer[2](src_attn_out, \n",
    "                                  lambda x: self.feed_forward(x,\n",
    "                                                              training=training),\n",
    "                                  training=training)\n",
    "\n",
    "        return ff_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sublayers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    Implements the Position-wise Feed-Forward Network (FFN) for the Transformer model.\n",
    "    The FFN consists of two fully connected layers with a ReLU activation in between.\n",
    "\n",
    "    Attributes:\n",
    "        dense_in (Dense):    First dense layer.\n",
    "        dense_out (Dense):   Second dense layer.\n",
    "        dropout (Dropout):   Dropout layer.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                d_model (int):      Output dimensionality of the Transformer.\n",
    "                d_ff (int):         Inner-layer dimensionality.\n",
    "                dropout (float):    Dropout rate after the ReLU activation.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.dense_in = layers.Dense(d_ff)\n",
    "        self.dense_out = layers.Dense(d_model)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, input_tensor, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the FFN. Applies both layers and ReLU activation to the input tensor.\n",
    "        Dropout inbetween the layers, as the ResidualLayer that wraps around will again perform a dropout\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "            training (bool, optional): Indicates whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            (Tensor): Output tensor.\n",
    "        \"\"\"\n",
    "        return self.dense_out(self.dropout(tf.nn.relu(self.dense_in(input_tensor)), training=training))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    This class serves as the final layer of the Transformer model, generating the predicted output.\n",
    "    It applies a dense layer to the final output of the Transformer model and then a log softmax function \n",
    "    across the vocabulary dimension. This results in a distribution over the possible output tokens for each \n",
    "    position in the sequence, where the value of each token is the log probability of that token being the \n",
    "    output for that position.\n",
    "\n",
    "    Attributes:\n",
    "        proj (Dense): Dense layer that is applied to the final output of the Transformer model. It increases \n",
    "        the dimensionality of the input to be the size of the vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab (int): Size of the output vocabulary.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "\n",
    "        self.proj = layers.Dense(vocab)\n",
    "\n",
    "    def call(self, input_tensor, training=None):\n",
    "        \"\"\"\n",
    "        This method applies the Dense layer and log softmax function to its input.\n",
    "        \n",
    "        Args:\n",
    "            input_tensor (Tensor):      The input tensor, which is the final output from the Transformer model.\n",
    "            training (bool, optional):  Indicates whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            result (Tensor):    A tensor of the same shape as the input, but the last dimension is now the size \n",
    "                                of the vocabulary. Each value in this tensor is the log probability of the corresponding token \n",
    "                                being the output for the position in the sequence.\n",
    "        \"\"\"\n",
    "        result = tf.nn.log_softmax(self.proj(input_tensor), axis=-1)\n",
    "\n",
    "        if not training:\n",
    "            self.visualize_data(result, \n",
    "                                'color_bar', \n",
    "                                text=f\"This is the data from {self.__class__.__name__}\", \n",
    "                                training=training)\n",
    "        return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Layer\n",
    "\n",
    "- If you try to understand this code, start with the MultiHeadAttention class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None, training=None):\n",
    "    \"\"\"\n",
    "    Compute 'Scaled Dot Product Attention'\n",
    "\n",
    "    The attention function computes a weighted sum of the value vectors, with the weights being determined by the similarity of the\n",
    "    query vector with the corresponding key vector. The dot product of the query and key serves as the measure of similarity, and is scaled\n",
    "    by the square root of the dimension of the key vector to avoid the issue of the dot product growing large for large dimensions.\n",
    "\n",
    "    Args:\n",
    "        query, key, value (Tensor):                     The query, key and value vectors. \n",
    "                                                        These typically have shape (batch_size, num_heads, seq_len, depth).\n",
    "                                                        (seq_len as we want to calculate the attention for each position simultaneously)\n",
    "        mask (Tensor of dtype tf.Boolean, optional):    A mask to apply to the attention scores before softmax, \n",
    "                                                        in order to prevent attention to certain positions. \n",
    "                                                        The shape should be broadcastable to shape (batch_size, num_heads, seq_len, seq_len???).\n",
    "        dropout (Dropout, optional):                    Dropout layer to apply to the attention scores after softmax.\n",
    "        training (bool, optional):                      Whether the model is in training mode.\n",
    "\n",
    "    Returns:\n",
    "        output (Tensor):                                The result of applying attention mechanism to the value vectors.\n",
    "        p_attn (Tensor):                                The attention weights after applying softmax and dropout.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    # Compute the dot product of the query and key vectors and scale by sqrt(d_k)\n",
    "    d_k = tf.cast(query.shape[-1], dtype=tf.float32)\n",
    "    scores = tf.matmul(query, tf.transpose(key, perm=[0, 1, 3, 2])) / tf.sqrt(d_k)\n",
    "\n",
    "    # Apply the mask to the scores before softmax\n",
    "    if mask is not None:\n",
    "        mask = tf.cast(mask, dtype=tf.bool)\n",
    "        scores = tf.where(mask, scores, tf.fill(tf.shape(scores), -1e9))\n",
    "\n",
    "    # Apply softmax to the scores to get the attention weights\n",
    "    p_attn = tf.nn.softmax(scores, axis=-1)\n",
    "\n",
    "    # Apply dropout to the attention weights\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn, training=training)\n",
    "\n",
    "    # Compute the weighted sum of the value vectors, using the attention weights\n",
    "    attn_out = tf.matmul(p_attn, value)\n",
    "\n",
    "    return attn_out, p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    MultiHeadedAttention layer is a key part of the Transformer model, enabling it to pay attention to different parts of the input for each output.\n",
    "    This is achieved by having multiple 'heads', each of which independently computes a scaled dot product attention over the input.\n",
    "    The outputs of these heads are then concatenated and linearly transformed to produce the final output.\n",
    "\n",
    "    Attributes:\n",
    "        d_k (int):                          Dimensionality of the query, key, and value vectors, \n",
    "                                            which should be identical for each head.\n",
    "        h (int):                            Number of heads.\n",
    "        query, key, value, linear (Dense):  These are the layers that perform the linear transformations for the input.\n",
    "        attn (Tensor, optional):            Tensor storing the attention values from the last forward pass.\n",
    "        dropout (Dropout):                  Dropout layer applied after the attention.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h (int):                    Number of attention heads.\n",
    "            d_model (int):              Dimensionality of the model.\n",
    "            dropout (float, optional):  Dropout rate.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0, 1])\n",
    "\n",
    "        assert d_model % h == 0 # make sure the number of attention heads are such that they can equally distribute over the input tensor\n",
    "        self.d_k = d_model // h # determine the size for the attention heads\n",
    "        self.h = h\n",
    "        self.query, self.key, self.value, self.linear = clones(layers.Dense, N=4, units=d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, query, key, value, mask=None, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the MultiHeadedAttention layer.\n",
    "        Applies linear transformations to the input, applies scaled dot product attention, then applies dropout, concatenates the heads,\n",
    "        and applies a final linear transformation.\n",
    "\n",
    "        Args:\n",
    "            query, key, value (Tensor):                     Input tensors. Value and query are (in our case) always the same.\n",
    "            mask (Tensor of dtype tf.Boolean, optional):    Boolean mask tensor for padding positions within the input.\n",
    "            training (bool, optional):                      Indicates whether to run the layer in training mode or inference mode.\n",
    "\n",
    "        Returns:\n",
    "            result (Tensor):                                The output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads\n",
    "            mask = tf.expand_dims(mask, 1)\n",
    "\n",
    "        # find out how many batches are processed in parallel\n",
    "        nbatches = tf.shape(query)[0]\n",
    "\n",
    "        # Transform the input data into a shape that can be used as matrix input for the attention function.\n",
    "        # The original size is d_model, the trainable matrices self.query, self.key, self.value transform this input tensor\n",
    "        # into a tensor of the same size, but now we have to think of it as being of size h * d_k. Such that each section of size d_k,\n",
    "        # will be passed through the attention mechanism independently. That is why all this transformations have to be done afterwards.\n",
    "        # [nbatches, -1, self.h, self.d_k] does split the tensor into h smaller tensors of size d_k \n",
    "        # (nbatches is only there for working with batches of data). The Permutation ensures, that the h tensors are of shape (1, d_k), \n",
    "        # such that they can be processed.\n",
    "        query, key, value = [\n",
    "            tf.transpose(tf.reshape(lin_layer(input), [nbatches, -1 , self.h, self.d_k]), perm=[0, 2, 1, 3]) \n",
    "            for lin_layer, input in zip([self.query, self.key, self.value], (query, key, value))\n",
    "        ]\n",
    "\n",
    "        att_out, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout, training=training)\n",
    "\n",
    "        # Now we reverse the whole process and reshape the output into vectors of shape (nbatches, 1, d_model) again.\n",
    "        att_out = tf.reshape(tf.transpose(att_out, perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\n",
    "\n",
    "        # visualization functions\n",
    "        if not training:\n",
    "            self.visualize_data(att_out, \n",
    "                                mode=\"color_bar\",\n",
    "                                training=training,\n",
    "                                text=f\"This is the output of {self.__class__.__name__}.\")\n",
    "            self.visualize_data(self.attn,\n",
    "                                mode=\"color_bar\",\n",
    "                                training=training,\n",
    "                                text=f\"This is the attention applied by {self.__class__.__name__}\")\n",
    "\n",
    "        # This finally mixes the results of the different heads together into one output vector\n",
    "        linear_output = self.linear(att_out)\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    \"\"\"\n",
    "    Generate positional encoding for a given length and depth to provide positional information.\n",
    "    Positional encoding is a technique where each position in the input sequence is assigned a \n",
    "    unique vector representation.\n",
    "\n",
    "    The encoding vector alternates between the sine and cosine functions of different \n",
    "    frequencies, which allows the model to distinguish the position of the inputs.\n",
    "\n",
    "    The positional encoding function uses a specific ratio to scale down the angle rates \n",
    "    exponentially (1 / (10000**(depth/depth))). It means that for lower dimensions in the \n",
    "    positional encoding, the angle rate is high which means the positional encoding is \n",
    "    changing rapidly for lower dimensions. For higher dimensions, the angle rate is low \n",
    "    which means the positional encoding is changing slowly. It gives a balance between \n",
    "    low and high frequency information.\n",
    "\n",
    "    Args:\n",
    "        length (int):   Length of the sequence for which positional encoding is to be generated.\n",
    "        depth (int):    The number of dimensions for the positional encoding. Equals the embedding size.\n",
    "\n",
    "    Returns:\n",
    "        Tensor:         A 2D Tensor of shape (length, depth) containing the positional encoding vectors.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]    # Creates a numpy array of shape (sequence_length, 1)\n",
    "                                                    # filled with the numbers 1 to sequence length\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth  # Creates a numpy array of shape (1, depth/2)\n",
    "                                                    # filled with the numbers 1 to depth/2 divided by depth\n",
    "\n",
    "    angle_rates = 1 / (10000**depths) \n",
    "    angle_rads  = positions * angle_rates           # broadcasting such that now element [i,j] is pos(i) * angle(j)\n",
    "\n",
    "    # as we have above chosen depth/2 we can now concatenate sines and cosines to aquire an vectore of size depth\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    A Keras layer to apply positional encoding on top of embeddings.\n",
    "\n",
    "    This layer creates embeddings for discret input vectors created by a tokenizer\n",
    "    and applies positional encoding to these embeddings to provide positional information.\n",
    "    The positional encoding is pre-computed in the constructor for efficiency and it is added to the output \n",
    "    of the embedding layer in the `call` method. The dropout is used to train the embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, dropout):\n",
    "        \"\"\"\n",
    "        Initializes Positional Embeddings\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int):   The size of the input token vector.\n",
    "            d_model (int):      The dimension used for the embeddings and positional encoding passed to the model.\n",
    "            dropout (float):    Value used for dropout.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0,1,2])\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "\n",
    "        # calculate positional encoding\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def call(self, input_token_vec, training=None):\n",
    "        \"\"\"\n",
    "        Performs the forward pass for the embedding and positional encoding layers.\n",
    "        \n",
    "        Args:\n",
    "            input_token_vec (Tensor):   Input tensor of shape `(batch_size, sequence_length)`.\n",
    "            training (bool, optional):  Indicator for the mode (training or inference) of the model.\n",
    "\n",
    "        Returns:\n",
    "            y (Tensor):     The output tensor after applying embedding, positional encoding, and dropout. \n",
    "                            It has the shape of `(batch_size, sequence_length, d_model)`.\n",
    "        \"\"\"\n",
    "\n",
    "        length = tf.shape(input_token_vec)[1]\n",
    "\n",
    "        x_emb = self.embedding(input_token_vec) # is now a tensor of shape (batch_size, length, d_model)\n",
    "        x_emb_scale = x_emb * tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # This factor sets the relative scale of the embedding and positional_encoding\n",
    "        \n",
    "        y = self.dropout(x_emb_scale + self.pos_encoding[tf.newaxis, :length, :])\n",
    "\n",
    "        if not training:\n",
    "            self.visualize_data(x_emb, \n",
    "                                mode='color_bar', \n",
    "                                text=f\"This is the embedding of the input to {self.__class__.__name__}.\", \n",
    "                                training=training)\n",
    "            self.visualize_data(y, \n",
    "                                mode='color_bar', \n",
    "                                text=f\"This is the embedding of the input to {self.__class__.__name__} with added positional encoding.\", \n",
    "                                training=training)\n",
    "            self.visualize_data(x_emb-y, \n",
    "                                mode='color_bar', \n",
    "                                text=f\"Here you can see the difference between both.\", \n",
    "                                training=training)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryTokenizer(tf.Module, VisualWrapper):\n",
    "    \"\"\"\n",
    "    The StoryTokenizer class is designed to perform tokenization and detokenization tasks using the BERT tokenizer.\n",
    "    \n",
    "    Methods:\n",
    "        tokenize:               Tokenize a string with BERT Tokenizer, add [Start] and [End] tokens.\n",
    "        detokenize:             Detokenize a token vector, clean the string of the reserved tokens.\n",
    "        lookup:                 Return the tokens a string is composed of.\n",
    "        add_start_end:          Add [Start], [End] toknes to a raggend token vector.\n",
    "        cleanup_text:           Remove reserved tokens from a string.\n",
    "        get_vocab_size:         Return the length of the vocabulary used by the tokenizer.\n",
    "        get_vocab_path:         Return the path of the vocabulary filee.\n",
    "        get_reserved_tokens:    Return a list of all reserved tokens.\n",
    "    \"\"\"\n",
    "    def __init__(self, reserved_tokens, vocab_path):    \n",
    "        \"\"\"\n",
    "        Initialize a StoryTokenizer\n",
    "\n",
    "        Args:\n",
    "            reserved_tokens (list of strings):  A list of strings with special tokens\n",
    "            vocab_path (string):                The path to the vocabulary file\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "\n",
    "        self.tokenizer = tf_text.BertTokenizer(vocab_path, lower_case=True)\n",
    "        self._reserved_tokens = reserved_tokens\n",
    "        self._vocab_path = tf.saved_model.Asset(vocab_path)\n",
    "\n",
    "        # read in the vocabulary from file.\n",
    "        vocab = pathlib.Path(vocab_path).read_text(encoding='utf-8').splitlines()\n",
    "        self.vocab = tf.Variable(vocab)        \n",
    "\n",
    "    def tokenize(self, strings, training=None):\n",
    "        \"\"\"\n",
    "        Tokenizes the input strings and adds start and end tokens.\n",
    "\n",
    "        Args:\n",
    "            strings (tf.Tensor):        The strings to be tokenized.\n",
    "            training (bool, optional):  If True, the model is in training mode. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            out (tf.RaggedTensor):      The tokenized strings with added start and end tokens.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        encoded = self.tokenizer.tokenize(strings)\n",
    "        merged_enc = encoded.merge_dims(-2, -1)\n",
    "        out = self.add_start_end(merged_enc)\n",
    "\n",
    "        if not training:\n",
    "            self.visualize_data(self.lookup(out),\n",
    "                                mode='print', \n",
    "                                text=f\"This is the data from {self.__class__.__name__}\", \n",
    "                                training=training)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def detokenize(self, tokenized, training=None):\n",
    "        \"\"\"\n",
    "        Detokenizes the input token IDs back into text strings.\n",
    "        Any reserved tokens (except for \"[UNK]\") are removed from the detokenized text.\n",
    "\n",
    "        Args:\n",
    "            tokenized (tf.RaggedTensor): The token IDs to be detokenized.\n",
    "            training (bool, optional): If True, the model is in training mode. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The detokenized text.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        words = self.tokenizer.detokenize(tokenized)\n",
    "        return self.cleanup_text(self._reserved_tokens, words)\n",
    "    \n",
    "    def lookup(self, token_ids):\n",
    "        \"\"\"\n",
    "        Converts token IDs to their corresponding token strings from the vocabulary.\n",
    "\n",
    "        Args:\n",
    "            token_ids (tf.RaggedTensor or tf.Tensor): The token IDs to be converted.\n",
    "\n",
    "        Returns:\n",
    "            tf.RaggedTensor or tf.Tensor: The corresponding token strings.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        return tf.gather(self.vocab, token_ids)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_start_end(ragged):\n",
    "        \"\"\"\n",
    "        Adds start and end tokens to the input token IDs.\n",
    "\n",
    "        Args:\n",
    "            ragged (tf.RaggedTensor): The input token IDs.\n",
    "\n",
    "        Returns:\n",
    "            tf.RaggedTensor: The token IDs with added start and end tokens.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        # Create vectores for the [Start] and [End] tokens.\n",
    "        START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n",
    "        END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n",
    "\n",
    "        # fill up dim 0 and concat in dim 1 to handle batches.\n",
    "        count = ragged.bounding_shape()[0]\n",
    "        starts = tf.fill([count, 1], START)\n",
    "        ends = tf.fill([count, 1], END)\n",
    "        return tf.concat([starts, ragged, ends], axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanup_text(reserved_tokens, token_txt):\n",
    "        \"\"\"\n",
    "        Removes any reserved tokens (except for \"[UNK]\") from the input text.\n",
    "\n",
    "        Args:\n",
    "            reserved_tokens (list of str): The list of reserved tokens.\n",
    "            token_txt (tf.Tensor): The input text.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The cleaned up text.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        # Create a regular expression searching for reserved tokens\n",
    "        bad_tokens = list(filter(lambda token: token != \"[UNK]\", reserved_tokens))\n",
    "        bad_tokens_re = \"|\".join(bad_tokens)\n",
    "\n",
    "        # Search and delete reserved tokens from the token_txt tensor\n",
    "        bad_cells = tf.strings.regex_full_match(token_txt, bad_tokens_re)\n",
    "        ragged_result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n",
    "\n",
    "        # join the text\n",
    "        result = tf.strings.reduce_join(ragged_result, separator=' ', axis=-1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return tf.shape(self.vocab)[0]\n",
    "    \n",
    "    def get_vocab_path(self):\n",
    "        return self._vocab_path\n",
    "    \n",
    "    def get_reserved_tokens(self):\n",
    "        return tf.constant(self._reserved_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_text_file):\n",
    "    \"\"\"\n",
    "    Load a text file as a TensorFlow dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_text_file (str): Path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: Dataset of lines from the text file.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    return tf.data.TextLineDataset(filenames=dataset_text_file)\n",
    "\n",
    "def create_vocab(dataset, reserved_tokens, vocab_size):\n",
    "    \"\"\"\n",
    "    Create a vocabulary from a dataset using the BERT tokenizer.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset):      Dataset of text lines to create the vocabulary from.\n",
    "        reserved_tokens (str list):     A list of reserved token strings.\n",
    "        vocab_size (int):               The size of the to be created vocab\n",
    "\n",
    "    Returns:\n",
    "        list of str: The created vocabulary.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    bert_vocab_args=dict(\n",
    "        vocab_size = vocab_size,\n",
    "        reserved_tokens = reserved_tokens,\n",
    "        bert_tokenizer_params = dict(lower_case=True),\n",
    "        learn_params = {},\n",
    "    )\n",
    "\n",
    "    story_vocab = bert_vocab.bert_vocab_from_dataset(\n",
    "        dataset.batch(1000).prefetch(2),\n",
    "        **bert_vocab_args\n",
    "    )\n",
    "    return story_vocab\n",
    "\n",
    "def create_vocab_from_textdata(text_file=corpus_file_path):\n",
    "    \"\"\"\n",
    "    Create a vocabulary from a text file.\n",
    "\n",
    "    Args:\n",
    "        text_file (str): Path to the text file to create the vocabulary from.\n",
    "\n",
    "    Returns:\n",
    "        list of str: The created vocabulary.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    dataset = load_dataset(text_file)\n",
    "    vocab = create_vocab(dataset, reserved_tokens, 8000)\n",
    "    return vocab\n",
    "\n",
    "def write_vocab_file(filepath, vocab):\n",
    "    \"\"\"\n",
    "    Write a vocabulary to a file, one token per line.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the file to write the vocabulary to.\n",
    "        vocab (list of str): The vocabulary to write.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    with open(filepath, 'w') as file:\n",
    "        for token in vocab:\n",
    "            print(token, file=file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator():\n",
    "    \"\"\"\n",
    "    A class to generate TensorFlow datasets for Transformer models from text files.\n",
    "    The txt_files_to_lines_gen generates lines, that are fitted into a certain length by\n",
    "    lines_to_fit_sentences (it combines follow-up sentences, if they don't exceed the limit together)..\n",
    "    generate_datasets and prepare_datapoint are used to generate the kind of data necessary for our model:\n",
    "    (src, tgt, src_mask, tgt_mask), label. Here src, tgt and label are similar tensors, but shifted right or left\n",
    "    and with or without [Start] or [End] tokens. The src_mask is a padding mask and the tgt_mask is a subsequent mask.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tokenizer, \n",
    "                 buffer_size=20000, \n",
    "                 batch_size=64,\n",
    "                 train_val_test_size = (0, 0, 0),\n",
    "                 max_padding=512, \n",
    "                 pad_id=0):\n",
    "        \"\"\"\n",
    "        Constructor for the DatasetGenerator class.\n",
    "        \n",
    "        Args:\n",
    "            tokenizer:          Instance of the tokenizer to be used.\n",
    "            buffer_size (int):  Number of elements from the dataset from which the new dataset will sample.\n",
    "                                This is crucial for randomisation, as the dataset is not shuffled further than buffer_size allows.\n",
    "            batch_size (int):   Number of elements per batch in the dataset.\n",
    "            max_padding (int):  The maximum sequence length, shorter sequences will be padded with pad_id.\n",
    "            pad_id (int):       ID to be used for padding shorter sequences.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size, self.val_size, self.test_size = train_val_test_size\n",
    "        self.max_padding = max_padding\n",
    "        self.pad_id = pad_id\n",
    "        self.dataset = None\n",
    "\n",
    "    def txt_files_to_lines_gen(self, file_path):\n",
    "        \"\"\"\n",
    "        Generator function that yields lines from text files in a directory.\n",
    "\n",
    "        Args:\n",
    "            file_path (str):    Path to the directory containing the text files.\n",
    "\n",
    "        Yields:\n",
    "            str:                A line from a text file.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        path = pathlib.Path(file_path)\n",
    "\n",
    "        for file in path.iterdir():\n",
    "            if file.is_file():\n",
    "                with open(file, 'r', encoding='utf-8') as f:\n",
    "                    for line in f:\n",
    "                        yield line.strip()\n",
    "\n",
    "    def lines_to_fit_sentences(self, sentences, length):\n",
    "        \"\"\"\n",
    "        Generator function that combines sentences so that the combined sentence is close to a certain length.\n",
    "        \n",
    "        Args:\n",
    "            sentences (iterator):   An iterator that yields sentences.\n",
    "            length (int):           The maximum length for combined sentences.\n",
    "            \n",
    "        Yields:\n",
    "            str:                    A combined sentence.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        length = length / 1.5 # estimate of token/word ratio (in real the value is about 1.4)\n",
    "\n",
    "        current_combined_sentence = \"\"\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()  # Remove leading/trailing whitespace\n",
    "            sentence_words = sentence.split()\n",
    "\n",
    "            # Check if combining the current sentence with the previous one exceeds the word limit\n",
    "            if len(current_combined_sentence.split()) + len(sentence_words) > length:\n",
    "                yield current_combined_sentence\n",
    "                current_combined_sentence = sentence  # Start a new combined sentence\n",
    "            else:\n",
    "                current_combined_sentence += \" \" + sentence  # Concatenate the sentences\n",
    "    \n",
    "    def generate_dataset(self, file_path, train_val_test_size = None):\n",
    "        \"\"\"\n",
    "        Generates a tokenized, batched TensorFlow dataset from text files.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the directory containing the text files.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: The generated dataset. It contains the following data: (src, tgt, src_mask, tgt_mask), label\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "\n",
    "        if train_val_test_size is not None:\n",
    "            self.train_size, self.val_size, self.test_size = train_val_test_size\n",
    "\n",
    "        # Create a Dataset from the text file\n",
    "        lines_gen = self.txt_files_to_lines_gen(file_path)\n",
    "        fit_sentence_gen = self.lines_to_fit_sentences(lines_gen, 512)\n",
    "        log.debug(f'generators set up')\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_generator(lambda: fit_sentence_gen, \n",
    "                                                 output_signature=tf.TensorSpec(shape=(), \n",
    "                                                                                dtype=tf.string))\n",
    "        log.debug(f'dataset created')\n",
    "\n",
    "        # Tokenize the whole dataset with the pre-trained tokenizer and apply our data preparation method.\n",
    "        train_data = (dataset\n",
    "                        .skip(0)\n",
    "                        .take(self.train_size * self.batch_size)\n",
    "                        .repeat()\n",
    "                        .shuffle(self.buffer_size)\n",
    "                        .batch(self.batch_size)\n",
    "                        .map(lambda x: self.prepare_datapoint(x), \n",
    "                             num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                        .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "        \n",
    "        val_data = (dataset\n",
    "                    .skip(self.train_size * self.batch_size)\n",
    "                    .take(self.val_size * self.batch_size)\n",
    "                    .repeat()\n",
    "                    .shuffle(self.buffer_size)\n",
    "                    .batch(self.batch_size)\n",
    "                    .map(lambda x: self.prepare_datapoint(x), \n",
    "                         num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "        \n",
    "        test_data = (dataset\n",
    "                    .skip((self.train_size + self.val_size) * self.batch_size)\n",
    "                    .take(self.test_size * self.batch_size)\n",
    "                    .repeat()\n",
    "                    .shuffle(self.buffer_size)\n",
    "                    .batch(self.batch_size)\n",
    "                    .map(lambda x: self.prepare_datapoint(x), \n",
    "                         num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "        self.dataset = train_data, val_data, test_data\n",
    "        log.debug(f'dataset processed')\n",
    "        \n",
    "        return self.dataset\n",
    "    \n",
    "    def prepare_datapoint(self, batch):\n",
    "        \"\"\"\n",
    "        Prepares a datapoint for the transformer model by tokenizing and creating the necessary masks.\n",
    "\n",
    "        Args:\n",
    "            data_point (str): A sentence or text to be prepared.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing source tokens, target tokens and their respective masks, and label tokens.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        src_tokens = self.tokenizer.tokenize(batch)\n",
    "        # Shorten tgt and label in order to remove [Start], [End] tokens\n",
    "        tgt_tokens = src_tokens[:, :-1]\n",
    "        label_tokens = src_tokens[:, 1:]\n",
    "        \n",
    "        # Fill the data to same size tensors.\n",
    "        src = src_tokens.to_tensor(shape=[None, self.max_padding], \n",
    "                                   default_value=self.pad_id)\n",
    "        tgt = tgt_tokens.to_tensor(shape=[None, self.max_padding], \n",
    "                                   default_value=self.pad_id)\n",
    "        label = label_tokens.to_tensor(shape=[None, self.max_padding], \n",
    "                                       default_value=self.pad_id)\n",
    "        \n",
    "        # padding mask for source and subsequent mask for tgt\n",
    "        # the masks are to be passed with the data through the model instead of reacreating it every time the model runs.\n",
    "        src_mask = (src != self.pad_id)[:, np.newaxis, :]\n",
    "        tgt_mask = self.make_subseq_mask(tgt)\n",
    "\n",
    "        return (src, tgt, src_mask, tgt_mask), label\n",
    "  \n",
    "    def make_subseq_mask(self, tgt):\n",
    "        \"\"\"\n",
    "        Creates a mask for the transformer model to avoid using future tokens and padding.\n",
    "\n",
    "        Args:\n",
    "            tgt (tf.Tensor): Tensor of target tokens.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The mask tensor.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        tgt_mask = (tgt != self.pad_id)[:, np.newaxis, :]\n",
    "        tgt_mask = tf.logical_and(tgt_mask, subsequent_mask(tgt.shape[-1]))\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGeneratorAlt():\n",
    "    \"\"\"\n",
    "    A class to generate TensorFlow datasets for Transformer models from text files.\n",
    "    The txt_files_to_lines_gen generates lines, that are fitted into a certain length by\n",
    "    lines_to_fit_sentences (it combines follow-up sentences, if they don't exceed the limit together)..\n",
    "    generate_datasets and prepare_datapoint are used to generate the kind of data necessary for our model:\n",
    "    (src, tgt, src_mask, tgt_mask), label. Here src, tgt and label are similar tensors, but shifted right or left\n",
    "    and with or without [Start] or [End] tokens. The src_mask is a padding mask and the tgt_mask is a subsequent mask.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tokenizer, \n",
    "                 buffer_size=20000, \n",
    "                 batch_size=64,\n",
    "                 train_val_test_size = (0, 0, 0),\n",
    "                 max_padding=128, \n",
    "                 pad_id=0):\n",
    "        \"\"\"\n",
    "        Constructor for the DatasetGenerator class.\n",
    "        \n",
    "        Args:\n",
    "            tokenizer:          Instance of the tokenizer to be used.\n",
    "            buffer_size (int):  Number of elements from the dataset from which the new dataset will sample.\n",
    "                                This is crucial for randomisation, as the dataset is not shuffled further than buffer_size allows.\n",
    "            batch_size (int):   Number of elements per batch in the dataset.\n",
    "            max_padding (int):  The maximum sequence length, shorter sequences will be padded with pad_id.\n",
    "            pad_id (int):       ID to be used for padding shorter sequences.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size, self.val_size, self.test_size = tuple(map(lambda x: x * self.batch_size, train_val_test_size))\n",
    "        self.max_padding = max_padding\n",
    "        self.pad_id = pad_id\n",
    "        self.dataset = None\n",
    "\n",
    "    def txt_files_to_lines_gen(self, file):\n",
    "        \"\"\"\n",
    "        Generator function that yields lines from text files in a directory.\n",
    "\n",
    "        Args:\n",
    "            file_path (str):    Path to the directory containing the text files.\n",
    "\n",
    "        Yields:\n",
    "            str:                A line from a text file.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f:\n",
    "                yield line.strip()\n",
    "\n",
    "    def generate_dataset(self, file_path, train_val_test_size = None):\n",
    "        \"\"\"\n",
    "        Generates a tokenized, batched TensorFlow dataset from text files.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the directory containing the text files.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: The generated dataset. It contains the following data: (src, tgt, src_mask, tgt_mask), label\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        if train_val_test_size is not None:\n",
    "            self.train_size, self.val_size, self.test_size = tuple(map(lambda x: x * self.batch_size, train_val_test_size))\n",
    "\n",
    "        log.debug(f'generators set up')\n",
    "\n",
    "        path = pathlib.Path(file_path)\n",
    "        file_list = [str(file) for file in path.iterdir() if file.is_file()]\n",
    "\n",
    "        files = tf.data.Dataset.from_tensor_slices(file_list)\n",
    "\n",
    "        # TODO: Set up a cycle length equal to the number of GPU devices.\n",
    "        dataset = files.interleave(lambda x: tf.data.Dataset.from_generator(\n",
    "                self.txt_files_to_lines_gen,\n",
    "                args=(x,),\n",
    "                output_signature=tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "                ),\n",
    "            num_parallel_calls = tf.data.AUTOTUNE,\n",
    "            deterministic=False\n",
    "        )\n",
    "        log.debug(f'dataset created')\n",
    "        \n",
    "        # Tokenize the whole dataset with the pre-trained tokenizer and apply our data preparation method.\n",
    "        train_data = (dataset\n",
    "                        .skip(0)\n",
    "                        .take(self.train_size)\n",
    "                        .repeat()\n",
    "                        .shuffle(self.buffer_size)\n",
    "                        .batch(self.batch_size)\n",
    "                        .map(lambda x: self.prepare_datapoint(x), \n",
    "                             num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                             deterministic=False)\n",
    "                        .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "        \n",
    "        val_data = (dataset\n",
    "                    .skip(self.train_size)\n",
    "                    .take(self.val_size)\n",
    "                    .repeat()\n",
    "                    .shuffle(self.buffer_size)\n",
    "                    .batch(self.batch_size)\n",
    "                    .map(lambda x: self.prepare_datapoint(x), \n",
    "                         num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                         deterministic=False)\n",
    "                    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "        \n",
    "        test_data = (dataset\n",
    "                    .skip(self.train_size + self.val_size)\n",
    "                    .take(self.test_size)\n",
    "                    .repeat()\n",
    "                    .shuffle(self.buffer_size)\n",
    "                    .batch(self.batch_size)\n",
    "                    .map(lambda x: self.prepare_datapoint(x), \n",
    "                         num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                         deterministic=False)\n",
    "                    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "        self.dataset = train_data, val_data, test_data\n",
    "        log.debug(f'dataset processed')\n",
    "        \n",
    "        return self.dataset\n",
    "    \n",
    "    def prepare_datapoint(self, data_point):\n",
    "        \"\"\"\n",
    "        Prepares a datapoint for the transformer model by tokenizing and creating the necessary masks.\n",
    "\n",
    "        Args:\n",
    "            data_point (str): A sentence or text to be prepared.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing source tokens, target tokens and their respective masks, and label tokens.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        src_tokens = self.tokenizer.tokenize(data_point)\n",
    "        # Shorten tgt and label in order to remove [Start], [End] tokens\n",
    "        tgt_tokens = src_tokens[:, :-1]\n",
    "        label_tokens = src_tokens[:, 1:]\n",
    "        \n",
    "        # Fill the data to same size tensors.\n",
    "        src = src_tokens.to_tensor(shape=[None, self.max_padding], \n",
    "                                   default_value=self.pad_id)\n",
    "        tgt = tgt_tokens.to_tensor(shape=[None, self.max_padding], \n",
    "                                   default_value=self.pad_id)\n",
    "        label = label_tokens.to_tensor(shape=[None, self.max_padding], \n",
    "                                       default_value=self.pad_id)\n",
    "        \n",
    "        # padding mask for source and subsequent mask for tgt\n",
    "        # the masks are to be passed with the data through the model instead of reacreating it every time the model runs.\n",
    "        src_mask = (src != self.pad_id)[:, np.newaxis, :]\n",
    "        tgt_mask = self.make_subseq_mask(tgt)\n",
    "\n",
    "        return (src, tgt, src_mask, tgt_mask), label\n",
    "  \n",
    "    def make_subseq_mask(self, tgt):\n",
    "        \"\"\"\n",
    "        Creates a mask for the transformer model to avoid using future tokens and padding.\n",
    "\n",
    "        Args:\n",
    "            tgt (tf.Tensor): Tensor of target tokens.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The mask tensor.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        tgt_mask = (tgt != self.pad_id)[:, np.newaxis, :]\n",
    "        tgt_mask = tf.logical_and(tgt_mask, subsequent_mask(tgt.shape[-1]))\n",
    "        return tgt_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(layers.Layer, VisualWrapper):\n",
    "    \"\"\"\n",
    "    This class represents a loss function layer that applies label smoothing to prevent overconfidence \n",
    "    in the model's predictions. This is done by replacing the 0s and 1s in the labels with smoothed values, \n",
    "    such that the model learns to be less confident and thus, more robust.\n",
    "\n",
    "    Methods:\n",
    "        call(x, target): Calculates and returns the loss given the model's output `x` and the target labels.\n",
    "\n",
    "    Example:\n",
    "        >>> loss_func = LabelSmoothingLoss(vocab_size=5000, padding_idx=0, smoothing=0.1)\n",
    "        >>> x = tf.random.uniform((10, 5000))  # model's output\n",
    "        >>> target = tf.random.uniform((10, 1), maxval=5000, dtype=tf.int32)  # target labels\n",
    "        >>> loss = loss_func(x, target)  # calculate loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, padding_idx, smoothing=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size (int): The size of the vocabulary, which also represents the number of classes.\n",
    "            padding_idx (int): The index representing padding elements.\n",
    "            smoothing (float): The smoothing factor to be applied. The values should be between 0 and 1. \n",
    "                            Default value is 0.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "\n",
    "        # confidence is used for the position of the predicted token, while smoothing is applied to all not predicted tokens\n",
    "        self.confidence = 1.0 - smoothing   # value for prediction\n",
    "        self.smoothing = smoothing          # value for smoothing\n",
    "        \n",
    "    def call(self, prediction, target):\n",
    "        \"\"\"\n",
    "        This function applies label smoothing to the target labels, computes the KL divergence loss \n",
    "        between the predicted and smoothed target distributions, then masks out the padding tokens \n",
    "        in the loss (since those should not contribute to the training signal). Finally, it averages \n",
    "        the loss over the non-padding tokens.\n",
    "\n",
    "        Args:\n",
    "            prediction (tf.Tensor):     The predicted token logits from the model in form of a one-hot-encoding tensor.\n",
    "                                        Shape is [batch_size, sequence_length, vocab_size].\n",
    "            target (tf.Tensor):         The target token IDs. Shape is [batch_size, sequence_length].\n",
    "\n",
    "        Returns:\n",
    "            loss (tf.Tensor):           The average loss (scalar) for the given batch.\n",
    "\n",
    "        Note:\n",
    "            The loss is averaged over non-padding tokens.\n",
    "        \"\"\"\n",
    "        # create padding mask\n",
    "        mask = self.padding_mask(target, self.padding_idx)\n",
    "\n",
    "        # Apply label confidence\n",
    "        true_dist = target * self.confidence\n",
    "\n",
    "        # Apply label smoothing\n",
    "        smoothing_value = self.smoothing / tf.cast(self.vocab_size - 2, tf.float32)\n",
    "        true_dist = tf.where(tf.equal(true_dist, 0), smoothing_value, true_dist)\n",
    "\n",
    "        # Calculate the loss\n",
    "        kl_div_loss = self.kl_div_loss(prediction, true_dist)\n",
    "        masked_loss = tf.cast(self.apply_mask(kl_div_loss, mask), prediction.dtype)\n",
    "        loss = tf.reduce_sum(masked_loss)/tf.reduce_sum(mask)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def padding_mask(tensor, padding_idx):\n",
    "        \"\"\"\n",
    "        Create a binary mask where padding entries are 0 and others are 1.\n",
    "\n",
    "        Args:\n",
    "            tensor (tf.Tensor):     A tensor to be masked, of any shape.\n",
    "            padding_idx (int):      The value that represents padding in the tensor.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor:              A binary mask of the same shape as input tensor.\n",
    "        \"\"\"\n",
    "        return tf.cast(tf.equal(tensor[:, :, padding_idx], 0), tf.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mask(tensor, mask):\n",
    "        \"\"\"\n",
    "        Applies a mask to a tensor, zeroing out where the mask is on.\n",
    "\n",
    "        Args:\n",
    "            tensor (tf.Tensor):     A tensor to be masked, of any shape.\n",
    "            mask (tf.Tensor):       A mask tensor, must be broadcastable to the shape of 'tensor'.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor:              A tensor of the same shape as input tensor but with masked values zeroed out.\n",
    "        \"\"\"\n",
    "        return tensor * (tf.reshape(mask, [-1, 1]) * tf.ones_like(tensor))\n",
    "    \n",
    "    @staticmethod\n",
    "    def kl_div_loss(input, target):\n",
    "        \"\"\"\n",
    "        Calculates the Kullback-Leibler divergence between the input and target distributions.\n",
    "\n",
    "        Notes: Inputs have to be logits, while target have to be probabilities.\n",
    "\n",
    "        Args:\n",
    "            input (tf.Tensor):      Input tensor, representing predicted probability distribution.\n",
    "            target (tf.Tensor):     Target tensor, representing true probability distribution.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor:              The KL divergence between the input and target distributions.\n",
    "        \"\"\"\n",
    "        return target * (tf.math.log(target)-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCompute(tf.keras.losses.Loss, VisualWrapper):\n",
    "    \"\"\"\n",
    "    Custom loss computation class that computes loss on a batch of examples.\n",
    "    This class inherits from tf.keras.losses.Loss, which allows it to be used seamlessly \n",
    "    within the Keras API.\n",
    "    \"\"\"\n",
    "    def __init__(self, generator, loss_function, vocab_size, name='loss_compute'):\n",
    "        \"\"\"\n",
    "        Initializes the LossCompute object.\n",
    "        \n",
    "        Args:\n",
    "            generator (layers.Layer):       The generator layer.\n",
    "            loss_function (layers.Layer):   The function class to compute the loss.\n",
    "            vocab_size (int):               The size of the vocabulary.\n",
    "            name (str, optional):           The name for the loss.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__(name=name)\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "        self.generator = generator\n",
    "        self.loss_function = loss_function\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Computes the loss on a batch of examples.\n",
    "        \n",
    "        Args:\n",
    "            y_true (tf.Tensor): The true labels.\n",
    "            y_pred (tf.Tensor): The predicted labels.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The total loss for the batch.\n",
    "        \"\"\"\n",
    "        # generate predictions as one-hot encoded tensor\n",
    "        y_pred = self.generator(y_pred)\n",
    "        y_true_one_hot = tf.cast(tf.one_hot(y_true, depth=self.vocab_size), tf.float32)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_function(y_pred, y_true_one_hot)\n",
    "\n",
    "        # Calculate mean loss per batch\n",
    "        norm = tf.cast(tf.shape(y_true)[0], dtype=tf.float32)\n",
    "        sloss = loss / norm\n",
    "\n",
    "        # Return total loss (for the whole batch)\n",
    "        # TODO: Do we want mean loss or total loss?\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSchedule(tf.keras.optimizers.schedules.LearningRateSchedule, VisualWrapper):\n",
    "    \"\"\"\n",
    "    Custom learning rate scheduler for the Transformer model.\n",
    "\n",
    "    This class inherits from tf.keras.optimizers.schedules.LearningRateSchedule, which allows it to be used seamlessly\n",
    "    within the Keras API for dynamically adjusting the learning rate during training.\n",
    "\n",
    "    It follows the learning rate schedule defined in the \"Attention is All You Need\" paper, which increases the \n",
    "    learning rate linearly for the first 'warmup_steps', and decreases it afterwards proportionally to the inverse \n",
    "    square root of the step number.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=512, warmup_steps=4000):\n",
    "        \"\"\"\n",
    "        Initializes the TransformerSchedule object.\n",
    "        \n",
    "        Args:\n",
    "            d_model (int, optional):        The dimensionality of the input.\n",
    "            warmup_steps (int, optional):   The number of steps for the linear warmup phase.\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        super().__init__()\n",
    "        VisualWrapper.__init__(self, vis_on_count=[0])\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32) # for calculations we need float tensors\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        \"\"\"\n",
    "        Computes the learning rate for a given step.\n",
    "        \n",
    "        Args:\n",
    "            step (int): The current training step.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The learning rate for the provided step.\n",
    "        \"\"\"\n",
    "        step = tf.cast(step, dtype=tf.float32)  # convert for calculations\n",
    "        arg_1 = tf.math.rsqrt(step)             # rsqrt is equivalent to 1/sqrt(x)\n",
    "        arg_2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        # Minimum of two arguments provides the linear warmup phase for the first 'warmup_steps'\n",
    "        # and the decrease proportional to the inverse square root of the step afterwards.\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg_1, arg_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(label, pred, pad_idx):\n",
    "  \"\"\"\n",
    "  This function calculates the accuracy of the prediction while ignoring the specified padding index. \n",
    "  It assumes that labels have already been converted into indices (i.e., not one-hot encoded).\n",
    "\n",
    "  Args:\n",
    "      label (tf.Tensor):  The ground truth labels. These should be integer indices, \n",
    "                          not one-hot encoded, with a shape of (batch_size, seq_length).\n",
    "      pred (tf.Tensor):   The predicted labels, given by the model. These should be \n",
    "                          the raw outputs of the model (i.e., logits) with a shape of \n",
    "                          (batch_size, seq_length, vocab_size).\n",
    "      pad_idx (int):      The index representing the padding in the sequence. This will be excluded \n",
    "                          from the accuracy calculation.\n",
    "\n",
    "  Returns:\n",
    "      tf.Tensor: The accuracy of the model's predictions, excluding padding. \n",
    "                  It is a scalar tensor (0-dimensional).\n",
    "  \"\"\"\n",
    "\n",
    "  pred = tf.argmax(pred, axis=2)      # calculate prediction tokens from logits\n",
    "  label = tf.cast(label, pred.dtype)  # assure matching works\n",
    "\n",
    "  match = label == pred   # mask\n",
    "  mask = label != pad_idx # mask out padding\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_with_pad_idx(pad_idx):\n",
    "   \"\"\"\n",
    "   Returns an accuracy function where the pad_idx is already set.add\n",
    "\n",
    "   Args:\n",
    "      pad_idx (int): An id for the padding token such that it can be masked in accuracy calculation\n",
    "\n",
    "    Returns:\n",
    "      function: A accuracy function that compares label and prediction.\n",
    "   \"\"\"\n",
    "   return lambda label, pred: masked_accuracy(label, pred, pad_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, \n",
    "               tgt_vocab, \n",
    "               N=6, \n",
    "               d_model=512, \n",
    "               d_ff=2048, \n",
    "               h=8, \n",
    "               dropout=0.1) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Constructs a Transformer model from the given hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        src_vocab (int):            The size of the source vocabulary.\n",
    "        tgt_vocab (int):            The size of the target vocabulary.\n",
    "        N (int, optional):          The number of layers in the Transformer's encoder and decoder stacks. Default is 6.\n",
    "        d_model (int, optional):    The dimension of the Transformer's embedding space. Default is 512.\n",
    "        d_ff (int, optional):       The dimension of the feed forward network model. Default is 2048.\n",
    "        h (int, optional):          The number of attention heads. Default is 8.\n",
    "        dropout (float, optional):  The dropout rate. Default is 0.1.\n",
    "\n",
    "    Returns:\n",
    "        model (tf.keras.Model): A Transformer model constructed from the provided hyperparameters.\n",
    "\n",
    "    This function constructs an Encoder-Decoder model using the specified hyperparameters. \n",
    "    The Encoder and Decoder stacks each consist of N layers. \n",
    "    Each layer in the Encoder stack consists of a multi-headed self-attention mechanism, \n",
    "    followed by position-wise fully connected feed-forward network. \n",
    "    Each layer in the Decoder stack consists of a multi-headed self-attention mechanism, \n",
    "    a multi-headed source-attention mechanism over the Encoder's output, \n",
    "    and position-wise fully connected feed-forward network.\n",
    "    \"\"\"\n",
    "    log.debug(f'execute')\n",
    "    model = EncoderDecoder(\n",
    "                EncoderStack(\n",
    "                    EncoderLayer,\n",
    "                    N=N, \n",
    "                    size=d_model, \n",
    "                    dropout=dropout, \n",
    "                    self_attn=MultiHeadedAttention(h, d_model), \n",
    "                    feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout)),\n",
    "                DecoderStack(\n",
    "                    DecoderLayer, \n",
    "                    N=N, \n",
    "                    size=d_model, \n",
    "                    dropout=dropout,\n",
    "                    self_attn=MultiHeadedAttention(h, d_model), \n",
    "                    src_attn=MultiHeadedAttention(h, d_model), \n",
    "                    feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout)),\n",
    "                PositionalEmbedding(\n",
    "                    src_vocab, \n",
    "                    d_model,\n",
    "                    dropout),\n",
    "                PositionalEmbedding(\n",
    "                    tgt_vocab, \n",
    "                    d_model,\n",
    "                    dropout),\n",
    "                Generator(tgt_vocab)\n",
    "            )\n",
    "    log.debug(f'model set up')\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 11:14:51 INFO     MainProcess MainThread _initialize_strategy Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "class ModelTrainer():\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 tokenizer, \n",
    "                 data_generator,\n",
    "                 data_path = None,\n",
    "                 train_val_test_size = (0, 0, 0),\n",
    "                 d_model = 512,\n",
    "                 n_stacks = 6,\n",
    "                 h_att = 8,\n",
    "                 smoothing = 0.1,\n",
    "                 max_padding = 512,\n",
    "                 pad_idx = 0,\n",
    "                 batch_size = 64,\n",
    "                 warmup_steps = 4000,\n",
    "                 base_lr = None,\n",
    "                 n_epochs = 1,\n",
    "                 initial_epoch = 0,\n",
    "                 steps_per_epoch = None,\n",
    "                 validation_steps = None,\n",
    "                 verbosity = 2,\n",
    "                 distributed_strategy = tf.distribute.MirroredStrategy(),\n",
    "                 load_model = False,\n",
    "                 save_model = True,\n",
    "                 model_load_path = None\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Docstring\n",
    "        \"\"\"\n",
    "        log.debug(f'initialize {self.__class__.__name__}')\n",
    "        # class modules\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # var for model compile\n",
    "        self.vocab_size = tokenizer.get_vocab_size()\n",
    "        self.d_model = d_model\n",
    "        self.n_stacks = n_stacks\n",
    "        self.h_att = h_att\n",
    "        self.smoothing = smoothing\n",
    "        self.accuracy = accuracy_with_pad_idx(pad_idx)\n",
    "\n",
    "        # var for distributed training\n",
    "        self.strategy = distributed_strategy\n",
    "        self.n_devices = distributed_strategy.num_replicas_in_sync\n",
    "        log.debug(f\"number of processing devices = {self.n_devices}\")\n",
    "\n",
    "        # var for model fitting\n",
    "        self.multi_device_batch_size = batch_size * self.n_devices\n",
    "        self.n_epochs = n_epochs\n",
    "        self.initial_epoch = initial_epoch\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.validation_steps = validation_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.base_lr = base_lr\n",
    "        self.fit_verbosity = verbosity\n",
    "        self.callbacks = []\n",
    "\n",
    "        # var for data generation\n",
    "        self.data_path = data_path\n",
    "        self.train_val_test_size = train_val_test_size\n",
    "        self.max_padding = max_padding\n",
    "        self.pad_idx = pad_idx\n",
    "        self.data_generator = data_generator(tokenizer = tokenizer, \n",
    "                                             batch_size = self.multi_device_batch_size,\n",
    "                                             train_val_test_size = train_val_test_size,\n",
    "                                             max_padding = max_padding,\n",
    "                                             pad_id = pad_idx)\n",
    "        self.train_data, self.val_data, self.test_data = self.load_dataset(self.data_generator,\n",
    "                                                                           self.data_path,\n",
    "                                                                           self.train_val_test_size)\n",
    "        \n",
    "        # var for load and save\n",
    "        self.load_model = load_model\n",
    "        self.save_model = save_model\n",
    "        self.model_load_path = model_load_path\n",
    "\n",
    "        # compile model and load model weights if applicable\n",
    "        self.model = self.compile_model()\n",
    "        if load_model:\n",
    "            self.load_model_weights(self.model, self.d_model, self.model_load_path)\n",
    "        \n",
    "        # add checkpoints\n",
    "        if save_model:\n",
    "            self.add_save_checkpoints()\n",
    "\n",
    "    def load_dataset(self, data_generator, data_path, train_val_test_size):\n",
    "        \"\"\"\n",
    "        This function loads the dataset into the ModelTrainer.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        if data_path is not None:\n",
    "            return data_generator.generate_dataset(data_path,\n",
    "                                                   train_val_test_size)\n",
    "        else:\n",
    "            return None, None, None\n",
    "        \n",
    "    def compile_model(self):\n",
    "        with self.strategy.scope():\n",
    "            # set_up_model\n",
    "            model = make_model(self.vocab_size, \n",
    "                               self.vocab_size, \n",
    "                               d_model = self.d_model,\n",
    "                               N = self.n_stacks,\n",
    "                               h = self.h_att)\n",
    "            log.debug(f'model set up')\n",
    "\n",
    "            # compile model\n",
    "            model.compile(\n",
    "            loss = LossCompute(model.generator, \n",
    "                               LabelSmoothingLoss(self.vocab_size, \n",
    "                                                  self.pad_idx, \n",
    "                                                  self.smoothing), \n",
    "                               self.vocab_size), \n",
    "            optimizer = tf.keras.optimizers.Adam(TransformerSchedule(self.d_model, \n",
    "                                                                     self.warmup_steps), # type: ignore\n",
    "                                                                     beta_1=0.9, \n",
    "                                                                     beta_2=0.98, \n",
    "                                                                     epsilon=1e-9), \n",
    "            metrics = [self.accuracy],\n",
    "            )\n",
    "            log.debug(f'model compiled')\n",
    "\n",
    "            VisualWrapper.reset_counter()\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def run_model(self, training_data=None, validation_data=None, epochs=None):\n",
    "        \"\"\"\n",
    "        Execute model training\n",
    "        \"\"\"\n",
    "        training_data = training_data or self.train_data\n",
    "        validation_data = validation_data or self.val_data\n",
    "        epochs = epochs or self.n_epochs\n",
    "\n",
    "        if training_data is None or validation_data is None or epochs is None:\n",
    "            raise ValueError(\"Training data, validation data and epochs must be provided either as arguments or as instance attributes.\")\n",
    "        \n",
    "        log.debug(f'execute model fit with {epochs} epochs')\n",
    "        \n",
    "        self.model.fit(training_data, \n",
    "                       epochs = epochs,\n",
    "                       steps_per_epoch = self.train_val_test_size[0],\n",
    "                       batch_size = self.multi_device_batch_size,\n",
    "                       validation_data = validation_data,\n",
    "                       validation_steps = self.train_val_test_size[1],\n",
    "                       callbacks = self.callbacks,\n",
    "                       verbose = self.fit_verbosity)\n",
    "        \n",
    "        if self.save_model:\n",
    "            self.save_model_weights()\n",
    "        \n",
    "        print(self.model.summary())\n",
    "        \n",
    "        VisualWrapper.reset_counter()\n",
    "    \n",
    "    def load_model_weights(self, model, d_model, model_folder):\n",
    "        \"\"\"\n",
    "        Load the latest model weights if available.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model):         The model to which the weights will be loaded.\n",
    "            d_model (int):                  The dimension of the Transformer architecture.\n",
    "            model_folder (str, optional):   The directory from which to load the weights. \n",
    "                                            Default is None.\n",
    "\n",
    "        Returns:\n",
    "            model (tf.keras.Model):         The model with the loaded weights.\n",
    "            \n",
    "        This function loads the weights from the latest trained model found in the provided model_folder \n",
    "        or from the latest model in the current directory if load_latest is True.\n",
    "        \"\"\"\n",
    "        log.debug(f'execute')\n",
    "        # TODO: Ensure architecture sizes match.\n",
    "        if model_folder is not None:\n",
    "            log.debug(f'model_folder={model_folder}')\n",
    "            # Load weights from the specified model folder\n",
    "            directories = [model_folder]\n",
    "        else:\n",
    "            directories = sorted(pathlib.Path('.').glob('model_N*_h*'), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "\n",
    "        log.debug(f'load_dir={directories}')\n",
    "\n",
    "        # Load weights from the latest trained model\n",
    "        latest_weights = None\n",
    "        if directories:\n",
    "            latest_dir_path = directories[0]\n",
    "            # Get all the h5 files inside the directory and sort them\n",
    "            h5_files = sorted(latest_dir_path.glob('*.h5'))\n",
    "\n",
    "            if h5_files:\n",
    "                # Pick the last epoch file (or final_model file if it exists)\n",
    "                latest_epoch_file = h5_files[-1] if 'final_model.h5' not in str(h5_files[-1]) else h5_files[-2]\n",
    "                latest_weights = latest_epoch_file\n",
    "\n",
    "        log.debug(f'model weights extracted')\n",
    "\n",
    "        # Load weights if we found a previously trained model\n",
    "        if latest_weights is not None:\n",
    "            print(f'Loading weights from {latest_weights}')\n",
    "            \n",
    "            # Create a dummy input matching the input shape of the model\n",
    "            # TODO: Ensure that the shape and type of the dummy_input match with the actual input that your model is going to receive.\n",
    "            dummy_input = tf.random.uniform(shape=[1,d_model]), tf.random.uniform(shape=[1,d_model]), None, None\n",
    "            # Call the model on the dummy input\n",
    "            _ = model.generator(model(dummy_input))\n",
    "\n",
    "            model.load_weights(latest_weights)\n",
    "        log.debug(f'model loaded with weights')\n",
    "\n",
    "    def add_save_checkpoints(self):\n",
    "        log.debug(f'execute')\n",
    "\n",
    "        current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        directory = f\"model_N{self.n_stacks}_h{self.h_att}_d{self.d_model}_t{current_time}\"\n",
    "        ckp_name = \"model_{epoch:03d}.h5\"\n",
    "        dir_path = pathlib.Path(directory)\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        checkpoint_path = dir_path / ckp_name\n",
    "        \n",
    "        epoch_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                              save_freq='epoch',\n",
    "                                                              save_weights_only=True, \n",
    "                                                              verbose=1)\n",
    "        \n",
    "        self.callbacks.append(epoch_checkpoint)\n",
    "    \n",
    "    def save_model_weights(self):\n",
    "        log.debug(f'execute')\n",
    "\n",
    "        current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "        directory = f\"model_N{self.n_stacks}_h{self.h_att}_d{self.d_model}_t{current_time}\"\n",
    "        final_name = \"final_model.h5\"\n",
    "        dir_path = pathlib.Path(directory)\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        save_path = dir_path / final_name\n",
    "\n",
    "        self.model.save_weights(save_path, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer(StoryTokenizer(reserved_tokens, vocab_path),\n",
    "                             DatasetGeneratorAlt,\n",
    "                             bco_compact_file_path,\n",
    "                             train_val_test_size=(600,200,200),\n",
    "                             d_model=128,\n",
    "                             n_stacks=6,\n",
    "                             h_att=8,\n",
    "                             max_padding=512,\n",
    "                             batch_size=32,\n",
    "                             warmup_steps=100,\n",
    "                             n_epochs=4,\n",
    "                             initial_epoch=0,\n",
    "                             steps_per_epoch=600,\n",
    "                             validation_steps=200,\n",
    "                             verbosity=1,\n",
    "                             load_model=False,\n",
    "                             save_model=True,\n",
    "                             model_load_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4' defined at (most recent call last):\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 973, in _bootstrap\n      self._bootstrap_inner()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 1016, in _bootstrap_inner\n      self.run()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 103, in call\n      subseq_mask, training)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 56, in encode\n      training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 39, in call\n      for layer in self.layers:\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 40, in call\n      input_tensor = layer(input_tensor, mask, training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\651474934.py\", line 38, in call\n      sublayer_out = sublayer(norm_input)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\1310204329.py\", line 71, in call\n      att_out = tf.reshape(tf.transpose(att_out, perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\nNode: 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4'\nDetected at node 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4' defined at (most recent call last):\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 973, in _bootstrap\n      self._bootstrap_inner()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 1016, in _bootstrap_inner\n      self.run()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 103, in call\n      subseq_mask, training)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 56, in encode\n      training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 39, in call\n      for layer in self.layers:\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 40, in call\n      input_tensor = layer(input_tensor, mask, training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\651474934.py\", line 38, in call\n      sublayer_out = sublayer(norm_input)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\1310204329.py\", line 71, in call\n      att_out = tf.reshape(tf.transpose(att_out, perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\nNode: 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,512,8,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[div_no_nan_1/ReadVariableOp_1/_638]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,512,8,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_77132]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luis\\Dateien\\Beschaeftigungen\\WiMi_Lingen\\Implementation\\TF_simulator_tensorflow\\model_generator_trainer.ipynb Zelle 61\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_trainer\u001b[39m.\u001b[39;49mrun_model()\n",
      "\u001b[1;32mc:\\Users\\Luis\\Dateien\\Beschaeftigungen\\WiMi_Lingen\\Implementation\\TF_simulator_tensorflow\\model_generator_trainer.ipynb Zelle 61\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTraining data, validation data and epochs must be provided either as arguments or as instance attributes.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexecute model fit with \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m epochs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(training_data, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m                epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m                steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_val_test_size[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m                batch_size \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulti_device_batch_size,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m                validation_data \u001b[39m=\u001b[39;49m validation_data,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m                validation_steps \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_val_test_size[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m                callbacks \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m                verbose \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_verbosity)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Luis/Dateien/Beschaeftigungen/WiMi_Lingen/Implementation/TF_simulator_tensorflow/model_generator_trainer.ipynb#Y124sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model_weights()\n",
      "File \u001b[1;32mc:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4' defined at (most recent call last):\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 973, in _bootstrap\n      self._bootstrap_inner()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 1016, in _bootstrap_inner\n      self.run()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 103, in call\n      subseq_mask, training)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 56, in encode\n      training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 39, in call\n      for layer in self.layers:\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 40, in call\n      input_tensor = layer(input_tensor, mask, training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\651474934.py\", line 38, in call\n      sublayer_out = sublayer(norm_input)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\1310204329.py\", line 71, in call\n      att_out = tf.reshape(tf.transpose(att_out, perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\nNode: 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4'\nDetected at node 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4' defined at (most recent call last):\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 973, in _bootstrap\n      self._bootstrap_inner()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\threading.py\", line 1016, in _bootstrap_inner\n      self.run()\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 103, in call\n      subseq_mask, training)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\3418427215.py\", line 56, in encode\n      training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 39, in call\n      for layer in self.layers:\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\292532597.py\", line 40, in call\n      input_tensor = layer(input_tensor, mask, training=training)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\651474934.py\", line 38, in call\n      sublayer_out = sublayer(norm_input)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\2728603522.py\", line 52, in call\n      attn_output = self.sublayer[0](input_tensor,\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Luis\\miniconda3\\envs\\tf_simu_tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_9712\\1310204329.py\", line 71, in call\n      att_out = tf.reshape(tf.transpose(att_out, perm=[0, 2, 1, 3]), (nbatches, -1, self.h * self.d_k))\nNode: 'encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,512,8,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[div_no_nan_1/ReadVariableOp_1/_638]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,512,8,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node encoder_decoder_2/encoder_stack_2/encoder_layer_13/residual_sublayer_62/multi_headed_attention_6/transpose_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_77132]"
     ]
    }
   ],
   "source": [
    "model_trainer.run_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordComplete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordComplete(tf.Module, VisualWrapper):\n",
    "  \"\"\"\n",
    "    This class defines a complete sequence generation model for a Transformer. \n",
    "    It uses a given tokenizer and Transformer model to generate sequences.\n",
    "  \"\"\"\n",
    "  def __init__(self, \n",
    "               tokenizer, \n",
    "               transformer, \n",
    "               max_length=512, \n",
    "               dtype=tf.Tensor, \n",
    "               decode_result=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tokenizer (Tokenizer):          Tokenizer object to convert raw text into tokens.\n",
    "        transformer (tf.keras.Model):   A Transformer model used for sequence generation.\n",
    "        max_length (int, optional):     The maximum length of sequences that can be generated.\n",
    "                                        Default is 512.\n",
    "        dtype (tf.Tensor, optional):    The datatype of the output tensor. Default is tf.Tensor.\n",
    "        decode_result (bool, optional): If True, decode the output tensor into a string. \n",
    "                                        Default is True.\n",
    "    \"\"\"\n",
    "    log.debug(f'initialize {self.__class__.__name__}')\n",
    "    super().__init__()\n",
    "    VisualWrapper.__init__(self, vis_on_count=None)\n",
    "    self.tokenizer = tokenizer\n",
    "    self.transformer = transformer\n",
    "    self.max_length = max_length\n",
    "    self.dtype = dtype\n",
    "    self.decode_result = decode_result\n",
    "\n",
    "  def __call__(self, input, decode=True, encoding='utf-8', training=None):\n",
    "    \"\"\"\n",
    "    Performs the sequence generation.\n",
    "\n",
    "    Args:\n",
    "        input (str or tf.Tensor):   The input sequence.\n",
    "        decode (bool, optional):    If True, the output sequence is decoded into a string. \n",
    "                                    Default is True.\n",
    "        encoding (str, optional):   The encoding to use when decoding the output sequence. \n",
    "                                    Default is 'utf-8'.\n",
    "        training (bool, optional):  Whether the model is currently training. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        text (str or tf.Tensor):    The generated text. If decode_result is True, this is a string.\n",
    "                                    Otherwise, it is a tensor.\n",
    "        tokens (tf.Tensor):         The tensor of generated tokens.\n",
    "    \"\"\"\n",
    "    VisualWrapper.should_visualize = True\n",
    "    \n",
    "    # TODO: Bug with empty strings as input\n",
    "    # Convert input to tensor if it is not already\n",
    "    # Create a dynamic tensor to store output\n",
    "    # Make sure tensor_input is 2-D\n",
    "    tensor_input = tf.convert_to_tensor(input)\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    if len(tensor_input.shape) == 0:\n",
    "      tensor_input = tensor_input[tf.newaxis]\n",
    "\n",
    "    # tokenize and encode input\n",
    "    # Identify end token of the input\n",
    "    tokenized_input = self.tokenizer.tokenize(tensor_input, training=training).to_tensor()\n",
    "    context = self.transformer.encode(tokenized_input, None, training=training)\n",
    "    end = tokenized_input[-1][-1]\n",
    "\n",
    "    # Write the input tokens (excluding the last one) to the output array\n",
    "    for i, value in enumerate(tokenized_input[0][:-1]):\n",
    "      output_array = output_array.write(i, value)\n",
    "\n",
    "    # Start the generation of sequence from the last position of the input to max_length\n",
    "    for i in tf.range(output_array.size(), self.max_length):\n",
    "\n",
    "      # Prepare input for decoder\n",
    "      # Decode the input\n",
    "      dec_input = output_array.concat()[tf.newaxis]\n",
    "      decode = self.transformer.decode(context, None, dec_input, None, training=training)\n",
    "\n",
    "      # Create logits predictions and select the last predicted token\n",
    "      predictions = self.transformer.generator(decode, training=training)\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the decoder as its input again.\n",
    "      output_array = output_array.write(i, predicted_id[0][0])\n",
    "\n",
    "      # break the loop, if [End] token is predicted\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "    \n",
    "    # Create a tensor for detokenization\n",
    "    # Detokenize\n",
    "    # Create tokens from detokenized output again\n",
    "    output = output_array.concat()[tf.newaxis]\n",
    "    text = self.tokenizer.detokenize(output)\n",
    "    tokens = self.tokenizer.lookup(output)\n",
    "\n",
    "    # If decode_result is True, decode the text tensor into a string\n",
    "    if self.decode_result:\n",
    "      text = text.numpy()[0].decode(encoding)\n",
    "\n",
    "    # reset visualisation\n",
    "    VisualWrapper.should_visualize = False\n",
    "    VisualWrapper.reset_counter()\n",
    "\n",
    "    return text, tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the data from StoryTokenizer\n",
      "[['[START]', 'what', 'will', 'be', 'your', '[END]']]\n",
      "[START] what will be your your your your your your your your your your your your your your your your your your your your your your your your your your your your\n"
     ]
    }
   ],
   "source": [
    "inference_model = WordComplete(StoryTokenizer(reserved_tokens, vocab_path), model_trainer.model, max_length=32)\n",
    "\n",
    "string = \"What will be your\"\n",
    "\n",
    "text, tokens = inference_model(string)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "Use this section to provide code for testing. Delete code after it is not used anymore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DatasetGenerator(StoryTokenizer(reserved_tokens, vocab_path),\n",
    "                                 batch_size=config[\"batch_size\"], \n",
    "                                 max_padding=config[\"max_padding\"], \n",
    "                                 pad_id=config[\"padding_idx\"])\n",
    "\n",
    "data_alt_generator = DatasetGeneratorAlt(StoryTokenizer(reserved_tokens, vocab_path),\n",
    "                                 batch_size=config[\"batch_size\"], \n",
    "                                 max_padding=config[\"max_padding\"], \n",
    "                                 pad_id=config[\"padding_idx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmark dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- The alternative generator is about 1.3 times as fast as the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.benchmark(model_trainer.train_data.take(1000), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.benchmark(model_trainer.train_data.take(1000), batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_simu_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
